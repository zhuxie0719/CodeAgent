#!/usr/bin/env python3
"""
æ¸…ç†ç©ºç™½å­—ç¬¦å·¥å…· v2
å¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒæ›´å¤šåŠŸèƒ½å’Œé…ç½®
"""

import os
import re
import argparse
import json
from pathlib import Path
from typing import List, Optional, Dict, Any

class WhitespaceCleanerV2:
    """ç©ºç™½å­—ç¬¦æ¸…ç†å™¨ v2"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or self._default_config()
        self.cleaned_files = []
        self.errors = []
        self.stats = {
            "files_processed": 0,
            "files_cleaned": 0,
            "lines_removed": 0,
            "bytes_saved": 0
        }
    
    def _default_config(self) -> Dict[str, Any]:
        """é»˜è®¤é…ç½®"""
        return {
            "extensions": ['.py', '.js', '.html', '.css', '.md', '.txt', '.json'],
            "remove_trailing_whitespace": True,
            "remove_trailing_tabs": True,
            "normalize_line_endings": True,
            "max_consecutive_empty_lines": 2,
            "remove_final_empty_lines": True,
            "preserve_indentation": True,
            "backup_files": False
        }
    
    def clean_file(self, file_path: str) -> Dict[str, Any]:
        """æ¸…ç†å•ä¸ªæ–‡ä»¶"""
        result = {
            "file": file_path,
            "cleaned": False,
            "lines_removed": 0,
            "bytes_saved": 0,
            "error": None
        }
        
        try:
            self.stats["files_processed"] += 1
            
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            original_content = content
            original_lines = len(content.split('\n'))
            original_size = len(content.encode('utf-8'))
            
            # æ¸…ç†è¡Œå°¾ç©ºç™½
            if self.config["remove_trailing_whitespace"]:
                content = re.sub(r'[ \t]+$', '', content, flags=re.MULTILINE)
            
            # æ¸…ç†è¡Œå°¾åˆ¶è¡¨ç¬¦
            if self.config["remove_trailing_tabs"]:
                content = re.sub(r'\t+$', '', content, flags=re.MULTILINE)
            
            # æ ‡å‡†åŒ–è¡Œç»“æŸç¬¦
            if self.config["normalize_line_endings"]:
                content = content.replace('\r\n', '\n').replace('\r', '\n')
            
            # æ¸…ç†è¿ç»­çš„ç©ºè¡Œ
            if self.config["max_consecutive_empty_lines"] > 0:
                max_empty = self.config["max_consecutive_empty_lines"]
                pattern = r'\n{' + str(max_empty + 1) + ',}'
                content = re.sub(pattern, '\n' * max_empty, content)
            
            # æ¸…ç†æ–‡ä»¶æœ«å°¾çš„ç©ºè¡Œ
            if self.config["remove_final_empty_lines"]:
                content = content.rstrip() + '\n'
            
            # å¦‚æœå†…å®¹æœ‰å˜åŒ–ï¼Œå†™å›æ–‡ä»¶
            if content != original_content:
                # å¤‡ä»½æ–‡ä»¶
                if self.config["backup_files"]:
                    backup_path = file_path + '.backup'
                    with open(backup_path, 'w', encoding='utf-8') as f:
                        f.write(original_content)
                
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                
                new_lines = len(content.split('\n'))
                new_size = len(content.encode('utf-8'))
                
                result["cleaned"] = True
                result["lines_removed"] = original_lines - new_lines
                result["bytes_saved"] = original_size - new_size
                
                self.stats["files_cleaned"] += 1
                self.stats["lines_removed"] += result["lines_removed"]
                self.stats["bytes_saved"] += result["bytes_saved"]
                
                self.cleaned_files.append(file_path)
            
        except Exception as e:
            result["error"] = str(e)
            self.errors.append(f"{file_path}: {e}")
        
        return result
    
    def clean_directory(self, directory_path: str) -> List[Dict[str, Any]]:
        """æ¸…ç†ç›®å½•ä¸­çš„æ–‡ä»¶"""
        results = []
        path = Path(directory_path)
        
        if path.is_file():
            if path.suffix in self.config["extensions"]:
                result = self.clean_file(str(path))
                results.append(result)
        elif path.is_dir():
            for file_path in path.rglob('*'):
                if file_path.is_file() and file_path.suffix in self.config["extensions"]:
                    result = self.clean_file(str(file_path))
                    results.append(result)
        
        return results
    
    def get_summary(self) -> Dict[str, Any]:
        """è·å–æ¸…ç†æ€»ç»“"""
        return {
            "stats": self.stats,
            "cleaned_files": len(self.cleaned_files),
            "errors": len(self.errors),
            "files": self.cleaned_files,
            "error_details": self.errors,
            "config": self.config
        }
    
    def save_report(self, output_file: str):
        """ä¿å­˜æ¸…ç†æŠ¥å‘Š"""
        report = {
            "timestamp": os.path.getmtime(output_file) if os.path.exists(output_file) else None,
            "summary": self.get_summary(),
            "details": self.cleaned_files
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ¸…ç†ç©ºç™½å­—ç¬¦å·¥å…· v2')
    parser.add_argument('path', help='è¦æ¸…ç†çš„æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„')
    parser.add_argument('--extensions', nargs='+', 
                       default=['.py', '.js', '.html', '.css', '.md', '.txt', '.json'],
                       help='è¦æ¸…ç†çš„æ–‡ä»¶æ‰©å±•å')
    parser.add_argument('--config', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--report', help='ä¿å­˜æ¸…ç†æŠ¥å‘Šåˆ°æŒ‡å®šæ–‡ä»¶')
    parser.add_argument('--dry-run', action='store_true',
                       help='åªæ˜¾ç¤ºä¼šæ¸…ç†çš„æ–‡ä»¶ï¼Œä¸å®é™…ä¿®æ”¹')
    parser.add_argument('--backup', action='store_true',
                       help='æ¸…ç†å‰å¤‡ä»½æ–‡ä»¶')
    parser.add_argument('--max-empty-lines', type=int, default=2,
                       help='æœ€å¤§è¿ç»­ç©ºè¡Œæ•°')
    
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    config = None
    if args.config and os.path.exists(args.config):
        with open(args.config, 'r', encoding='utf-8') as f:
            config = json.load(f)
    
    # åˆ›å»ºæ¸…ç†å™¨
    cleaner = WhitespaceCleanerV2(config)
    
    # åº”ç”¨å‘½ä»¤è¡Œå‚æ•°
    cleaner.config["extensions"] = args.extensions
    cleaner.config["backup_files"] = args.backup
    cleaner.config["max_consecutive_empty_lines"] = args.max_empty_lines
    
    print(f"ğŸ§¹ æ¸…ç†ç©ºç™½å­—ç¬¦ v2: {args.path}")
    print(f"ğŸ“ æ–‡ä»¶ç±»å‹: {', '.join(args.extensions)}")
    print(f"ğŸ“Š æœ€å¤§è¿ç»­ç©ºè¡Œ: {args.max_empty_lines}")
    
    if args.dry_run:
        print("ğŸ” é¢„è§ˆæ¨¡å¼ - ä¸ä¼šå®é™…ä¿®æ”¹æ–‡ä»¶")
        # è¿™é‡Œå¯ä»¥æ·»åŠ é¢„è§ˆé€»è¾‘
        return
    
    results = cleaner.clean_directory(args.path)
    
    summary = cleaner.get_summary()
    
    print(f"âœ… æ¸…ç†å®Œæˆ!")
    print(f"ğŸ“Š å¤„ç†äº† {summary['stats']['files_processed']} ä¸ªæ–‡ä»¶")
    print(f"ğŸ§¹ æ¸…ç†äº† {summary['stats']['files_cleaned']} ä¸ªæ–‡ä»¶")
    print(f"ğŸ“ ç§»é™¤äº† {summary['stats']['lines_removed']} è¡Œ")
    print(f"ğŸ’¾ èŠ‚çœäº† {summary['stats']['bytes_saved']} å­—èŠ‚")
    
    if summary["errors"]:
        print(f"âŒ é‡åˆ° {summary['errors']} ä¸ªé”™è¯¯:")
        for error in summary["error_details"]:
            print(f"  - {error}")
    
    if args.report:
        cleaner.save_report(args.report)
        print(f"ğŸ“„ æ¸…ç†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.report}")


if __name__ == "__main__":
    main()
