#!/usr/bin/env python3
"""
Flaskç®€å•é™æ€æµ‹è¯•
åŸºäºFlask 2.0.0çš„å·²çŸ¥é—®é¢˜è¿›è¡Œæ£€æµ‹
"""

import os
import sys
import json
import ast
import re
from pathlib import Path
from typing import Dict, List, Any, Optional
import importlib.util

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


class StaticTestRunner:
    """é™æ€æµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self):
        self.results = {
            "flask_issues": [],
            "code_quality": [],
            "security_issues": [],
            "performance_issues": []
        }
        
        # Flask 2.0.0 å·²çŸ¥é—®é¢˜åˆ—è¡¨
        self.flask_issues = [
            {
                "id": "FLASK-001",
                "title": "url_for() åœ¨æŸäº›æƒ…å†µä¸‹è¿”å›é”™è¯¯çš„URL",
                "description": "url_for()å‡½æ•°åœ¨å¤„ç†å¤æ‚è·¯ç”±æ—¶å¯èƒ½è¿”å›é”™è¯¯çš„URL",
                "pattern": r"url_for\s*\(",
                "severity": "high"
            },
            {
                "id": "FLASK-002", 
                "title": "æ¨¡æ¿æ¸²æŸ“æ€§èƒ½é—®é¢˜",
                "description": "å¤§å‹æ¨¡æ¿æ¸²æŸ“æ—¶æ€§èƒ½è¾ƒå·®",
                "pattern": r"render_template\s*\(",
                "severity": "medium"
            },
            {
                "id": "FLASK-003",
                "title": "JSONå“åº”ç¼–ç é—®é¢˜",
                "description": "æŸäº›Unicodeå­—ç¬¦åœ¨JSONå“åº”ä¸­ç¼–ç ä¸æ­£ç¡®",
                "pattern": r"jsonify\s*\(",
                "severity": "medium"
            },
            {
                "id": "FLASK-004",
                "title": "ä¼šè¯ç®¡ç†å®‰å…¨é—®é¢˜",
                "description": "ä¼šè¯cookieåœ¨æŸäº›æƒ…å†µä¸‹ä¸å¤Ÿå®‰å…¨",
                "pattern": r"session\s*\[",
                "severity": "high"
            },
            {
                "id": "FLASK-005",
                "title": "è¯·æ±‚ä¸Šä¸‹æ–‡é—®é¢˜",
                "description": "åœ¨æŸäº›å¼‚æ­¥æ“ä½œä¸­è¯·æ±‚ä¸Šä¸‹æ–‡å¯èƒ½ä¸¢å¤±",
                "pattern": r"request\.",
                "severity": "high"
            }
        ]
    
    def run_analysis(self, target_path: str) -> Dict[str, Any]:
        """è¿è¡Œé™æ€åˆ†æ"""
        print(f"ğŸ¯ åˆ†æç›®æ ‡: {target_path}")
        
        target_path = Path(target_path)
        
        if target_path.is_file():
            self._analyze_file(target_path)
        elif target_path.is_dir():
            self._analyze_directory(target_path)
        else:
            raise ValueError(f"æ— æ•ˆçš„ç›®æ ‡è·¯å¾„: {target_path}")
        
        # ç”Ÿæˆæ€»ç»“
        summary = self._generate_summary()
        
        return {
            "summary": summary,
            "details": self.results,
            "timestamp": self._get_timestamp()
        }
    
    def _analyze_file(self, file_path: Path):
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        if file_path.suffix != '.py':
            return
        
        print(f"ğŸ“„ åˆ†ææ–‡ä»¶: {file_path}")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # è§£æAST
            try:
                tree = ast.parse(content)
            except SyntaxError as e:
                self.results["code_quality"].append({
                    "file": str(file_path),
                    "issue": "è¯­æ³•é”™è¯¯",
                    "description": f"Pythonè¯­æ³•é”™è¯¯: {e}",
                    "line": e.lineno,
                    "severity": "high"
                })
                return
            
            # æ£€æŸ¥Flaskç›¸å…³é—®é¢˜
            self._check_flask_issues(content, file_path)
            
            # æ£€æŸ¥ä»£ç è´¨é‡
            self._check_code_quality(tree, file_path)
            
            # æ£€æŸ¥å®‰å…¨é—®é¢˜
            self._check_security_issues(content, file_path)
            
            # æ£€æŸ¥æ€§èƒ½é—®é¢˜
            self._check_performance_issues(content, file_path)
            
        except Exception as e:
            self.results["code_quality"].append({
                "file": str(file_path),
                "issue": "æ–‡ä»¶è¯»å–é”™è¯¯",
                "description": f"æ— æ³•è¯»å–æ–‡ä»¶: {e}",
                "severity": "medium"
            })
    
    def _analyze_directory(self, dir_path: Path):
        """åˆ†æç›®å½•ä¸­çš„æ‰€æœ‰Pythonæ–‡ä»¶"""
        print(f"ğŸ“ åˆ†æç›®å½•: {dir_path}")
        
        python_files = list(dir_path.rglob("*.py"))
        
        for file_path in python_files:
            # è·³è¿‡__pycache__ç›®å½•
            if "__pycache__" in str(file_path):
                continue
            
            self._analyze_file(file_path)
    
    def _check_flask_issues(self, content: str, file_path: Path):
        """æ£€æŸ¥Flaskç›¸å…³é—®é¢˜"""
        lines = content.split('\n')
        
        for issue in self.flask_issues:
            pattern = issue["pattern"]
            matches = re.finditer(pattern, content, re.IGNORECASE)
            
            for match in matches:
                line_num = content[:match.start()].count('\n') + 1
                line_content = lines[line_num - 1].strip()
                
                self.results["flask_issues"].append({
                    "file": str(file_path),
                    "issue_id": issue["id"],
                    "title": issue["title"],
                    "description": issue["description"],
                    "line": line_num,
                    "line_content": line_content,
                    "severity": issue["severity"]
                })
    
    def _check_code_quality(self, tree: ast.AST, file_path: Path):
        """æ£€æŸ¥ä»£ç è´¨é‡é—®é¢˜"""
        issues = []
        
        for node in ast.walk(tree):
            # æ£€æŸ¥è¿‡é•¿çš„å‡½æ•°
            if isinstance(node, ast.FunctionDef):
                if len(node.body) > 50:
                    issues.append({
                        "file": str(file_path),
                        "issue": "å‡½æ•°è¿‡é•¿",
                        "description": f"å‡½æ•° '{node.name}' æœ‰ {len(node.body)} è¡Œï¼Œå»ºè®®æ‹†åˆ†",
                        "line": node.lineno,
                        "severity": "medium"
                    })
            
            # æ£€æŸ¥å¤æ‚çš„æ¡ä»¶è¯­å¥
            elif isinstance(node, ast.If):
                if self._count_conditions(node.test) > 3:
                    issues.append({
                        "file": str(file_path),
                        "issue": "æ¡ä»¶è¯­å¥è¿‡äºå¤æ‚",
                        "description": f"ç¬¬ {node.lineno} è¡Œçš„æ¡ä»¶è¯­å¥è¿‡äºå¤æ‚",
                        "line": node.lineno,
                        "severity": "low"
                    })
            
            # æ£€æŸ¥æœªä½¿ç”¨çš„å¯¼å…¥
            elif isinstance(node, ast.Import):
                for alias in node.names:
                    if not self._is_import_used(tree, alias.name):
                        issues.append({
                            "file": str(file_path),
                            "issue": "æœªä½¿ç”¨çš„å¯¼å…¥",
                            "description": f"å¯¼å…¥çš„æ¨¡å— '{alias.name}' æœªè¢«ä½¿ç”¨",
                            "line": node.lineno,
                            "severity": "low"
                        })
        
        self.results["code_quality"].extend(issues)
    
    def _check_security_issues(self, content: str, file_path: Path):
        """æ£€æŸ¥å®‰å…¨é—®é¢˜"""
        security_patterns = [
            {
                "pattern": r"eval\s*\(",
                "issue": "ä½¿ç”¨eval()å‡½æ•°",
                "description": "eval()å‡½æ•°å­˜åœ¨å®‰å…¨é£é™©ï¼Œå»ºè®®é¿å…ä½¿ç”¨",
                "severity": "high"
            },
            {
                "pattern": r"exec\s*\(",
                "issue": "ä½¿ç”¨exec()å‡½æ•°", 
                "description": "exec()å‡½æ•°å­˜åœ¨å®‰å…¨é£é™©ï¼Œå»ºè®®é¿å…ä½¿ç”¨",
                "severity": "high"
            },
            {
                "pattern": r"os\.system\s*\(",
                "issue": "ä½¿ç”¨os.system()",
                "description": "os.system()å­˜åœ¨å‘½ä»¤æ³¨å…¥é£é™©",
                "severity": "high"
            },
            {
                "pattern": r"subprocess\.call\s*\(",
                "issue": "ä½¿ç”¨subprocess.call()",
                "description": "subprocess.call()å¯èƒ½å­˜åœ¨å®‰å…¨é£é™©ï¼Œå»ºè®®ä½¿ç”¨subprocess.run()",
                "severity": "medium"
            }
        ]
        
        lines = content.split('\n')
        
        for pattern_info in security_patterns:
            pattern = pattern_info["pattern"]
            matches = re.finditer(pattern, content, re.IGNORECASE)
            
            for match in matches:
                line_num = content[:match.start()].count('\n') + 1
                line_content = lines[line_num - 1].strip()
                
                self.results["security_issues"].append({
                    "file": str(file_path),
                    "issue": pattern_info["issue"],
                    "description": pattern_info["description"],
                    "line": line_num,
                    "line_content": line_content,
                    "severity": pattern_info["severity"]
                })
    
    def _check_performance_issues(self, content: str, file_path: Path):
        """æ£€æŸ¥æ€§èƒ½é—®é¢˜"""
        performance_patterns = [
            {
                "pattern": r"for\s+\w+\s+in\s+range\s*\(\s*len\s*\(",
                "issue": "ä½æ•ˆçš„å¾ªç¯",
                "description": "ä½¿ç”¨range(len())éå†åˆ—è¡¨æ•ˆç‡è¾ƒä½ï¼Œå»ºè®®ä½¿ç”¨enumerate()",
                "severity": "low"
            },
            {
                "pattern": r"\.append\s*\(\s*\[\s*\]\s*\)",
                "issue": "é¢‘ç¹çš„åˆ—è¡¨æ“ä½œ",
                "description": "é¢‘ç¹çš„åˆ—è¡¨appendæ“ä½œå¯èƒ½å½±å“æ€§èƒ½",
                "severity": "low"
            },
            {
                "pattern": r"import\s+\*",
                "issue": "é€šé…ç¬¦å¯¼å…¥",
                "description": "é€šé…ç¬¦å¯¼å…¥å¯èƒ½å½±å“æ€§èƒ½ï¼Œå»ºè®®æ˜ç¡®å¯¼å…¥éœ€è¦çš„æ¨¡å—",
                "severity": "low"
            }
        ]
        
        lines = content.split('\n')
        
        for pattern_info in performance_patterns:
            pattern = pattern_info["pattern"]
            matches = re.finditer(pattern, content, re.IGNORECASE)
            
            for match in matches:
                line_num = content[:match.start()].count('\n') + 1
                line_content = lines[line_num - 1].strip()
                
                self.results["performance_issues"].append({
                    "file": str(file_path),
                    "issue": pattern_info["issue"],
                    "description": pattern_info["description"],
                    "line": line_num,
                    "line_content": line_content,
                    "severity": pattern_info["severity"]
                })
    
    def _count_conditions(self, node: ast.AST) -> int:
        """è®¡ç®—æ¡ä»¶è¯­å¥çš„å¤æ‚åº¦"""
        if isinstance(node, ast.BoolOp):
            return len(node.values)
        elif isinstance(node, ast.Compare):
            return len(node.comparators) + 1
        else:
            return 1
    
    def _is_import_used(self, tree: ast.AST, module_name: str) -> bool:
        """æ£€æŸ¥å¯¼å…¥çš„æ¨¡å—æ˜¯å¦è¢«ä½¿ç”¨"""
        for node in ast.walk(tree):
            if isinstance(node, ast.Name):
                if node.id == module_name:
                    return True
            elif isinstance(node, ast.Attribute):
                if isinstance(node.value, ast.Name) and node.value.id == module_name:
                    return True
        return False
    
    def _generate_summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆåˆ†ææ€»ç»“"""
        total_issues = (
            len(self.results["flask_issues"]) +
            len(self.results["code_quality"]) +
            len(self.results["security_issues"]) +
            len(self.results["performance_issues"])
        )
        
        high_severity = sum(1 for issue in self.results["flask_issues"] if issue["severity"] == "high")
        high_severity += sum(1 for issue in self.results["security_issues"] if issue["severity"] == "high")
        
        return {
            "total_issues": total_issues,
            "high_severity_issues": high_severity,
            "flask_issues_count": len(self.results["flask_issues"]),
            "code_quality_issues_count": len(self.results["code_quality"]),
            "security_issues_count": len(self.results["security_issues"]),
            "performance_issues_count": len(self.results["performance_issues"])
        }
    
    def _get_timestamp(self) -> str:
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        import datetime
        return datetime.datetime.now().isoformat()
    
    def save_results(self, results: Dict[str, Any], output_path: str):
        """ä¿å­˜æ£€æµ‹ç»“æœ"""
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")


if __name__ == "__main__":
    runner = StaticTestRunner()
    results = runner.run_analysis(".")
    print("\n" + "="*60)
    print("é™æ€æ£€æµ‹ç»“æœ:")
    print("="*60)
    print(json.dumps(results, ensure_ascii=False, indent=2))
