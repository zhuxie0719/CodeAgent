"""
åªåŒ…å«BugDetectionAgentçš„APIæœåŠ¡
"""

import asyncio
import uuid
import os
import json
from datetime import datetime
from typing import Dict, Any, List, Optional
from pathlib import Path

from fastapi import FastAPI, File, UploadFile, HTTPException, BackgroundTasks, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
import sys
sys.path.append(str(Path(__file__).parent.parent))

# å¯¼å…¥æ–‡ä»¶åˆ†æå™¨
from file_analyzer import FileAnalyzer

try:
    from agents.bug_detection_agent.agent import BugDetectionAgent
    from config.settings import settings
except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯: {e}")
    # åˆ›å»ºä¸€ä¸ªç®€åŒ–çš„BugDetectionAgentç±»
    class BugDetectionAgent:
        def __init__(self, config):
            self.config = config
            self.status = "running"
            self.tasks = {}
            self.file_analyzer = FileAnalyzer()
        
        async def start(self):
            print("ç®€åŒ–BugDetectionAgentå¯åŠ¨")
        
        async def stop(self):
            print("ç®€åŒ–BugDetectionAgentåœæ­¢")
        
        def get_status(self):
            return {"status": "running"}
        
        async def submit_task(self, task_id, task_data):
            # å¤„ç†æ–‡ä»¶æˆ–é¡¹ç›®æ£€æµ‹
            file_path = task_data.get("file_path", "")
            analysis_type = task_data.get("analysis_type", "file")
            options = task_data.get("options", {})
            
            # å¦‚æœæ˜¯é¡¹ç›®åˆ†æï¼Œå…ˆè§£å‹é¡¹ç›®
            if analysis_type == "project":
                try:
                    # è§£å‹é¡¹ç›®æ–‡ä»¶
                    project_path = await self.extract_project(file_path)
                    # åˆ†ææ•´ä¸ªé¡¹ç›®
                    result = await self.analyze_project(project_path, options)
                except Exception as e:
                    result = {
                        "success": False,
                        "error": f"é¡¹ç›®åˆ†æå¤±è´¥: {str(e)}",
                        "detection_results": {
                            "project_path": file_path,
                            "total_issues": 0,
                            "issues": [],
                            "summary": {"error_count": 0, "warning_count": 0, "info_count": 0}
                        }
                    }
            else:
                # å•æ–‡ä»¶åˆ†æ
                result = await self.file_analyzer.analyze_file(file_path, options)
            
            # å­˜å‚¨ä»»åŠ¡ç»“æœ
            self.tasks[task_id] = {
                "task_id": task_id,
                "status": "completed",
                "created_at": datetime.now().isoformat(),
                "started_at": datetime.now().isoformat(),
                "completed_at": datetime.now().isoformat(),
                "result": result,
                "error": None
            }
            
            return task_id
        
        async def _analyze_single_file(self, file_path, options):
            """åˆ†æå•ä¸ªæ–‡ä»¶"""
            # æ ¹æ®æ–‡ä»¶ç±»å‹ç”Ÿæˆä¸åŒçš„ç»“æœ
            if file_path.endswith('.java'):
                result = {
                    "success": True,
                    "detection_results": {
                        "total_issues": 3,
                        "issues": [
                            {
                                "type": "null_pointer_dereference",
                                "severity": "error",
                                "message": "æ½œåœ¨çš„ç©ºæŒ‡é’ˆè§£å¼•ç”¨",
                                "line": 15,
                                "file": "test.java",
                                "language": "java"
                            },
                            {
                                "type": "memory_leak",
                                "severity": "warning", 
                                "message": "å¯èƒ½å­˜åœ¨å†…å­˜æ³„æ¼",
                                "line": 25,
                                "file": "test.java",
                                "language": "java"
                            }
                        ],
                        "summary": {"error_count": 1, "warning_count": 1, "info_count": 0}
                    }
                }
            elif file_path.endswith('.c') or file_path.endswith('.cpp'):
                result = {
                    "success": True,
                    "detection_results": {
                        "total_issues": 4,
                        "issues": [
                            {
                                "type": "buffer_overflow",
                                "severity": "error",
                                "message": "ç¼“å†²åŒºæº¢å‡ºé£é™©",
                                "line": 12,
                                "file": "test.c",
                                "language": "c"
                            },
                            {
                                "type": "memory_leak",
                                "severity": "warning",
                                "message": "å†…å­˜æ³„æ¼",
                                "line": 30,
                                "file": "test.c", 
                                "language": "c"
                            }
                        ],
                        "summary": {"error_count": 1, "warning_count": 1, "info_count": 0}
                    }
                }
            elif file_path.endswith('.js'):
                result = {
                    "success": True,
                    "detection_results": {
                        "total_issues": 2,
                        "issues": [
                            {
                                "type": "xss_vulnerability",
                                "severity": "error",
                                "message": "XSSæ¼æ´é£é™©",
                                "line": 8,
                                "file": "test.js",
                                "language": "javascript"
                            }
                        ],
                        "summary": {"error_count": 1, "warning_count": 0, "info_count": 0}
                    }
                }
            else:
                # Pythonæ–‡ä»¶æˆ–å…¶ä»–æ–‡ä»¶ - è¿›è¡ŒçœŸå®çš„æ–‡ä»¶åˆ†æ
                try:
                    # è¯»å–æ–‡ä»¶å†…å®¹è¿›è¡Œåˆ†æ
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                    
                    # åŸºäºæ–‡ä»¶å†…å®¹ç”Ÿæˆæ£€æµ‹ç»“æœ
                    issues = []
                    filename = os.path.basename(file_path)
                    
                    # æ£€æµ‹æœªä½¿ç”¨çš„å¯¼å…¥
                    lines = content.split('\n')
                    for i, line in enumerate(lines, 1):
                        line = line.strip()
                        if line.startswith('import ') or line.startswith('from '):
                            # ç®€å•çš„å¯¼å…¥æ£€æµ‹é€»è¾‘
                            if 'unused' in line.lower() or 'test' in line.lower():
                                issues.append({
                                    "type": "unused_import",
                                    "severity": "warning",
                                    "message": "æœªä½¿ç”¨çš„å¯¼å…¥",
                                    "line": i,
                                    "file": filename,
                                    "language": "python"
                                })
                    
                    # æ£€æµ‹ç¡¬ç¼–ç å¯†é’¥
                    if 'API_KEY' in content or 'SECRET' in content or 'PASSWORD' in content:
                        for i, line in enumerate(lines, 1):
                            if '=' in line and ('API_KEY' in line or 'SECRET' in line or 'PASSWORD' in line):
                                issues.append({
                                    "type": "hardcoded_secrets",
                                    "severity": "error",
                                    "message": "å‘ç°ç¡¬ç¼–ç çš„å¯†é’¥æˆ–å¯†ç ",
                                    "line": i,
                                    "file": filename,
                                    "language": "python"
                                })
                    
                    # æ£€æµ‹ä¸å®‰å…¨çš„evalä½¿ç”¨
                    if 'eval(' in content:
                        for i, line in enumerate(lines, 1):
                            if 'eval(' in line:
                                issues.append({
                                    "type": "unsafe_eval",
                                    "severity": "error",
                                    "message": "ä¸å®‰å…¨çš„evalä½¿ç”¨",
                                    "line": i,
                                    "file": filename,
                                    "language": "python"
                                })
                   
                    # æ£€æµ‹ç¼ºå°‘æ–‡æ¡£å­—ç¬¦ä¸²çš„å‡½æ•°
                    in_function = False
                    for i, line in enumerate(lines, 1):
                        if line.strip().startswith('def ') and not in_function:
                            in_function = True
                            # æ£€æŸ¥ä¸‹ä¸€è¡Œæ˜¯å¦æœ‰æ–‡æ¡£å­—ç¬¦ä¸²
                            if i < len(lines) and not lines[i].strip().startswith('"""') and not lines[i].strip().startswith("'''"):
                                issues.append({
                                    "type": "missing_docstring",
                                    "severity": "info",
                                    "message": "å‡½æ•°ç¼ºå°‘æ–‡æ¡£å­—ç¬¦ä¸²",
                                    "line": i,
                                    "file": filename,
                                    "language": "python"
                                })
                        elif line.strip() and not line.startswith(' ') and not line.startswith('\t'):
                            in_function = False
                    
                    # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°é—®é¢˜ï¼Œæ·»åŠ ä¸€ä¸ªé»˜è®¤çš„æç¤º
                    if not issues:
                        issues.append({
                            "type": "code_quality",
                            "severity": "info",
                            "message": "ä»£ç è´¨é‡è‰¯å¥½ï¼Œæœªå‘ç°æ˜æ˜¾é—®é¢˜",
                            "line": 1,
                            "file": filename,
                            "language": "python"
                        })
                    
                    result = {
                        "success": True,
                        "detection_results": {
                            "file_path": file_path,
                            "language": "python",
                            "total_issues": len(issues),
                            "issues": issues,
                            "detection_tools": ["custom_analyzer"],
                            "analysis_time": 0.5,
                            "summary": {
                                "error_count": sum(1 for issue in issues if issue["severity"] == "error"),
                                "warning_count": sum(1 for issue in issues if issue["severity"] == "warning"),
                                "info_count": sum(1 for issue in issues if issue["severity"] == "info")
                            }
                        }
                    }
                    
                except Exception as e:
                    # å¦‚æœåˆ†æå¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
                    result = {
                        "success": False,
                        "error": f"Pythonæ–‡ä»¶åˆ†æå¤±è´¥: {str(e)}",
                        "detection_results": {
                            "file_path": file_path,
                            "language": "python",
                            "total_issues": 0,
                            "issues": [],
                            "summary": {"error_count": 0, "warning_count": 0, "info_count": 0}
                        }
                    }
            
            # å­˜å‚¨ä»»åŠ¡ç»“æœ
            self.tasks[task_id] = {
                "task_id": task_id,
                "status": "completed",
                "created_at": datetime.now().isoformat(),
                "started_at": datetime.now().isoformat(),
                "completed_at": datetime.now().isoformat(),
                "result": result,
                "error": None
            }
            
            return task_id
        
        async def extract_project(self, file_path):
            """è§£å‹é¡¹ç›®æ–‡ä»¶"""
            import zipfile
            import tarfile
            import shutil
            import tempfile
            
            file_path = Path(file_path)
            extract_dir = Path("temp_extract") / f"project_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            extract_dir.mkdir(parents=True, exist_ok=True)
            
            try:
                if file_path.suffix.lower() == '.zip':
                    with zipfile.ZipFile(file_path, 'r') as zip_ref:
                        zip_ref.extractall(extract_dir)
                elif file_path.suffix.lower() in ['.tar', '.tar.gz']:
                    with tarfile.open(file_path, 'r:*') as tar_ref:
                        tar_ref.extractall(extract_dir)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path.suffix}")
                
                print(f"é¡¹ç›®è§£å‹åˆ°: {extract_dir}")
                return str(extract_dir)
                
            except Exception as e:
                print(f"é¡¹ç›®è§£å‹å¤±è´¥: {e}")
                raise
        
        async def analyze_project(self, project_path, options):
            """åˆ†ææ•´ä¸ªé¡¹ç›®"""
            try:
                print(f"å¼€å§‹åˆ†æé¡¹ç›®: {project_path}")
                
                # æ‰«æé¡¹ç›®æ–‡ä»¶
                files_by_language = self.scan_project_files(project_path)
                
                if not files_by_language:
                    return {
                        "success": False,
                        "error": "æœªæ‰¾åˆ°æ”¯æŒçš„ä»£ç æ–‡ä»¶",
                        "detection_results": {
                            "project_path": project_path,
                            "total_issues": 0,
                            "issues": [],
                            "summary": {"error_count": 0, "warning_count": 0, "info_count": 0}
                        }
                    }
                
                # åˆ†ææ‰€æœ‰æ–‡ä»¶
                all_results = []
                total_files = sum(len(files) for files in files_by_language.values())
                
                # é™åˆ¶åˆ†æçš„æ–‡ä»¶æ•°é‡
                max_files = 50
                files_analyzed = 0
                
                for language, files in files_by_language.items():
                    print(f"åˆ†æ {language} æ–‡ä»¶: {len(files)} ä¸ª")
                    
                    for file_path in files:
                        if files_analyzed >= max_files:
                            break
                        try:
                            # åˆ†æå•ä¸ªæ–‡ä»¶
                            file_result = await self.file_analyzer.analyze_file(file_path, options)
                            if file_result and file_result.get("success"):
                                all_results.append(file_result["detection_results"])
                                files_analyzed += 1
                        except Exception as e:
                            print(f"åˆ†ææ–‡ä»¶å¤±è´¥ {file_path}: {e}")
                
                # åˆå¹¶æ‰€æœ‰ç»“æœ
                combined_result = self._combine_project_results(all_results, project_path)
                
                print(f"é¡¹ç›®åˆ†æå®Œæˆï¼Œå…±åˆ†æ {files_analyzed} ä¸ªæ–‡ä»¶")
                return {
                    "success": True,
                    "detection_results": combined_result
                }
                
            except Exception as e:
                print(f"é¡¹ç›®åˆ†æå¤±è´¥: {e}")
                return {
                    "success": False,
                    "error": str(e),
                    "detection_results": {
                        "project_path": project_path,
                        "total_issues": 0,
                        "issues": [],
                        "summary": {"error_count": 0, "warning_count": 0, "info_count": 0}
                    }
                }
        
        def scan_project_files(self, project_path):
            """æ‰«æé¡¹ç›®ä¸­çš„ä»£ç æ–‡ä»¶"""
            try:
                project_path = Path(project_path)
                files_by_language = {
                    "python": [],
                    "java": [],
                    "c": [],
                    "cpp": [],
                    "javascript": [],
                    "go": []
                }
                
                # æ”¯æŒçš„æ–‡ä»¶æ‰©å±•å
                extensions = {
                    "python": [".py", ".pyw", ".pyi"],
                    "java": [".java"],
                    "c": [".c", ".h"],
                    "cpp": [".cpp", ".cc", ".cxx", ".hpp", ".hxx"],
                    "javascript": [".js", ".jsx", ".ts", ".tsx"],
                    "go": [".go"]
                }
                
                for language, ext_list in extensions.items():
                    for extension in ext_list:
                        # é€’å½’æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶
                        for file_path in project_path.rglob(f"*{extension}"):
                            # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆé™åˆ¶10MBï¼‰
                            if file_path.stat().st_size <= 10 * 1024 * 1024:
                                files_by_language[language].append(str(file_path))
                
                # è¿‡æ»¤æ‰ç©ºçš„è¯­è¨€
                files_by_language = {k: v for k, v in files_by_language.items() if v}
                
                print(f"æ‰«æåˆ°æ–‡ä»¶: {sum(len(files) for files in files_by_language.values())} ä¸ª")
                for language, files in files_by_language.items():
                    print(f"  {language}: {len(files)} ä¸ªæ–‡ä»¶")
                
                return files_by_language
                
            except Exception as e:
                print(f"é¡¹ç›®æ–‡ä»¶æ‰«æå¤±è´¥: {e}")
                return {}
        
        def _combine_project_results(self, results, project_path):
            """åˆå¹¶é¡¹ç›®åˆ†æç»“æœ"""
            try:
                all_issues = []
                total_files = len(results)
                analysis_time = 0
                detection_tools = set()
                files_analyzed = []
                
                for result in results:
                    if result and "issues" in result:
                        all_issues.extend(result["issues"])
                        analysis_time += result.get("analysis_time", 0)
                        detection_tools.update(result.get("detection_tools", []))
                        
                        # è®°å½•åˆ†æçš„æ–‡ä»¶ä¿¡æ¯
                        file_info = {
                            "file_path": result.get("file_path", ""),
                            "language": result.get("language", "unknown"),
                            "total_issues": result.get("total_issues", 0),
                            "issues": result.get("issues", [])
                        }
                        files_analyzed.append(file_info)
                
                # æŒ‰ä¸¥é‡æ€§æ’åº
                severity_levels = {"error": 1, "warning": 2, "info": 3}
                all_issues.sort(key=lambda x: severity_levels.get(x.get("severity", "info"), 3))
                
                combined_result = {
                    "project_path": project_path,
                    "total_files": total_files,
                    "total_issues": len(all_issues),
                    "issues": all_issues,
                    "files_analyzed": files_analyzed,  # æ·»åŠ æ–‡ä»¶åˆ—è¡¨
                    "detection_tools": list(detection_tools),
                    "analysis_time": analysis_time,
                    "summary": {
                        "error_count": sum(1 for issue in all_issues if issue.get("severity") == "error"),
                        "warning_count": sum(1 for issue in all_issues if issue.get("severity") == "warning"),
                        "info_count": sum(1 for issue in all_issues if issue.get("severity") == "info")
                    },
                    "languages_detected": list(set(issue.get("language", "unknown") for issue in all_issues))
                }
                
                return combined_result
                
            except Exception as e:
                print(f"åˆå¹¶é¡¹ç›®ç»“æœå¤±è´¥: {e}")
                return {
                    "project_path": project_path,
                    "total_files": 0,
                    "total_issues": 0,
                    "issues": [],
                    "files_analyzed": [],
                    "error": str(e)
                }
        
        async def get_task_status(self, task_id):
            task = self.tasks.get(task_id)
            if task:
                return task
            else:
                return {
                    "task_id": task_id,
                    "status": "pending",
                    "created_at": datetime.now().isoformat(),
                    "started_at": None,
                    "completed_at": None,
                    "result": None,
                    "error": None
                }
    
    # ç®€åŒ–çš„è®¾ç½®
    class Settings:
        AGENTS = {"bug_detection_agent": {"enabled": True}}
    
    settings = Settings()


# æ•°æ®æ¨¡å‹
class BaseResponse(BaseModel):
    """åŸºç¡€å“åº”æ¨¡å‹"""
    success: bool = Field(True, description="æ˜¯å¦æˆåŠŸ")
    message: str = Field("æ“ä½œæˆåŠŸ", description="å“åº”æ¶ˆæ¯")
    timestamp: str = Field(default_factory=lambda: datetime.now().isoformat(), description="æ—¶é—´æˆ³")
    data: Optional[Dict[str, Any]] = Field(None, description="å“åº”æ•°æ®")


class HealthResponse(BaseModel):
    """å¥åº·æ£€æŸ¥å“åº”æ¨¡å‹"""
    status: str = Field(..., description="æœåŠ¡çŠ¶æ€")
    message: str = Field(..., description="çŠ¶æ€æ¶ˆæ¯")
    timestamp: str = Field(default_factory=lambda: datetime.now().isoformat(), description="æ—¶é—´æˆ³")


# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="AI Agent ç¼ºé™·æ£€æµ‹ API",
    description="ä¸“æ³¨äºç¼ºé™·æ£€æµ‹çš„APIæœåŠ¡",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€BugDetectionAgentå®ä¾‹
bug_detection_agent = None

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨äº‹ä»¶"""
    global bug_detection_agent
    try:
        config = settings.AGENTS.get("bug_detection_agent", {})
        bug_detection_agent = BugDetectionAgent(config)
        await bug_detection_agent.start()
        print("BugDetectionAgent å¯åŠ¨æˆåŠŸ")
    except Exception as e:
        print(f"BugDetectionAgent å¯åŠ¨å¤±è´¥: {e}")

@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­äº‹ä»¶"""
    global bug_detection_agent
    if bug_detection_agent:
        await bug_detection_agent.stop()
        print("BugDetectionAgent å·²åœæ­¢")

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    global bug_detection_agent
    
    if bug_detection_agent:
        agent_status = bug_detection_agent.get_status()
        return HealthResponse(
            status="healthy",
            message=f"APIæœåŠ¡è¿è¡Œæ­£å¸¸ï¼ŒAgentçŠ¶æ€: {agent_status['status']}",
            timestamp=datetime.now().isoformat()
        )
    else:
        return HealthResponse(
            status="error",
            message="BugDetectionAgent æœªå¯åŠ¨",
            timestamp=datetime.now().isoformat()
        )

@app.post("/api/v1/detection/upload", response_model=BaseResponse)
async def upload_file_for_detection(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    enable_static: bool = Query(True, description="å¯ç”¨è‡ªå®šä¹‰é™æ€æ£€æµ‹"),
    enable_pylint: bool = Query(True, description="å¯ç”¨Pylintæ£€æµ‹"),
    enable_flake8: bool = Query(True, description="å¯ç”¨Flake8æ£€æµ‹"),
    enable_ai_analysis: bool = Query(True, description="å¯ç”¨AIåˆ†æ"),
    analysis_type: str = Query("file", description="åˆ†æç±»å‹: file(å•æ–‡ä»¶) æˆ– project(é¡¹ç›®)")
):
    """ä¸Šä¼ æ–‡ä»¶è¿›è¡Œç¼ºé™·æ£€æµ‹ - æ”¯æŒå¤æ‚é¡¹ç›®å‹ç¼©åŒ…"""
    global bug_detection_agent
    
    if not bug_detection_agent:
        raise HTTPException(status_code=500, detail="BugDetectionAgent æœªå¯åŠ¨")
    
    # éªŒè¯æ–‡ä»¶å¤§å°
    content = await file.read()
    file_size = len(content)
    
    # æ ¹æ®åˆ†æç±»å‹è®¾ç½®ä¸åŒçš„é™åˆ¶
    if analysis_type == "project":
        max_size = 100 * 1024 * 1024  # 100MB for projects
        supported_extensions = ['.zip', '.tar', '.tar.gz', '.rar', '.7z']
    else:
        max_size = 10 * 1024 * 1024  # 10MB for single files
        supported_extensions = ['.py', '.java', '.c', '.cpp', '.h', '.hpp', '.js', '.ts', '.go']
    
    if file_size > max_size:
        raise HTTPException(status_code=413, detail=f"æ–‡ä»¶è¿‡å¤§ï¼Œæœ€å¤§æ”¯æŒ{max_size // (1024*1024)}MB")
    
    # éªŒè¯æ–‡ä»¶ç±»å‹
    file_extension = Path(file.filename).suffix.lower()
    if file_extension not in supported_extensions:
        raise HTTPException(
            status_code=400, 
            detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ã€‚æ”¯æŒçš„ç±»å‹: {', '.join(supported_extensions)}"
        )
    
    # ä¿å­˜æ–‡ä»¶
    upload_dir = Path("uploads")
    upload_dir.mkdir(exist_ok=True)
    file_path = upload_dir / f"{file.filename}"
    
    with open(file_path, "wb") as f:
        f.write(content)
    
    # åˆ›å»ºæ£€æµ‹ä»»åŠ¡
    task_data = {
        "file_path": str(file_path),
        "analysis_type": analysis_type,
        "options": {
            "enable_static": enable_static,
            "enable_pylint": enable_pylint,
            "enable_flake8": enable_flake8,
            "enable_ai_analysis": enable_ai_analysis
        }
    }
    
    try:
        task_id = await bug_detection_agent.submit_task(f"task_{uuid.uuid4().hex[:12]}", task_data)
        
        # åœ¨åå°ç”Ÿæˆå¯ä¸‹è½½æŠ¥å‘Šå’Œç»“æ„åŒ–ä¿¡æ¯å­˜å‚¨
        background_tasks.add_task(generate_report_task, task_id, str(file_path))
        background_tasks.add_task(store_structured_data, task_id, str(file_path), analysis_type)
        
        return BaseResponse(
            message="æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œå¼€å§‹æ£€æµ‹",
            data={
                "task_id": task_id,
                "filename": file.filename,
                "file_size": file_size,
                "agent_id": "bug_detection_agent",
                "analysis_type": analysis_type
            }
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æäº¤æ£€æµ‹ä»»åŠ¡å¤±è´¥: {str(e)}")

@app.get("/api/v1/tasks/{task_id}", response_model=BaseResponse)
async def get_task_status(task_id: str):
    """è·å–ä»»åŠ¡çŠ¶æ€"""
    global bug_detection_agent
    
    if not bug_detection_agent:
        raise HTTPException(status_code=500, detail="BugDetectionAgent æœªå¯åŠ¨")
    
    try:
        task_status = await bug_detection_agent.get_task_status(task_id)
        if not task_status:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
        
        return BaseResponse(
            message="è·å–ä»»åŠ¡çŠ¶æ€æˆåŠŸ",
            data=task_status
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")

@app.get("/api/v1/detection/rules", response_model=BaseResponse)
async def get_detection_rules():
    """è·å–æ£€æµ‹è§„åˆ™"""
    global bug_detection_agent
    
    if not bug_detection_agent:
        raise HTTPException(status_code=500, detail="BugDetectionAgent æœªå¯åŠ¨")
    
    try:
        rules = await bug_detection_agent.get_detection_rules()
        
        return BaseResponse(
            message="è·å–æ£€æµ‹è§„åˆ™æˆåŠŸ",
            data=rules
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æ£€æµ‹è§„åˆ™å¤±è´¥: {str(e)}")

@app.get("/api/v1/ai-reports/{task_id}")
async def get_ai_report(task_id: str):
    """è·å–AIç”Ÿæˆçš„è‡ªç„¶è¯­è¨€æŠ¥å‘Š"""
    global bug_detection_agent
    
    if not bug_detection_agent:
        raise HTTPException(status_code=500, detail="BugDetectionAgent æœªå¯åŠ¨")
    
    try:
        # è·å–ä»»åŠ¡çŠ¶æ€
        task_status = await bug_detection_agent.get_task_status(task_id)
        if not task_status:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
        
        if task_status.get("status") != "completed":
            raise HTTPException(status_code=400, detail="ä»»åŠ¡å°šæœªå®Œæˆ")
        
        # æ£€æŸ¥AIæŠ¥å‘Šæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        ai_report_path = Path("reports") / f"ai_report_{task_id}.md"
        
        if ai_report_path.exists():
            # è¯»å–AIæŠ¥å‘Šå†…å®¹
            with open(ai_report_path, 'r', encoding='utf-8') as f:
                ai_report_content = f.read()
            
            return BaseResponse(
                message="è·å–AIæŠ¥å‘ŠæˆåŠŸ",
                data={
                    "task_id": task_id,
                    "ai_report": ai_report_content,
                    "report_type": "markdown"
                }
            )
        else:
            # å¦‚æœæ²¡æœ‰AIæŠ¥å‘Šæ–‡ä»¶ï¼Œå®æ—¶ç”Ÿæˆä¸€ä¸ª
            detection_results = task_status.get("result", {}).get("detection_results", {})
            file_path = task_status.get("result", {}).get("file_path", "")
            
            if detection_results:
                ai_report = await generate_ai_report(detection_results, file_path)
                return BaseResponse(
                    message="è·å–AIæŠ¥å‘ŠæˆåŠŸ",
                    data={
                        "task_id": task_id,
                        "ai_report": ai_report,
                        "report_type": "markdown"
                    }
                )
            else:
                raise HTTPException(status_code=404, detail="æ£€æµ‹ç»“æœä¸å­˜åœ¨")
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–AIæŠ¥å‘Šå¤±è´¥: {str(e)}")

@app.get("/api/v1/reports/{task_id}")
async def download_report(task_id: str):
    """ä¸‹è½½æ£€æµ‹æŠ¥å‘Š"""
    global bug_detection_agent
    
    if not bug_detection_agent:
        raise HTTPException(status_code=500, detail="BugDetectionAgent æœªå¯åŠ¨")
    
    try:
        # è·å–ä»»åŠ¡çŠ¶æ€
        task_status = await bug_detection_agent.get_task_status(task_id)
        if not task_status:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
        
        if task_status.get("status") != "completed":
            raise HTTPException(status_code=400, detail="ä»»åŠ¡å°šæœªå®Œæˆ")
        
        # ç”ŸæˆæŠ¥å‘Š
        detection_results = task_status.get("result", {}).get("detection_results", {})
        file_path = task_status.get("result", {}).get("file_path", "")
        
        if not detection_results:
            raise HTTPException(status_code=404, detail="æ£€æµ‹ç»“æœä¸å­˜åœ¨")
        
        # æ£€æŸ¥BugDetectionAgentæ˜¯å¦æœ‰generate_downloadable_reportæ–¹æ³•
        if hasattr(bug_detection_agent, 'generate_downloadable_report'):
            report_path = await bug_detection_agent.generate_downloadable_report(detection_results, file_path)
        else:
            # å¦‚æœæ²¡æœ‰è¯¥æ–¹æ³•ï¼Œåˆ›å»ºä¸€ä¸ªç®€åŒ–çš„æŠ¥å‘Š
            report_path = await create_simple_report(detection_results, file_path, task_id)
        
        if not report_path or not Path(report_path).exists():
            raise HTTPException(status_code=404, detail="æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨")
        
        # è¿”å›æ–‡ä»¶
        from fastapi.responses import FileResponse
        return FileResponse(
            path=report_path,
            filename=f"bug_detection_report_{task_id}.json",
            media_type="application/json"
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ä¸‹è½½æŠ¥å‘Šå¤±è´¥: {str(e)}")

@app.get("/api/v1/ai-reports/{task_id}/download")
async def download_ai_report(task_id: str):
    """ä¸‹è½½AIç”Ÿæˆçš„è‡ªç„¶è¯­è¨€æŠ¥å‘Š"""
    global bug_detection_agent
    
    if not bug_detection_agent:
        raise HTTPException(status_code=500, detail="BugDetectionAgent æœªå¯åŠ¨")
    
    try:
        # æ£€æŸ¥AIæŠ¥å‘Šæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        ai_report_path = Path("reports") / f"ai_report_{task_id}.md"
        
        if not ai_report_path.exists():
            # å¦‚æœæ²¡æœ‰AIæŠ¥å‘Šæ–‡ä»¶ï¼Œç”Ÿæˆä¸€ä¸ª
            task_status = await bug_detection_agent.get_task_status(task_id)
            if not task_status or task_status.get("status") != "completed":
                raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨æˆ–æœªå®Œæˆ")
            
            detection_results = task_status.get("result", {}).get("detection_results", {})
            file_path = task_status.get("result", {}).get("file_path", "")
            
            if not detection_results:
                raise HTTPException(status_code=404, detail="æ£€æµ‹ç»“æœä¸å­˜åœ¨")
            
            # ç”ŸæˆAIæŠ¥å‘Š
            ai_report = await generate_ai_report(detection_results, file_path)
            
            # ä¿å­˜AIæŠ¥å‘Š
            ai_report_path.parent.mkdir(exist_ok=True)
            with open(ai_report_path, 'w', encoding='utf-8') as f:
                f.write(ai_report)
        
        # è¿”å›æ–‡ä»¶
        from fastapi.responses import FileResponse
        return FileResponse(
            path=ai_report_path,
            filename=f"ai_report_{task_id}.md",
            media_type="text/markdown"
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ä¸‹è½½AIæŠ¥å‘Šå¤±è´¥: {str(e)}")

@app.get("/api/v1/structured-data/{task_id}", response_model=BaseResponse)
async def get_structured_data(task_id: str):
    """è·å–ç»“æ„åŒ–æ•°æ®ç»™ä¿®å¤agent"""
    try:
        # æ£€æŸ¥ç»“æ„åŒ–æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        structured_file = Path("structured_data") / f"structured_data_{task_id}.json"
        
        if not structured_file.exists():
            raise HTTPException(status_code=404, detail="ç»“æ„åŒ–æ•°æ®ä¸å­˜åœ¨")
        
        # è¯»å–ç»“æ„åŒ–æ•°æ®
        with open(structured_file, 'r', encoding='utf-8') as f:
            structured_data = json.load(f)
        
        return BaseResponse(
            message="è·å–ç»“æ„åŒ–æ•°æ®æˆåŠŸ",
            data=structured_data
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–ç»“æ„åŒ–æ•°æ®å¤±è´¥: {str(e)}")

@app.get("/api/v1/structured-data/{task_id}/download")
async def download_structured_data(task_id: str):
    """ä¸‹è½½ç»“æ„åŒ–æ•°æ®æ–‡ä»¶"""
    try:
        # æ£€æŸ¥ç»“æ„åŒ–æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        structured_file = Path("structured_data") / f"structured_data_{task_id}.json"
        
        if not structured_file.exists():
            raise HTTPException(status_code=404, detail="ç»“æ„åŒ–æ•°æ®ä¸å­˜åœ¨")
        
        # è¿”å›æ–‡ä»¶
        from fastapi.responses import FileResponse
        return FileResponse(
            path=structured_file,
            filename=f"structured_data_{task_id}.json",
            media_type="application/json"
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ä¸‹è½½ç»“æ„åŒ–æ•°æ®å¤±è´¥: {str(e)}")

async def create_simple_report(detection_results: Dict[str, Any], file_path: str, task_id: str) -> str:
    """åˆ›å»ºç®€åŒ–çš„æ£€æµ‹æŠ¥å‘Š"""
    try:
        # åˆ›å»ºæŠ¥å‘Šç›®å½•
        report_dir = Path("reports")
        report_dir.mkdir(exist_ok=True)
        
        # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"bug_detection_report_{timestamp}.json"
        report_path = report_dir / filename
        
        # ç”ŸæˆæŠ¥å‘Šå†…å®¹
        report_data = {
            "report_info": {
                "generated_at": datetime.now().isoformat(),
                "file_path": file_path,
                "task_id": task_id,
                "total_issues": detection_results.get("total_issues", 0),
                "summary": detection_results.get("summary", {}),
                "detection_tools": detection_results.get("detection_tools", [])
            },
            "issues": detection_results.get("issues", []),
            "statistics": {
                "by_severity": _get_issues_by_severity(detection_results.get("issues", [])),
                "by_type": _get_issues_by_type(detection_results.get("issues", [])),
            }
        }
        
        # ä¿å­˜æŠ¥å‘Š
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)
        
        print(f"ç®€åŒ–æ£€æµ‹æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        return str(report_path)
        
    except Exception as e:
        print(f"ç”Ÿæˆç®€åŒ–æŠ¥å‘Šå¤±è´¥: {e}")
        return None

def _get_issues_by_severity(issues: List[Dict[str, Any]]) -> Dict[str, int]:
    """æŒ‰ä¸¥é‡æ€§ç»Ÿè®¡é—®é¢˜"""
    severity_count = {}
    for issue in issues:
        severity = issue.get("severity", "info")
        severity_count[severity] = severity_count.get(severity, 0) + 1
    return severity_count

def _get_issues_by_type(issues: List[Dict[str, Any]]) -> Dict[str, int]:
    """æŒ‰ç±»å‹ç»Ÿè®¡é—®é¢˜"""
    type_count = {}
    for issue in issues:
        issue_type = issue.get("type", "unknown")
        type_count[issue_type] = type_count.get(issue_type, 0) + 1
    return type_count

async def generate_ai_report(detection_results: Dict[str, Any], file_path: str) -> str:
    """ä½¿ç”¨AIç”Ÿæˆè‡ªç„¶è¯­è¨€æŠ¥å‘Š"""
    try:
        import requests
        
        # å‡†å¤‡æ£€æµ‹æ•°æ®
        issues = detection_results.get("issues", [])
        summary = detection_results.get("summary", {})
        
        # æ„å»ºæç¤ºè¯
        prompt = f"""
è¯·åˆ†æä»¥ä¸‹Pythonä»£ç æ£€æµ‹ç»“æœï¼Œç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„ä¸­æ–‡è‡ªç„¶è¯­è¨€æŠ¥å‘Šï¼š

æ–‡ä»¶è·¯å¾„: {file_path}
æ£€æµ‹æ‘˜è¦: é”™è¯¯ {summary.get('error_count', 0)} ä¸ªï¼Œè­¦å‘Š {summary.get('warning_count', 0)} ä¸ªï¼Œä¿¡æ¯ {summary.get('info_count', 0)} ä¸ª

æ£€æµ‹åˆ°çš„é—®é¢˜:
"""
        
        for i, issue in enumerate(issues[:10], 1):  # åªå–å‰10ä¸ªé—®é¢˜
            prompt += f"""
{i}. ç±»å‹: {issue.get('type', 'unknown')}
   ä¸¥é‡æ€§: {issue.get('severity', 'info')}
   ä½ç½®: ç¬¬ {issue.get('line', 0)} è¡Œ
   æè¿°: {issue.get('message', '')}
"""
        
        prompt += """

è¯·ç”Ÿæˆä¸€ä»½åŒ…å«ä»¥ä¸‹å†…å®¹çš„ä¸“ä¸šæŠ¥å‘Šï¼š
1. ä»£ç è´¨é‡æ€»ä½“è¯„ä¼°
2. ä¸»è¦é—®é¢˜åˆ†æå’Œè¯­æ³•é”™è¯¯
3. æ”¹è¿›å»ºè®®
4. ä¼˜å…ˆçº§æ’åº

æŠ¥å‘Šè¦æ±‚ï¼š
- ä½¿ç”¨ä¸“ä¸šçš„æŠ€æœ¯è¯­è¨€
- æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®
- æŒ‰é‡è¦æ€§æ’åºé—®é¢˜
- è¯­è¨€ç®€æ´æ˜äº†
"""
        
        # è°ƒç”¨DeepSeek API 
        ai_report = await call_deepseek_api(prompt)
        
        return ai_report
        
    except Exception as e:
        print(f"ç”ŸæˆAIæŠ¥å‘Šå¤±è´¥: {e}")
        return "AIæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚"

async def call_deepseek_api(prompt: str) -> str:
    """è°ƒç”¨DeepSeek APIç”ŸæˆæŠ¥å‘Š"""
    try:
        from deepseek_config import deepseek_config
        import aiohttp
        
        # æ£€æŸ¥æ˜¯å¦é…ç½®äº†APIå¯†é’¥
        if not deepseek_config.is_configured():
            print("âš ï¸ APIå¯†é’¥æœªé…ç½®ï¼Œä½¿ç”¨æ¨¡æ‹ŸæŠ¥å‘Š")
            return generate_mock_ai_report(prompt)
        
        print("ğŸ¤– è°ƒç”¨DeepSeek APIç”ŸæˆçœŸå®AIæŠ¥å‘Š...")
        print(f"APIå¯†é’¥: {deepseek_config.api_key[:10]}...{deepseek_config.api_key[-10:]}")
        
        # æ„å»ºè¯·æ±‚æ•°æ®
        request_data = {
            "model": deepseek_config.model,
            "messages": [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç è´¨é‡åˆ†æä¸“å®¶ï¼Œæ“…é•¿åˆ†æPythonä»£ç é—®é¢˜å¹¶æä¾›æ”¹è¿›å»ºè®®ã€‚è¯·ç”¨ä¸“ä¸šã€ç®€æ´çš„ä¸­æ–‡å›ç­”ã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "max_tokens": deepseek_config.max_tokens,
            "temperature": deepseek_config.temperature
        }
        
        # è°ƒç”¨DeepSeek API
        async with aiohttp.ClientSession() as session:
            async with session.post(
                f"{deepseek_config.base_url}/chat/completions",
                headers=deepseek_config.get_headers(),
                json=request_data,
                timeout=aiohttp.ClientTimeout(total=30)
            ) as response:
                print(f"ğŸ“Š APIå“åº”çŠ¶æ€: {response.status}")
                
                if response.status == 200:
                    result = await response.json()
                    ai_response = result["choices"][0]["message"]["content"]
                    print("âœ… çœŸå®AIæŠ¥å‘Šç”ŸæˆæˆåŠŸï¼")
                    return ai_response
                elif response.status == 402:
                    print("âš ï¸ DeepSeek APIä½™é¢ä¸è¶³ï¼Œä½¿ç”¨æ¨¡æ‹ŸæŠ¥å‘Š")
                    return generate_mock_ai_report(prompt)
                else:
                    error_text = await response.text()
                    print(f"âš ï¸ DeepSeek APIè°ƒç”¨å¤±è´¥: {response.status} - {error_text}")
                    return generate_mock_ai_report(prompt)
    
    except Exception as e:
        print(f"âš ï¸ è°ƒç”¨DeepSeek APIå¤±è´¥: {e}ï¼Œä½¿ç”¨æ¨¡æ‹ŸæŠ¥å‘Š")
        return generate_mock_ai_report(prompt)

def generate_mock_ai_report(prompt: str) -> str:
    """ç”Ÿæˆæ¨¡æ‹Ÿçš„AIæŠ¥å‘Š"""
    # ä»promptä¸­æå–é—®é¢˜æ•°é‡
    issues_count = len(prompt.split('é—®é¢˜:')) - 1 if 'é—®é¢˜:' in prompt else 0
    
    return f"""
# ä»£ç è´¨é‡æ£€æµ‹æŠ¥å‘Š

## æ€»ä½“è¯„ä¼°
æ ¹æ®é™æ€ä»£ç åˆ†æç»“æœï¼Œæ‚¨çš„ä»£ç æ•´ä½“è´¨é‡{'è‰¯å¥½' if issues_count < 3 else 'éœ€è¦æ”¹è¿›'}ã€‚æ£€æµ‹å‘ç°äº†{issues_count}ä¸ªæ½œåœ¨é—®é¢˜ï¼Œå»ºè®®åŠæ—¶ä¿®å¤ã€‚

## ä¸»è¦é—®é¢˜åˆ†æ
1. **ä»£ç è§„èŒƒé—®é¢˜**: å‘ç°äº†ä¸€äº›å‘½åå’Œæ ¼å¼é—®é¢˜ï¼Œå»ºè®®ä½¿ç”¨ä»£ç æ ¼å¼åŒ–å·¥å…·
2. **æ½œåœ¨å®‰å…¨é£é™©**: æ£€æµ‹åˆ°å¯èƒ½å­˜åœ¨å®‰å…¨æ¼æ´çš„ä»£ç æ¨¡å¼
3. **æ€§èƒ½ä¼˜åŒ–**: éƒ¨åˆ†ä»£ç å¯èƒ½å­˜åœ¨æ€§èƒ½ç“¶é¢ˆ

## æ”¹è¿›å»ºè®®
1. ç«‹å³ä¿®å¤æ‰€æœ‰é”™è¯¯çº§åˆ«çš„é—®é¢˜
2. é€æ­¥æ”¹è¿›è­¦å‘Šçº§åˆ«çš„é—®é¢˜
3. è€ƒè™‘é‡æ„å¤æ‚åº¦è¿‡é«˜çš„å‡½æ•°
4. æ·»åŠ é€‚å½“çš„é”™è¯¯å¤„ç†æœºåˆ¶

## ä¼˜å…ˆçº§æ’åº
- ğŸ”´ é«˜ä¼˜å…ˆçº§: å®‰å…¨ç›¸å…³é—®é¢˜å’Œé”™è¯¯
- ğŸŸ¡ ä¸­ä¼˜å…ˆçº§: ä»£ç è´¨é‡å’Œæ€§èƒ½é—®é¢˜  
- ğŸŸ¢ ä½ä¼˜å…ˆçº§: ä»£ç é£æ ¼å’Œæ–‡æ¡£é—®é¢˜

å»ºè®®å®šæœŸè¿›è¡Œä»£ç å®¡æŸ¥ï¼Œä¿æŒä»£ç è´¨é‡ã€‚

---
*æ³¨ï¼šè¿™æ˜¯æ¨¡æ‹Ÿçš„AIæŠ¥å‘Šã€‚è¦ä½¿ç”¨çœŸå®çš„AIåˆ†æï¼Œè¯·é…ç½®DeepSeek APIå¯†é’¥ã€‚*
"""

async def generate_report_task(task_id: str, file_path: str):
    """åå°ä»»åŠ¡ï¼šç”Ÿæˆæ£€æµ‹æŠ¥å‘Š"""
    global bug_detection_agent
    
    try:
        # ç­‰å¾…ä»»åŠ¡å®Œæˆ
        max_wait_time = 300  # 5åˆ†é’Ÿ
        wait_interval = 2    # 2ç§’
        waited_time = 0
        
        while waited_time < max_wait_time:
            task_status = await bug_detection_agent.get_task_status(task_id)
            if task_status and task_status.get("status") == "completed":
                break
            await asyncio.sleep(wait_interval)
            waited_time += wait_interval
        
        if waited_time >= max_wait_time:
            print(f"ä»»åŠ¡ {task_id} è¶…æ—¶ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š")
            return
        
        # ç”ŸæˆæŠ¥å‘Š
        detection_results = task_status.get("result", {}).get("detection_results", {})
        if detection_results:
            # ç”ŸæˆJSONæŠ¥å‘Š
            if hasattr(bug_detection_agent, 'generate_downloadable_report'):
                report_path = await bug_detection_agent.generate_downloadable_report(detection_results, file_path)
            else:
                report_path = await create_simple_report(detection_results, file_path, task_id)
            
            if report_path:
                print(f"JSONæŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
            
            # ç”ŸæˆAIè‡ªç„¶è¯­è¨€æŠ¥å‘Š
            ai_report = await generate_ai_report(detection_results, file_path)
            
            # ä¿å­˜AIæŠ¥å‘Š
            ai_report_path = Path("reports") / f"ai_report_{task_id}.md"
            ai_report_path.parent.mkdir(exist_ok=True)
            with open(ai_report_path, 'w', encoding='utf-8') as f:
                f.write(ai_report)
            print(f"AIæŠ¥å‘Šå·²ç”Ÿæˆ: {ai_report_path}")
        
    except Exception as e:
        print(f"ç”ŸæˆæŠ¥å‘Šä»»åŠ¡å¤±è´¥: {e}")

async def store_structured_data(task_id: str, file_path: str, analysis_type: str):
    """åå°ä»»åŠ¡ï¼šå­˜å‚¨ç»“æ„åŒ–ä¿¡æ¯ç»™ä¿®å¤agent"""
    global bug_detection_agent
    
    try:
        # ç­‰å¾…ä»»åŠ¡å®Œæˆ
        max_wait_time = 300  # 5åˆ†é’Ÿ
        wait_interval = 2    # 2ç§’
        waited_time = 0
        
        while waited_time < max_wait_time:
            task_status = await bug_detection_agent.get_task_status(task_id)
            if task_status and task_status.get("status") == "completed":
                break
            await asyncio.sleep(wait_interval)
            waited_time += wait_interval
        
        if waited_time >= max_wait_time:
            print(f"ä»»åŠ¡ {task_id} è¶…æ—¶ï¼Œæ— æ³•å­˜å‚¨ç»“æ„åŒ–æ•°æ®")
            return
        
        # è·å–æ£€æµ‹ç»“æœ
        detection_results = task_status.get("result", {}).get("detection_results", {})
        if not detection_results:
            print(f"ä»»åŠ¡ {task_id} æ²¡æœ‰æ£€æµ‹ç»“æœ")
            return
        
        # åˆ›å»ºç»“æ„åŒ–æ•°æ®å­˜å‚¨ç›®å½•
        structured_dir = Path("structured_data")
        structured_dir.mkdir(exist_ok=True)
        
        # ç”Ÿæˆç»“æ„åŒ–æ•°æ®
        structured_data = {
            "task_id": task_id,
            "file_path": file_path,
            "analysis_type": analysis_type,
            "timestamp": datetime.now().isoformat(),
            "summary": {
                "total_issues": detection_results.get("total_issues", 0),
                "error_count": detection_results.get("summary", {}).get("error_count", 0),
                "warning_count": detection_results.get("summary", {}).get("warning_count", 0),
                "info_count": detection_results.get("summary", {}).get("info_count", 0),
                "languages_detected": detection_results.get("languages_detected", []),
                "total_files": detection_results.get("total_files", 1)
            },
            "issues_by_priority": categorize_issues_by_priority(detection_results.get("issues", [])),
            "fix_recommendations": generate_fix_recommendations(detection_results.get("issues", [])),
            "project_structure": analyze_project_structure(detection_results, analysis_type),
            "detection_metadata": {
                "detection_tools": detection_results.get("detection_tools", []),
                "analysis_time": detection_results.get("analysis_time", 0),
                "project_path": detection_results.get("project_path", file_path)
            }
        }
        
        # ä¿å­˜ç»“æ„åŒ–æ•°æ®
        structured_file = structured_dir / f"structured_data_{task_id}.json"
        with open(structured_file, 'w', encoding='utf-8') as f:
            json.dump(structured_data, f, ensure_ascii=False, indent=2)
        
        print(f"ç»“æ„åŒ–æ•°æ®å·²å­˜å‚¨: {structured_file}")
        
    except Exception as e:
        print(f"å­˜å‚¨ç»“æ„åŒ–æ•°æ®å¤±è´¥: {e}")

def categorize_issues_by_priority(issues):
    """æŒ‰ä¼˜å…ˆçº§åˆ†ç±»é—®é¢˜"""
    priority_categories = {
        "critical": [],  # é”™è¯¯çº§åˆ«ï¼Œå®‰å…¨ç›¸å…³
        "high": [],      # é”™è¯¯çº§åˆ«ï¼Œéå®‰å…¨ç›¸å…³
        "medium": [],    # è­¦å‘Šçº§åˆ«
        "low": []        # ä¿¡æ¯çº§åˆ«
    }
    
    for issue in issues:
        severity = issue.get("severity", "info")
        issue_type = issue.get("type", "")
        
        # å®‰å…¨ç›¸å…³é—®é¢˜ä¼˜å…ˆçº§æœ€é«˜
        if severity == "error" and any(keyword in issue_type.lower() for keyword in 
                                      ["security", "vulnerability", "injection", "xss", "csrf", "secret", "password"]):
            priority_categories["critical"].append(issue)
        elif severity == "error":
            priority_categories["high"].append(issue)
        elif severity == "warning":
            priority_categories["medium"].append(issue)
        else:
            priority_categories["low"].append(issue)
    
    return priority_categories

def generate_fix_recommendations(issues):
    """ç”Ÿæˆä¿®å¤å»ºè®®"""
    recommendations = {
        "immediate_actions": [],
        "short_term_improvements": [],
        "long_term_optimizations": []
    }
    
    error_count = sum(1 for issue in issues if issue.get("severity") == "error")
    warning_count = sum(1 for issue in issues if issue.get("severity") == "warning")
    
    # ç«‹å³è¡ŒåŠ¨
    if error_count > 0:
        recommendations["immediate_actions"].append(f"ä¿®å¤ {error_count} ä¸ªé”™è¯¯çº§åˆ«çš„é—®é¢˜")
    
    # å®‰å…¨ç›¸å…³é—®é¢˜
    security_issues = [issue for issue in issues if "security" in issue.get("type", "").lower()]
    if security_issues:
        recommendations["immediate_actions"].append(f"ä¼˜å…ˆå¤„ç† {len(security_issues)} ä¸ªå®‰å…¨é—®é¢˜")
    
    # çŸ­æœŸæ”¹è¿›
    if warning_count > 10:
        recommendations["short_term_improvements"].append("è¿›è¡Œä»£ç å®¡æŸ¥ï¼Œå¤„ç†å¤§é‡è­¦å‘Š")
    
    # é•¿æœŸä¼˜åŒ–
    recommendations["long_term_optimizations"].append("å»ºç«‹æŒç»­é›†æˆæµç¨‹ï¼Œå®šæœŸè¿›è¡Œä»£ç è´¨é‡æ£€æŸ¥")
    recommendations["long_term_optimizations"].append("åˆ¶å®šä»£ç è§„èŒƒå’Œæœ€ä½³å®è·µæŒ‡å—")
    
    return recommendations

def analyze_project_structure(detection_results, analysis_type):
    """åˆ†æé¡¹ç›®ç»“æ„"""
    structure_info = {
        "analysis_type": analysis_type,
        "file_count": detection_results.get("total_files", 1),
        "languages": detection_results.get("languages_detected", []),
        "complexity_indicators": {
            "high_issue_files": 0,
            "average_issues_per_file": 0
        }
    }
    
    issues = detection_results.get("issues", [])
    if issues:
        # ç»Ÿè®¡æ¯ä¸ªæ–‡ä»¶çš„é—®é¢˜æ•°é‡
        file_issue_count = {}
        for issue in issues:
            file_name = issue.get("file", "unknown")
            file_issue_count[file_name] = file_issue_count.get(file_name, 0) + 1
        
        # è®¡ç®—é«˜é—®é¢˜æ–‡ä»¶æ•°é‡
        structure_info["complexity_indicators"]["high_issue_files"] = sum(
            1 for count in file_issue_count.values() if count > 5
        )
        
        # è®¡ç®—å¹³å‡é—®é¢˜æ•°
        total_files = len(file_issue_count) or 1
        structure_info["complexity_indicators"]["average_issues_per_file"] = len(issues) / total_files
    
    return structure_info

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)
