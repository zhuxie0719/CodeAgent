"""
ç»¼åˆæ£€æµ‹API
ç»Ÿä¸€çš„æ£€æµ‹å…¥å£ï¼Œé›†æˆé™æ€æ£€æµ‹å’ŒåŠ¨æ€æ£€æµ‹åŠŸèƒ½
"""

import asyncio
import tempfile
import os
import json
import sys
import httpx
import zipfile
import shutil
from datetime import datetime
from typing import Dict, Any, Optional, List
from pathlib import Path

from fastapi import APIRouter, File, UploadFile, HTTPException, BackgroundTasks, Form
from pydantic import BaseModel, Field

# å¯¼å…¥æ£€æµ‹ç»„ä»¶
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from agents.dynamic_detection_agent.agent import DynamicDetectionAgent
from agents.bug_detection_agent.agent import BugDetectionAgent
from api.deepseek_config import deepseek_config

# æ•°æ®æ¨¡å‹
class BaseResponse(BaseModel):
    """åŸºç¡€å“åº”æ¨¡å‹"""
    success: bool = Field(True, description="æ˜¯å¦æˆåŠŸ")
    message: str = Field("", description="å“åº”æ¶ˆæ¯")
    data: Optional[Dict[str, Any]] = Field(None, description="å“åº”æ•°æ®")
    error: Optional[str] = Field(None, description="é”™è¯¯ä¿¡æ¯")

class DetectionRequest(BaseModel):
    """æ£€æµ‹è¯·æ±‚æ¨¡å‹"""
    static_analysis: bool = Field(True, description="æ˜¯å¦è¿›è¡Œé™æ€åˆ†æ")
    dynamic_monitoring: bool = Field(True, description="æ˜¯å¦è¿›è¡ŒåŠ¨æ€ç›‘æ§")
    runtime_analysis: bool = Field(True, description="æ˜¯å¦è¿›è¡Œè¿è¡Œæ—¶åˆ†æ")

# åˆ›å»ºAPIRouter
router = APIRouter()

# å…¨å±€æ£€æµ‹å™¨
dynamic_agent = DynamicDetectionAgent({
    "monitor_interval": 5,
    "alert_thresholds": {
        "cpu_threshold": 80,
        "memory_threshold": 85,
        "disk_threshold": 90,
        "network_threshold": 80
    },
    "enable_web_app_test": False,
    "enable_dynamic_detection": True,
    "enable_flask_specific_tests": True,
    "enable_server_testing": True
})

# æ£€æŸ¥æ˜¯å¦å¯ç”¨Dockeræ”¯æŒï¼ˆé€šè¿‡ç¯å¢ƒå˜é‡ï¼Œé»˜è®¤ç¦ç”¨ï¼‰
use_docker = os.getenv("USE_DOCKER", "false").lower() == "true"

static_agent = BugDetectionAgent({
    "enable_ai_analysis": True,
    "analysis_depth": "comprehensive",
    "use_docker": use_docker
})

# æ³¨æ„ï¼šåŠ¨æ€æ£€æµ‹ä¸ä½¿ç”¨Dockerï¼Œå®ƒç›´æ¥ä½¿ç”¨æœ¬åœ°è™šæ‹Ÿç¯å¢ƒ

class ComprehensiveDetector:
    """ç»¼åˆæ£€æµ‹å™¨ï¼Œé›†æˆé™æ€æ£€æµ‹å’ŒåŠ¨æ€æ£€æµ‹åŠŸèƒ½"""
    
    def __init__(self, static_agent, dynamic_agent):
        self.static_agent = static_agent
        self.dynamic_agent = dynamic_agent
        self.enable_web_app_test = False
        self.enable_dynamic_detection = True
        self.enable_flask_specific_tests = True
        self.enable_server_testing = True
    
    async def detect_defects(self, zip_file_path: str, 
                           static_analysis: bool = True,
                           dynamic_monitoring: bool = True,
                           runtime_analysis: bool = True,
                           enable_dynamic_detection: bool = True,
                           enable_flask_specific_tests: bool = True,
                           enable_server_testing: bool = True,
                           # é™æ€æ£€æµ‹å·¥å…·é€‰æ‹©
                           enable_pylint: bool = True,
                           enable_mypy: bool = True,
                           enable_semgrep: bool = True,
                           enable_ruff: bool = True,
                           enable_bandit: bool = True,
                           enable_llm_filter: bool = True) -> Dict[str, Any]:
        """æ‰§è¡Œç»¼åˆæ£€æµ‹"""
        # è®¾ç½®enable_web_app_testå±æ€§ï¼Œå¹¶åŒæ­¥åˆ°dynamic_agent
        self.enable_web_app_test = enable_web_app_test
        if hasattr(self.dynamic_agent, 'enable_web_app_test'):
            self.dynamic_agent.enable_web_app_test = enable_web_app_test
        
        results = {
            "detection_type": "comprehensive",
            "timestamp": datetime.now().isoformat(),
            "zip_file": zip_file_path,
            "analysis_options": {
                "static_analysis": static_analysis,
                "dynamic_monitoring": dynamic_monitoring,
                "runtime_analysis": runtime_analysis,
                "enable_dynamic_detection": enable_dynamic_detection,
                "enable_flask_specific_tests": enable_flask_specific_tests,
                "enable_server_testing": enable_server_testing,
                # é™æ€æ£€æµ‹å·¥å…·é€‰æ‹©
                "enable_pylint": enable_pylint,
                "enable_mypy": enable_mypy,
                "enable_semgrep": enable_semgrep,
                "enable_ruff": enable_ruff,
                "enable_bandit": enable_bandit,
                "enable_llm_filter": enable_llm_filter
            }
        }
        
        try:
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(zip_file_path)
            max_size = 50 * 1024 * 1024  # 50MBé™åˆ¶
            
            if file_size > max_size:
                results["error"] = f"æ–‡ä»¶è¿‡å¤§ ({file_size // (1024*1024)}MB > {max_size // (1024*1024)}MB)"
                return results
            
            # ä½¿ç”¨BugDetectionAgentçš„extract_projectæ–¹æ³•æ¥è§£å‹é¡¹ç›®å¹¶åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
            print(f"ğŸ”§ å¼€å§‹è§£å‹é¡¹ç›®å¹¶åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ: {zip_file_path}")
            try:
                # è®¾ç½®è¾ƒé•¿çš„è¶…æ—¶æ—¶é—´ï¼Œç»™è™šæ‹Ÿç¯å¢ƒåˆ›å»ºè¶³å¤Ÿæ—¶é—´
                extract_dir = await asyncio.wait_for(
                    self.static_agent.extract_project(zip_file_path),
                    timeout=120.0  # å¢åŠ åˆ°120ç§’
                )
                print(f"âœ… é¡¹ç›®è§£å‹å®Œæˆï¼Œè™šæ‹Ÿç¯å¢ƒå·²åˆ›å»º: {extract_dir}")
            except asyncio.TimeoutError:
                print("âš ï¸ è™šæ‹Ÿç¯å¢ƒåˆ›å»ºè¶…æ—¶ï¼ˆ120ç§’ï¼‰ï¼Œä½¿ç”¨ç®€å•è§£å‹æ¨¡å¼")
                extract_dir = await self._simple_extract_project(zip_file_path)
                results["warning"] = "è™šæ‹Ÿç¯å¢ƒåˆ›å»ºè¶…æ—¶ï¼Œä½¿ç”¨ç®€å•è§£å‹æ¨¡å¼"
            except KeyboardInterrupt:
                print("âš ï¸ è™šæ‹Ÿç¯å¢ƒåˆ›å»ºè¢«ä¸­æ–­ï¼Œä½¿ç”¨ç®€å•è§£å‹æ¨¡å¼")
                extract_dir = await self._simple_extract_project(zip_file_path)
                results["warning"] = "è™šæ‹Ÿç¯å¢ƒåˆ›å»ºè¢«ä¸­æ–­ï¼Œä½¿ç”¨ç®€å•è§£å‹æ¨¡å¼"
            except Exception as e:
                print(f"âŒ é¡¹ç›®è§£å‹å¤±è´¥: {e}")
                # å¦‚æœè™šæ‹Ÿç¯å¢ƒåˆ›å»ºå¤±è´¥ï¼Œå°è¯•ç®€å•çš„æ–‡ä»¶è§£å‹
                extract_dir = await self._simple_extract_project(zip_file_path)
                    
                # è®¾ç½®è­¦å‘Šä¿¡æ¯
                results["warning"] = f"è™šæ‹Ÿç¯å¢ƒåˆ›å»ºå¤±è´¥ï¼Œä½¿ç”¨ç®€å•è§£å‹æ¨¡å¼: {e}"
            
            results["extracted_path"] = extract_dir
            results["files"] = self._list_files(extract_dir)
            
            # é™åˆ¶æ–‡ä»¶æ•°é‡ï¼Œé¿å…å¤„ç†è¿‡å¤šæ–‡ä»¶
            if len(results["files"]) > 1000:
                results["warning"] = f"æ–‡ä»¶æ•°é‡è¿‡å¤š ({len(results['files'])} > 1000)ï¼Œå°†è¿›è¡Œé‡‡æ ·åˆ†æ"
                results["files"] = results["files"][:1000]  # åªå–å‰1000ä¸ªæ–‡ä»¶
            
            # ========== æ­¥éª¤1: æ‰§è¡Œåˆæ­¥ä»£ç åˆ†æ ==========
            print("ğŸ” å¼€å§‹åˆæ­¥ä»£ç åˆ†æ...")
            preliminary_analysis = await self._perform_preliminary_analysis(extract_dir)
            results["preliminary_analysis"] = preliminary_analysis
            
            # ç”Ÿæˆä»“åº“ç»“æ„æ–‡ä»¶
            repository_structure_file = await self._generate_repository_structure(extract_dir)
            if repository_structure_file:
                results["repository_structure_file"] = repository_structure_file
            
            # ä¿å­˜åˆæ­¥åˆ†æç»“æœä¾›é™æ€æ£€æµ‹ä½¿ç”¨
            self._current_preliminary_analysis = preliminary_analysis
            
            # ========== æ­¥éª¤2: æ‰§è¡Œé™æ€åˆ†æå’ŒåŠ¨æ€æ£€æµ‹ ==========
            # å¹¶è¡Œæ‰§è¡Œé™æ€åˆ†æå’ŒåŠ¨æ€æ£€æµ‹
            tasks = []
            
            # é™æ€åˆ†æ
            if static_analysis:
                tasks.append(self._perform_static_analysis_async(
                    extract_dir,
                    enable_pylint=enable_pylint,
                    enable_mypy=enable_mypy,
                    enable_semgrep=enable_semgrep,
                    enable_ruff=enable_ruff,
                    enable_bandit=enable_bandit,
                    enable_llm_filter=enable_llm_filter
                ))
            
            # åŠ¨æ€ç›‘æ§
            if dynamic_monitoring:
                tasks.append(self._perform_dynamic_monitoring_async())
            
            # è¿è¡Œæ—¶åˆ†æ
            if runtime_analysis:
                tasks.append(self._perform_runtime_analysis_async(extract_dir))
            
            # åŠ¨æ€ç¼ºé™·æ£€æµ‹
            if enable_dynamic_detection:
                tasks.append(self._perform_dynamic_detection_async(extract_dir, enable_flask_specific_tests, enable_server_testing))
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼ˆæ·»åŠ è¶…æ—¶æœºåˆ¶ï¼‰
            if tasks:
                try:
                    # è®¾ç½®120ç§’è¶…æ—¶ï¼Œç»™æ£€æµ‹æ›´å¤šæ—¶é—´
                    task_results = await asyncio.wait_for(
                        asyncio.gather(*tasks, return_exceptions=True),
                        timeout=120.0
                    )
                except asyncio.TimeoutError:
                    print("âš ï¸ æ£€æµ‹ä»»åŠ¡è¶…æ—¶ï¼ˆ120ç§’ï¼‰ï¼Œä½¿ç”¨é»˜è®¤ç»“æœ")
                    results["warning"] = "æ£€æµ‹ä»»åŠ¡è¶…æ—¶ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½æœªå®Œæˆ"
                    # åˆ›å»ºé»˜è®¤çš„å¤±è´¥ç»“æœ
                    task_results = []
                    for i, task in enumerate(tasks):
                        if i == 0 and static_analysis:
                            task_results.append({"error": "æ£€æµ‹è¶…æ—¶", "issues": []})
                        elif i == 1 and dynamic_monitoring:
                            task_results.append({"error": "æ£€æµ‹è¶…æ—¶", "alerts": []})
                        elif i == 2 and runtime_analysis:
                            task_results.append({"error": "æ£€æµ‹è¶…æ—¶", "execution_successful": False})
                        elif i == 3 and enable_dynamic_detection:
                            task_results.append({"error": "æ£€æµ‹è¶…æ—¶", "tests_completed": False})
                
                # å¤„ç†ç»“æœ
                task_index = 0
                if static_analysis:
                    if isinstance(task_results[task_index], Exception):
                        results["static_analysis"] = {"error": str(task_results[task_index]), "issues": []}
                    else:
                        results["static_analysis"] = task_results[task_index]
                    task_index += 1
                
                if dynamic_monitoring:
                    if isinstance(task_results[task_index], Exception):
                        results["dynamic_monitoring"] = {"error": str(task_results[task_index]), "alerts": []}
                    else:
                        results["dynamic_monitoring"] = task_results[task_index]
                    task_index += 1
                
                if runtime_analysis:
                    if isinstance(task_results[task_index], Exception):
                        results["runtime_analysis"] = {"error": str(task_results[task_index]), "execution_successful": False}
                    else:
                        results["runtime_analysis"] = task_results[task_index]
                    task_index += 1
                
                if enable_dynamic_detection:
                    if isinstance(task_results[task_index], Exception):
                        results["dynamic_detection"] = {"error": str(task_results[task_index]), "tests_completed": False}
                    else:
                        results["dynamic_detection"] = task_results[task_index]
            
            # ç”Ÿæˆç»¼åˆæ‘˜è¦
            results["summary"] = self._generate_summary(results)
            
            # æ¸…ç†ä¸´æ—¶ç›®å½•å’Œè™šæ‹Ÿç¯å¢ƒ
            try:
                await self.static_agent.cleanup_project_environment(extract_dir)
                print(f"âœ… é¡¹ç›®ç¯å¢ƒæ¸…ç†å®Œæˆ: {extract_dir}")
            except Exception as cleanup_error:
                print(f"âš ï¸ ç¯å¢ƒæ¸…ç†å¤±è´¥: {cleanup_error}")
                # å›é€€åˆ°æ‰‹åŠ¨æ¸…ç†
                shutil.rmtree(extract_dir, ignore_errors=True)
            # åˆå¹¶é™æ€å’ŒåŠ¨æ€æ£€æµ‹ç¼ºé™·æ¸…å•ï¼Œç”Ÿæˆç»Ÿä¸€æ ¼å¼
            print("ğŸ“‹ [DEBUG] å¼€å§‹åˆå¹¶ç¼ºé™·æ¸…å•...")
            merged_defects = self._merge_defects_list(results, extract_dir)
            results["merged_defects"] = merged_defects
            print(f"ğŸ“‹ [DEBUG] åˆå¹¶åçš„ç¼ºé™·æ•°é‡: {len(merged_defects)}")
            if merged_defects:
                print(f"ğŸ“‹ [DEBUG] å‰3ä¸ªç¼ºé™·ç¤ºä¾‹:")
                for i, defect in enumerate(merged_defects[:3], 1):
                    print(f"  {i}. æ–‡ä»¶: {defect.get('file', 'N/A')}, è¡Œå·: {defect.get('line', 'N/A')}, æ¥æº: {defect.get('source', 'N/A')}")
            else:
                print("âš ï¸ [DEBUG] è­¦å‘Š: merged_defects ä¸ºç©ºï¼")
            
            # ç”Ÿæˆä»»åŠ¡ä¿¡æ¯JSONæ–‡ä»¶ä¾›ä¿®å¤å·¥ä½œæµä½¿ç”¨ï¼ˆä¿å­˜åˆ°æ°¸ä¹…ä½ç½®ï¼‰
            print("ğŸ“ [DEBUG] å¼€å§‹ç”Ÿæˆä»»åŠ¡ä¿¡æ¯JSON...")
            task_info_path = self._generate_task_info_json(merged_defects, extract_dir)
            print(f"ğŸ“ [DEBUG] task_info_path = {task_info_path}")
            if task_info_path:
                print(f"ğŸ“ [DEBUG] æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {os.path.exists(task_info_path)}")
            else:
                print("âš ï¸ [DEBUG] è­¦å‘Š: task_info_path ä¸º Noneï¼Œå¯èƒ½æ²¡æœ‰ç”Ÿæˆä»»åŠ¡ä¿¡æ¯")
            
            if task_info_path and os.path.exists(task_info_path):
                # å°†ä»»åŠ¡ä¿¡æ¯æ–‡ä»¶å¤åˆ¶åˆ°ç»“æœç›®å½•ï¼ˆä½¿ç”¨ç»å¯¹è·¯å¾„ï¼Œç¡®ä¿ä¿å­˜åœ¨é¡¹ç›®æ ¹ç›®å½•ï¼‰
                # è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆAPIæ–‡ä»¶æ‰€åœ¨ç›®å½•çš„çˆ¶ç›®å½•ï¼‰
                api_dir = Path(__file__).parent
                project_root = api_dir.parent
                results_dir = project_root / "comprehensive_detection_results"
                results_dir.mkdir(exist_ok=True)
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                permanent_task_info_file = results_dir / f"agent_task_info_{timestamp}.json"
                permanent_task_info_file_abs = permanent_task_info_file.resolve()
                print(f"ğŸ“ [DEBUG] å¤åˆ¶ä»»åŠ¡ä¿¡æ¯æ–‡ä»¶åˆ°æ°¸ä¹…ä½ç½®:")
                print(f"   ç›¸å¯¹è·¯å¾„: {permanent_task_info_file}")
                print(f"   ç»å¯¹è·¯å¾„: {permanent_task_info_file_abs}")
                shutil.copy2(task_info_path, permanent_task_info_file_abs)
                results["task_info_file"] = str(permanent_task_info_file_abs)
                print(f"âœ… [DEBUG] æ–‡ä»¶å·²å¤åˆ¶ï¼ŒéªŒè¯æ–‡ä»¶å­˜åœ¨: {permanent_task_info_file_abs.exists()}")
                # åŒæ—¶å°†ä»»åŠ¡ä¿¡æ¯å†…å®¹åŒ…å«åœ¨ç»“æœä¸­
                with open(permanent_task_info_file_abs, 'r', encoding='utf-8') as f:
                    task_info_data = json.load(f)
                    results["task_info"] = task_info_data
                print(f"âœ… [DEBUG] ä»»åŠ¡ä¿¡æ¯å·²ä¿å­˜ï¼Œä»»åŠ¡æ•°é‡: {len(task_info_data)}")
                print(f"ğŸ“ [DEBUG] æ³¨æ„: ä»»åŠ¡ä¿¡æ¯ä¸­çš„æ–‡ä»¶è·¯å¾„ä¸ºç»å¯¹è·¯å¾„")
                print(f"ğŸ“ [DEBUG] ä¸´æ—¶ç›®å½•: {extract_dir}")
                print(f"ğŸ“ [DEBUG] ä¸´æ—¶ç›®å½•å°†ä¿ç•™ï¼Œä»¥ä¾¿ä¿®å¤Agentä½¿ç”¨")
            else:
                print("âš ï¸ [DEBUG] è­¦å‘Š: æœªä¿å­˜ä»»åŠ¡ä¿¡æ¯æ–‡ä»¶åˆ°æ°¸ä¹…ä½ç½®")
                results["task_info_file"] = None
                results["task_info"] = []
            
            # ä¸åˆ é™¤ä¸´æ—¶ç›®å½•ï¼Œä¿ç•™ä¸Šä¼ çš„æ–‡ä»¶ä»¥ä¾¿åç»­ä¿®å¤ä½¿ç”¨
            # æ³¨æ„ï¼šä¸´æ—¶ç›®å½•ä¼šä¸€ç›´ä¿ç•™ï¼Œéœ€è¦æ‰‹åŠ¨æ¸…ç†æˆ–å®šæœŸæ¸…ç†
            print(f"ğŸ“ [DEBUG] ä¿ç•™ä¸´æ—¶ç›®å½•: {extract_dir}")
            print(f"âš ï¸ [DEBUG] æ³¨æ„: ä¸´æ—¶ç›®å½•æœªåˆ é™¤ï¼Œéœ€è¦å®šæœŸæ¸…ç†ä»¥é‡Šæ”¾ç£ç›˜ç©ºé—´")
            
            return results
            
        except Exception as e:
            results["error"] = str(e)
            # å³ä½¿å‡ºç°é”™è¯¯ä¹Ÿè¦ç”Ÿæˆsummary
            results["summary"] = self._generate_summary(results)
            return results
    
    async def _simple_extract_project(self, zip_file_path: str) -> str:
        """ç®€å•çš„é¡¹ç›®è§£å‹æ–¹æ³•ï¼ˆä¸åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼‰"""
        try:
            import zipfile
            import tempfile
            
            # åˆ›å»ºä¸´æ—¶è§£å‹ç›®å½•
            temp_dir = tempfile.mkdtemp(prefix="comprehensive_extract_")
            
            # è§£å‹ZIPæ–‡ä»¶
            with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
                zip_ref.extractall(temp_dir)
            
            print(f"âš ï¸ ä½¿ç”¨ç®€å•è§£å‹æ¨¡å¼: {temp_dir}")
            return temp_dir
            
        except Exception as e:
            print(f"âŒ ç®€å•è§£å‹ä¹Ÿå¤±è´¥: {e}")
            raise e
    
    def _list_files(self, project_path: str) -> List[str]:
        """åˆ—å‡ºé¡¹ç›®æ–‡ä»¶ï¼ˆæ’é™¤è™šæ‹Ÿç¯å¢ƒå’Œç¼“å­˜æ–‡ä»¶ï¼‰"""
        files = []
        skip_dirs = {'venv', '__pycache__', '.git', 'node_modules', '.pytest_cache', '.mypy_cache'}
        
        for root, dirs, filenames in os.walk(project_path):
            # è·³è¿‡ä¸éœ€è¦çš„ç›®å½•
            dirs[:] = [d for d in dirs if d not in skip_dirs]
            
            for filename in filenames:
                # è·³è¿‡éšè—æ–‡ä»¶å’Œç¼“å­˜æ–‡ä»¶
                if filename.startswith('.') or filename.endswith(('.pyc', '.pyo', '.pyd')):
                    continue
                    
                file_path = os.path.relpath(os.path.join(root, filename), project_path)
                files.append(file_path)
        return files
    
    async def _perform_preliminary_analysis(self, project_path: str) -> Dict[str, Any]:
        """æ‰§è¡Œåˆæ­¥ä»£ç åˆ†æï¼ˆé¡¹ç›®ç»“æ„ã€ä»£ç è´¨é‡ã€ä¾èµ–å…³ç³»ï¼‰"""
        try:
            from agents.code_analysis_agent.agent import CodeAnalysisAgent
            
            # åˆå§‹åŒ–ä»£ç åˆ†æä»£ç†
            code_analysis_agent = CodeAnalysisAgent({
                "enable_ai_analysis": True,
                "analysis_depth": "comprehensive"
            })
            
            print("  ğŸ“Š æ‰§è¡Œé¡¹ç›®ç»“æ„åˆ†æ...")
            project_structure = await code_analysis_agent.project_analyzer.analyze_project_structure(project_path)
            
            print("  ğŸ“ˆ æ‰§è¡Œä»£ç è´¨é‡åˆ†æ...")
            code_quality = await code_analysis_agent.code_analyzer.analyze_code_quality(project_path)
            
            print("  ğŸ”— æ‰§è¡Œä¾èµ–å…³ç³»åˆ†æ...")
            dependencies = await code_analysis_agent.dependency_analyzer.analyze_dependencies(project_path)
            
            print("âœ… åˆæ­¥ä»£ç åˆ†æå®Œæˆ")
            
            return {
                "success": True,
                "project_structure": project_structure,
                "code_quality": code_quality,
                "dependencies": dependencies
            }
        except Exception as e:
            print(f"âŒ åˆæ­¥ä»£ç åˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {
                "success": False,
                "error": str(e),
                "project_structure": {},
                "code_quality": {},
                "dependencies": {}
            }
    
    async def _generate_repository_structure(self, project_path: str) -> Optional[str]:
        """ç”Ÿæˆä»“åº“ç»“æ„æ–‡ä»¶ï¼ˆtreeæ ¼å¼ï¼‰"""
        try:
            from tools.repository_structure_generator import repository_structure_generator
            
            # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆä½¿ç”¨ç»å¯¹è·¯å¾„ï¼‰
            api_dir = Path(__file__).parent
            project_root = api_dir.parent
            structure_dir = project_root / "comprehensive_detection_results"
            structure_dir.mkdir(exist_ok=True)
            
            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            structure_file = structure_dir / f"repository_structure_{timestamp}.txt"
            
            # ç”Ÿæˆå¹¶ä¿å­˜æ ‘å½¢ç»“æ„
            success = repository_structure_generator.save_tree_structure(
                project_path, 
                str(structure_file),
                max_depth=10
            )
            
            if success:
                print(f"âœ… ä»“åº“ç»“æ„æ–‡ä»¶å·²ç”Ÿæˆ: {structure_file}")
                return str(structure_file)
            else:
                print("âš ï¸ ä»“åº“ç»“æ„æ–‡ä»¶ç”Ÿæˆå¤±è´¥")
                return None
        except Exception as e:
            print(f"âŒ ç”Ÿæˆä»“åº“ç»“æ„æ–‡ä»¶å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    async def _perform_static_analysis_async(self, project_path: str,
                                             enable_pylint: bool = True,
                                             enable_mypy: bool = True,
                                             enable_semgrep: bool = True,
                                             enable_ruff: bool = True,
                                             enable_bandit: bool = True,
                                             enable_llm_filter: bool = True) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡Œé™æ€åˆ†æ"""
        try:
            # ç¡®ä¿é™æ€æ£€æµ‹agentå·²åˆå§‹åŒ–ï¼ˆå·¥å…·åˆå§‹åŒ–ï¼‰
            if not hasattr(self.static_agent, '_tools_initialized') or not self.static_agent._tools_initialized:
                print("ğŸ”§ åˆå§‹åŒ–é™æ€æ£€æµ‹å·¥å…·...")
                await self.static_agent.initialize()
                self.static_agent._tools_initialized = True
                print("âœ… é™æ€æ£€æµ‹å·¥å…·åˆå§‹åŒ–å®Œæˆ")
            
            # è·å–åˆæ­¥åˆ†æç»“æœï¼ˆå¦‚æœå·²æ‰§è¡Œï¼‰
            preliminary_analysis = None
            if hasattr(self, '_current_preliminary_analysis'):
                preliminary_analysis = self._current_preliminary_analysis
            
            # è°ƒç”¨é™æ€æ£€æµ‹agentï¼ˆä¼ é€’åˆæ­¥åˆ†æç»“æœå’Œå·¥å…·é€‰æ‹©ï¼‰
            analysis_result = await self.static_agent.analyze_project(project_path, {
                "enable_static": True,
                "enable_pylint": enable_pylint,
                "enable_mypy": enable_mypy,
                "enable_semgrep": enable_semgrep,
                "enable_ruff": enable_ruff,
                "enable_bandit": enable_bandit,
                "enable_llm_filter": enable_llm_filter,
                "enable_ai_analysis": True,
                "preliminary_analysis": preliminary_analysis,  # ä¼ é€’åˆæ­¥åˆ†æç»“æœ
                "pylint_directory_mode": False,  # ç¦ç”¨ç›®å½•æ¨¡å¼ï¼Œä½¿ç”¨å•æ–‡ä»¶æ¨¡å¼ä»¥ç¡®ä¿é—®é¢˜ä¸è¢«è¿‡æ»¤æ‰
                "max_parallel_files": 10,  # å¹¶è¡Œæ–‡ä»¶æ•°é™åˆ¶
                "max_issues_to_return": 1000  # é™åˆ¶è¿”å›çš„é—®é¢˜æ•°é‡ï¼Œé¿å…æ•°æ®è¿‡å¤§
            })
            
            if analysis_result.get("success", False):
                detection_results = analysis_result.get("detection_results", {})
                # è°ƒè¯•ï¼šæ£€æŸ¥ç»“æœç»“æ„
                import logging
                logger = logging.getLogger(__name__)
                logger.info(f"é™æ€åˆ†æç»“æœ: success={analysis_result.get('success')}, detection_results keys={list(detection_results.keys()) if detection_results else 'None'}")
                if detection_results:
                    logger.info(f"æ£€æµ‹åˆ°çš„é—®é¢˜æ•°: {len(detection_results.get('issues', []))}")
                    logger.info(f"å·¥å…·è¦†ç›–ç‡: {detection_results.get('tool_coverage', {})}")
                # å¦‚æœæœ‰åˆæ­¥åˆ†æç»“æœï¼Œåˆå¹¶è¿›å»
                if preliminary_analysis and preliminary_analysis.get("success"):
                    detection_results["preliminary_analysis"] = preliminary_analysis
                return detection_results
            else:
                return {
                    "error": analysis_result.get("error", "é™æ€åˆ†æå¤±è´¥"),
                    "issues": [],
                    "statistics": {
                        "total_files": 0,
                        "total_lines": 0,
                        "average_complexity": 0,
                        "maintainability_score": 0
                    },
                    "files_analyzed": 0
                }
        except Exception as e:
            return {
                "error": str(e), 
                "issues": [],
                "statistics": {
                    "total_files": 0,
                    "total_lines": 0,
                    "average_complexity": 0,
                    "maintainability_score": 0
                },
                "files_analyzed": 0
            }
    
    async def _perform_dynamic_monitoring_async(self) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡ŒåŠ¨æ€ç›‘æ§"""
        try:
            return await self.dynamic_agent.start_monitoring(duration=60)
        except Exception as e:
            return {"error": str(e), "alerts": []}
    
    async def _perform_runtime_analysis_async(self, project_path: str) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡Œè¿è¡Œæ—¶åˆ†æ"""
        try:
            return await self.dynamic_agent.perform_runtime_analysis(project_path)
        except Exception as e:
            return {"error": str(e), "execution_successful": False}
    
    async def _perform_dynamic_detection_async(self, project_path: str, enable_flask_tests: bool = True, enable_server_tests: bool = True) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡ŒåŠ¨æ€ç¼ºé™·æ£€æµ‹"""
        try:
            return await self.dynamic_agent.perform_dynamic_detection(project_path, enable_flask_tests, enable_server_tests)
        except Exception as e:
            return {"error": str(e), "tests_completed": False}
    
    def _generate_summary(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆæ‘˜è¦"""
        summary = {
            "total_files": len(results.get("files", [])),
            "analysis_completed": not bool(results.get("error")),
            "issues_summary": {}
        }
        
        # ç»Ÿè®¡é—®é¢˜æ•°é‡
        total_issues = 0
        critical_issues = 0
        warning_issues = 0
        info_issues = 0
        
        # ç»Ÿè®¡é™æ€åˆ†æé—®é¢˜
        if "static_analysis" in results:
            static = results["static_analysis"]
            issues = static.get("issues", [])
            statistics = static.get("statistics", {})
            
            summary["issues_summary"]["static"] = {
                "analysis_type": static.get("analysis_type", "unknown"),
                "files_analyzed": static.get("files_analyzed", 0),
                "issues_found": len(issues),
                "total_files": statistics.get("total_files", 0),
                "total_lines": statistics.get("total_lines", 0),
                "average_complexity": statistics.get("average_complexity", 0),
                "maintainability_score": statistics.get("maintainability_score", 0),
                "issues_by_severity": statistics.get("issues_by_severity", {}),
                "issues_by_type": statistics.get("issues_by_type", {}),
                "issues_by_tool": statistics.get("issues_by_tool", {})
            }
            
            # ç»Ÿè®¡é—®é¢˜ä¸¥é‡ç¨‹åº¦
            for issue in issues:
                total_issues += 1
                severity = issue.get("severity", "info").lower()
                if severity == "error" or severity == "critical":
                    critical_issues += 1
                elif severity == "warning":
                    warning_issues += 1
                else:
                    info_issues += 1
        
        # ç»Ÿè®¡åŠ¨æ€ç›‘æ§ç»“æœ
        if "dynamic_monitoring" in results:
            dynamic = results["dynamic_monitoring"]
            alerts = dynamic.get("alerts", [])
            summary["issues_summary"]["dynamic"] = {
                "monitoring_duration": dynamic.get("duration", 0),
                "alerts_generated": len(alerts)
            }
            
            # ç»Ÿè®¡å‘Šè­¦æ•°é‡
            for alert in alerts:
                total_issues += 1
                severity = alert.get("severity", "info").lower()
                if severity == "error" or severity == "critical":
                    critical_issues += 1
                elif severity == "warning":
                    warning_issues += 1
                else:
                    info_issues += 1
        
        # ç»Ÿè®¡è¿è¡Œæ—¶åˆ†æç»“æœ
        if "runtime_analysis" in results:
            runtime = results["runtime_analysis"]
            summary["issues_summary"]["runtime"] = {
                "execution_successful": runtime.get("execution_successful", False),
                "main_file": runtime.get("main_file", "unknown")
            }
            
            # å¦‚æœæœ‰è¿è¡Œæ—¶é”™è¯¯ï¼Œè®¡å…¥é—®é¢˜
            if runtime.get("error"):
                total_issues += 1
                critical_issues += 1
        
        # ç»Ÿè®¡åŠ¨æ€æ£€æµ‹ç»“æœ
        if "dynamic_detection" in results:
            dynamic_detection = results["dynamic_detection"]
            summary["issues_summary"]["dynamic_detection"] = {
                "status": dynamic_detection.get("status", "unknown"),
                "is_flask_project": dynamic_detection.get("is_flask_project", False),
                "tests_completed": dynamic_detection.get("tests_completed", False),
                "success_rate": dynamic_detection.get("success_rate", 0)
            }
            
            # ç»Ÿè®¡åŠ¨æ€æ£€æµ‹é—®é¢˜
            dynamic_issues = dynamic_detection.get("issues", [])
            for issue in dynamic_issues:
                total_issues += 1
                severity = issue.get("severity", "info").lower()
                if severity == "error" or severity == "critical":
                    critical_issues += 1
                elif severity == "warning":
                    warning_issues += 1
                else:
                    info_issues += 1
        
        # è®¾ç½®æ•´ä½“çŠ¶æ€
        if critical_issues > 0:
            overall_status = "error"
        elif warning_issues > 0:
            overall_status = "warning"
        elif info_issues > 0:
            overall_status = "info"
        else:
            overall_status = "good"
        
        # ç”Ÿæˆå»ºè®®
        recommendations = []
        if critical_issues > 0:
            recommendations.append("å‘ç°ä¸¥é‡é—®é¢˜ï¼Œå»ºè®®ç«‹å³ä¿®å¤")
        if warning_issues > 0:
            recommendations.append("å‘ç°è­¦å‘Šé—®é¢˜ï¼Œå»ºè®®åŠæ—¶å¤„ç†")
        
        # æ£€æŸ¥è¿è¡Œæ—¶åˆ†æå’ŒåŠ¨æ€æ£€æµ‹çš„çŠ¶æ€
        runtime_analysis = results.get("runtime_analysis", {})
        dynamic_detection = results.get("dynamic_detection", {})
        runtime_failed = not runtime_analysis.get("execution_successful", True)
        dynamic_success = dynamic_detection.get("tests_completed", False) and dynamic_detection.get("success_rate", 0) >= 100
        
        if runtime_failed:
            if dynamic_success:
                # è¿è¡Œæ—¶åˆ†æå¤±è´¥ä½†åŠ¨æ€æ£€æµ‹æˆåŠŸï¼Œè¯´æ˜é¡¹ç›®éœ€è¦Flaskç¯å¢ƒæ‰èƒ½è¿è¡Œ
                recommendations.append("è¿è¡Œæ—¶åˆ†æå¤±è´¥ï¼Œä½†åŠ¨æ€æ£€æµ‹æˆåŠŸã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºé¡¹ç›®éœ€è¦Flaskç¯å¢ƒæ‰èƒ½è¿è¡Œï¼Œå±äºæ­£å¸¸æƒ…å†µ")
            else:
                # ä¸¤è€…éƒ½å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥é…ç½®
                recommendations.append("è¿è¡Œæ—¶åˆ†æå¤±è´¥ï¼Œæ£€æŸ¥é¡¹ç›®é…ç½®å’Œä¾èµ–")
        
        # æ·»åŠ æ‘˜è¦å­—æ®µ
        summary.update({
            "total_issues": total_issues,
            "critical_issues": critical_issues,
            "warning_issues": warning_issues,
            "info_issues": info_issues,
            "overall_status": overall_status,
            "recommendations": recommendations
        })
        
        return summary
    
    def _generate_natural_language_description(self, issue: Dict[str, Any], source: str = "static") -> str:
        """
        ä¸ºæ¯ä¸ªç¼ºé™·ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°
        
        Args:
            issue: ç¼ºé™·ä¿¡æ¯å­—å…¸
            source: æ¥æºï¼ˆ"static" æˆ– "dynamic"ï¼‰
        
        Returns:
            è‡ªç„¶è¯­è¨€æè¿°å­—ç¬¦ä¸²
        """
        if source == "static":
            tool = issue.get("tool", "unknown")
            message = issue.get("message", "")
            severity = issue.get("severity", "info")
            file_path = issue.get("file", "unknown")
            line = issue.get("line", 0)
            symbol = issue.get("symbol", "")
            
            # æ ¹æ®å·¥å…·å’Œé—®é¢˜ç±»å‹ç”Ÿæˆæè¿°
            if tool == "pylint":
                if "import" in message.lower() and "error" in message.lower():
                    return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼Œå­˜åœ¨å¯¼å…¥é”™è¯¯ï¼š{message}"
                elif "missing" in message.lower() and "docstring" in message.lower():
                    return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼Œç¼ºå°‘å‡½æ•°æˆ–æ–¹æ³•çš„æ–‡æ¡£å­—ç¬¦ä¸²"
                elif "unused" in message.lower():
                    return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼Œå­˜åœ¨æœªä½¿ç”¨çš„å˜é‡æˆ–å‚æ•°ï¼š{message}"
                elif severity == "error":
                    return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼Œå‘ç°ä¸¥é‡é”™è¯¯ï¼š{message}"
                else:
                    return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼Œ{tool} æ£€æµ‹åˆ°é—®é¢˜ï¼š{message}"
            
            elif tool == "mypy":
                return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼Œç±»å‹æ£€æŸ¥å‘ç°é—®é¢˜ï¼š{message}"
            
            elif tool == "semgrep":
                rule_id = issue.get("check_id", "")
                return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼Œæ£€æµ‹åˆ°å®‰å…¨æˆ–ä»£ç è´¨é‡é—®é¢˜ï¼ˆè§„åˆ™ï¼š{rule_id}ï¼‰ï¼š{message}"
            
            elif tool == "ruff":
                rule_code = issue.get("code", "")
                return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼Œä»£ç è§„èŒƒé—®é¢˜ï¼ˆè§„åˆ™ï¼š{rule_code}ï¼‰ï¼š{message}"
            
            elif tool == "bandit":
                test_id = issue.get("test_id", "")
                return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼Œå‘ç°å®‰å…¨é—®é¢˜ï¼ˆæ£€æµ‹é¡¹ï¼š{test_id}ï¼‰ï¼š{message}"
            
            else:
                return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼Œ{tool} æ£€æµ‹åˆ°{severity}çº§åˆ«é—®é¢˜ï¼š{message}"
        
        elif source == "dynamic":
            issue_type = issue.get("type", "unknown")
            message = issue.get("message", "")
            file_path = issue.get("file", "unknown")
            line = issue.get("line", 0)
            
            if issue_type == "import_error":
                import_name = issue.get("import", "")
                return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼ŒåŠ¨æ€æ£€æµ‹å‘ç°å¯¼å…¥é”™è¯¯ï¼šæ— æ³•å¯¼å…¥æ¨¡å— '{import_name}'"
            
            elif "flask" in issue_type.lower() or "functionality" in issue_type.lower():
                return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼ŒFlaskåŠŸèƒ½æµ‹è¯•å‘ç°é—®é¢˜ï¼š{message}"
            
            elif "runtime" in issue_type.lower():
                return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼Œè¿è¡Œæ—¶æ£€æµ‹å‘ç°é—®é¢˜ï¼š{message}"
            
            elif issue_type in ["cpu_high", "memory_high", "disk_high", "network_high"]:
                return f"ç³»ç»Ÿèµ„æºç›‘æ§å‘Šè­¦ï¼š{message}"
            
            else:
                return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼ŒåŠ¨æ€æ£€æµ‹å‘ç°é—®é¢˜ï¼š{message}"
        
        else:
            return issue.get("message", "æ£€æµ‹åˆ°é—®é¢˜")
    
    def _merge_defects_list(self, results: Dict[str, Any], project_path: str) -> List[Dict[str, Any]]:
        """
        åˆå¹¶é™æ€æ£€æµ‹å’ŒåŠ¨æ€æ£€æµ‹çš„ç¼ºé™·æ¸…å•ï¼Œç”Ÿæˆç»Ÿä¸€æ ¼å¼
        
        Args:
            results: æ£€æµ‹ç»“æœå­—å…¸
            project_path: é¡¹ç›®è·¯å¾„
        
        Returns:
            åˆå¹¶åçš„ç¼ºé™·åˆ—è¡¨ï¼Œæ¯ä¸ªç¼ºé™·åŒ…å«ï¼š
            - description: è‡ªç„¶è¯­è¨€æè¿°
            - file: æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
            - line: è¡Œå·
            - severity: ä¸¥é‡ç¨‹åº¦
            - source: æ¥æºï¼ˆ"static" æˆ– "dynamic"ï¼‰
            - tool: æ£€æµ‹å·¥å…·
            - original_issue: åŸå§‹é—®é¢˜ä¿¡æ¯
        """
        merged_defects = []
        
        # å¤„ç†é™æ€åˆ†æç»“æœ
        if "static_analysis" in results:
            static_result = results["static_analysis"]
            if isinstance(static_result, dict) and not static_result.get("error"):
                issues = static_result.get("issues", [])
                for issue in issues:
                    file_path = issue.get("file", "")
                    line = issue.get("line", 0)
                    
                    # è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„
                    if file_path and os.path.isabs(file_path):
                        try:
                            file_path = os.path.relpath(file_path, project_path)
                        except:
                            pass
                    
                    # ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°æ—¶ä½¿ç”¨ç›¸å¯¹è·¯å¾„
                    issue_for_desc = issue.copy()
                    issue_for_desc["file"] = file_path  # ä½¿ç”¨å·²è½¬æ¢çš„ç›¸å¯¹è·¯å¾„
                    merged_defect = {
                        "description": self._generate_natural_language_description(issue_for_desc, "static"),
                        "file": file_path,
                        "line": line,
                        "severity": issue.get("severity", "info"),
                        "source": "static",
                        "tool": issue.get("tool", "unknown"),
                        "original_issue": issue
                    }
                    merged_defects.append(merged_defect)
        
        # å¤„ç†åŠ¨æ€ç›‘æ§ç»“æœ
        if "dynamic_monitoring" in results:
            dynamic_result = results["dynamic_monitoring"]
            if isinstance(dynamic_result, dict) and not dynamic_result.get("error"):
                alerts = dynamic_result.get("alerts", [])
                for alert in alerts:
                    # åŠ¨æ€ç›‘æ§å‘Šè­¦å¯èƒ½æ²¡æœ‰æ–‡ä»¶ä¿¡æ¯
                    file_path = alert.get("file", "")
                    line = alert.get("line", 0)
                    
                    if file_path and os.path.isabs(file_path):
                        try:
                            file_path = os.path.relpath(file_path, project_path)
                        except:
                            pass
                    
                    # ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°æ—¶ä½¿ç”¨ç›¸å¯¹è·¯å¾„
                    alert_for_desc = alert.copy()
                    alert_for_desc["file"] = file_path if file_path else "system"
                    merged_defect = {
                        "description": self._generate_natural_language_description(alert_for_desc, "dynamic"),
                        "file": file_path if file_path else "system",
                        "line": line if line else 0,
                        "severity": alert.get("severity", "warning"),
                        "source": "dynamic",
                        "tool": "dynamic_monitoring",
                        "original_issue": alert
                    }
                    merged_defects.append(merged_defect)
        
        # å¤„ç†åŠ¨æ€æ£€æµ‹ç»“æœ
        if "dynamic_detection" in results:
            dynamic_detection_result = results["dynamic_detection"]
            if isinstance(dynamic_detection_result, dict) and not dynamic_detection_result.get("error"):
                issues = dynamic_detection_result.get("issues", [])
                for issue in issues:
                    file_path = issue.get("file", "")
                    line = issue.get("line", 0)
                    
                    if file_path and os.path.isabs(file_path):
                        try:
                            file_path = os.path.relpath(file_path, project_path)
                        except:
                            pass
                    
                    # ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°æ—¶ä½¿ç”¨ç›¸å¯¹è·¯å¾„
                    issue_for_desc = issue.copy()
                    issue_for_desc["file"] = file_path if file_path else "unknown"
                    merged_defect = {
                        "description": self._generate_natural_language_description(issue_for_desc, "dynamic"),
                        "file": file_path if file_path else "unknown",
                        "line": line if line else 0,
                        "severity": issue.get("severity", "error"),
                        "source": "dynamic",
                        "tool": "dynamic_detection",
                        "original_issue": issue
                    }
                    merged_defects.append(merged_defect)
        
        # æŒ‰æ–‡ä»¶è·¯å¾„å’Œè¡Œå·æ’åº
        merged_defects.sort(key=lambda x: (x.get("file", ""), x.get("line", 0)))
        
        return merged_defects
    
    def _generate_task_info_json(self, merged_defects: List[Dict[str, Any]], project_path: str) -> Optional[str]:
        """
        ç”Ÿæˆä»»åŠ¡ä¿¡æ¯JSONæ–‡ä»¶ä¾›ä¿®å¤å·¥ä½œæµä½¿ç”¨
        æ¯ä¸ªç¼ºé™·ç”Ÿæˆä¸€ä¸ªç‹¬ç«‹ä»»åŠ¡ï¼Œtaskå­—æ®µä¸ºç¼ºé™·çš„ç®€å•æè¿°
        
        Args:
            merged_defects: åˆå¹¶åçš„ç¼ºé™·åˆ—è¡¨
            project_path: é¡¹ç›®è·¯å¾„
        
        Returns:
            ç”Ÿæˆçš„ä»»åŠ¡ä¿¡æ¯JSONæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœç”Ÿæˆå¤±è´¥åˆ™è¿”å›None
        """
        try:
            print(f"ğŸ“ [DEBUG] _generate_task_info_json: è¾“å…¥ç¼ºé™·æ•°é‡={len(merged_defects)}, é¡¹ç›®è·¯å¾„={project_path}")
            
            # ä¸ºæ¯ä¸ªç¼ºé™·ç”Ÿæˆä¸€ä¸ªä»»åŠ¡
            tasks = []
            skipped_count = 0
            not_exist_count = 0
            
            for defect in merged_defects:
                file_path = defect.get("file", "")
                if not file_path or file_path in ["system", "unknown"]:
                    skipped_count += 1
                    print(f"  âš ï¸ [DEBUG] è·³è¿‡æ— æ•ˆæ–‡ä»¶è·¯å¾„çš„ç¼ºé™·: {file_path}")
                    continue
                
                # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
                abs_file_path = os.path.join(project_path, file_path)
                if not os.path.exists(abs_file_path):
                    not_exist_count += 1
                    print(f"  âš ï¸ [DEBUG] æ–‡ä»¶ä¸å­˜åœ¨: {abs_file_path}")
                    # æ³¨æ„ï¼šå³ä½¿æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä¹Ÿåˆ›å»ºä»»åŠ¡ï¼ˆæ–‡ä»¶å¯èƒ½åœ¨åç»­æ­¥éª¤ä¸­åˆ›å»ºï¼‰
                    # ä½¿ç”¨ç›¸å¯¹è·¯å¾„ä½œä¸ºproblem_fileï¼Œåœ¨ä¿®å¤æ—¶å†è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
                
                # è·å–ç¼ºé™·æè¿°ä½œä¸ºä»»åŠ¡æè¿°
                task_description = defect.get("description", "")
                if not task_description:
                    # å¦‚æœæ²¡æœ‰æè¿°ï¼Œç”Ÿæˆä¸€ä¸ªç®€å•çš„æè¿°
                    severity = defect.get("severity", "unknown")
                    tool = defect.get("tool", "unknown")
                    line = defect.get("line", 0)
                    file_name = os.path.basename(file_path)
                    task_description = f"ä¿®å¤ {file_name} ç¬¬ {line} è¡Œçš„ {tool} {severity} çº§åˆ«é—®é¢˜"
                
                # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„å¹¶ç»Ÿä¸€ä½¿ç”¨æ­£æ–œæ 
                abs_file_path = os.path.join(project_path, file_path)
                problem_file = abs_file_path.replace("\\", "/")
                
                task = {
                    "task": task_description,  # ä½¿ç”¨ç¼ºé™·çš„ç®€å•æè¿°
                    "problem_file": problem_file,  # ä¿å­˜ç»å¯¹è·¯å¾„
                    "project_root": project_path.replace("\\", "/"),
                    "agent_test_path": os.path.join(project_path, "agent-test").replace("\\", "/"),
                    "backup_agent_path": os.path.join(project_path, "backup-agent").replace("\\", "/"),
                    # å¯é€‰ï¼šæ·»åŠ ç¼ºé™·çš„è¯¦ç»†ä¿¡æ¯ï¼Œæ–¹ä¾¿åç»­å¤„ç†
                    "defect_info": {
                        "line": defect.get("line", 0),
                        "severity": defect.get("severity", "unknown"),
                        "tool": defect.get("tool", "unknown"),
                        "source": defect.get("source", "unknown")
                    }
                }
                tasks.append(task)
            
            print(f"ğŸ“ [DEBUG] ç”Ÿæˆä»»åŠ¡ç»Ÿè®¡:")
            print(f"   æ€»ç¼ºé™·æ•°: {len(merged_defects)}")
            print(f"   ç”Ÿæˆä»»åŠ¡æ•°: {len(tasks)}")
            print(f"   è·³è¿‡ç¼ºé™·æ•°: {skipped_count}")
            print(f"   æ–‡ä»¶ä¸å­˜åœ¨æ•°: {not_exist_count}")
            
            if not tasks:
                print("âš ï¸ [DEBUG] è­¦å‘Š: tasks ä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆä»»åŠ¡ä¿¡æ¯JSONæ–‡ä»¶")
                return None
            
            # ä¿å­˜ä»»åŠ¡ä¿¡æ¯JSONæ–‡ä»¶
            task_info_dir = Path(project_path)
            task_info_dir.mkdir(parents=True, exist_ok=True)
            task_info_file = task_info_dir / "agent_task_info.json"
            
            print(f"ğŸ“ [DEBUG] ä¿å­˜ä»»åŠ¡ä¿¡æ¯åˆ°: {task_info_file}")
            with open(task_info_file, 'w', encoding='utf-8') as f:
                json.dump(tasks, f, indent=2, ensure_ascii=False)
            
            print(f"âœ… [DEBUG] ä»»åŠ¡ä¿¡æ¯JSONæ–‡ä»¶å·²ç”Ÿæˆ: {task_info_file}")
            print(f"âœ… [DEBUG] æ¯ä¸ªç¼ºé™·éƒ½ç”Ÿæˆäº†ä¸€ä¸ªç‹¬ç«‹ä»»åŠ¡")
            return str(task_info_file)
        
        except Exception as e:
            print(f"âŒ [DEBUG] ç”Ÿæˆä»»åŠ¡ä¿¡æ¯JSONæ–‡ä»¶å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def generate_report(self, results: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š"""
        report_lines = [
            "# ç»¼åˆæ£€æµ‹æŠ¥å‘Š",
            f"ç”Ÿæˆæ—¶é—´: {results.get('timestamp', 'unknown')}",
            f"æ£€æµ‹ç±»å‹: {results.get('detection_type', 'unknown')}",
            "",
            "## æ£€æµ‹æ‘˜è¦",
        ]
        
        summary = results.get("summary", {})
        report_lines.extend([
            f"- æ€»æ–‡ä»¶æ•°: {summary.get('total_files', 0)}",
            f"- åˆ†æå®Œæˆ: {summary.get('analysis_completed', False)}",
            ""
        ])
        
        # æ·»åŠ é—®é¢˜æ‘˜è¦
        issues_summary = summary.get("issues_summary", {})
        if issues_summary:
            report_lines.append("## é—®é¢˜ç»Ÿè®¡")
            for analysis_type, stats in issues_summary.items():
                report_lines.append(f"### {analysis_type.upper()}")
                for key, value in stats.items():
                    report_lines.append(f"- {key}: {value}")
                report_lines.append("")
        
        return "\n".join(report_lines)
    
    def save_results(self, results: Dict[str, Any], file_path: str):
        """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            print(f"æ£€æµ‹ç»“æœå·²ä¿å­˜åˆ°: {file_path}")
        except Exception as e:
            print(f"ä¿å­˜ç»“æœå¤±è´¥: {e}")
    
    def generate_severe_issues_report(self, results: Dict[str, Any], filename: str) -> str:
        """ç”Ÿæˆä¸¥é‡é—®é¢˜æ±‡æ€»æ–‡æ¡£"""
        report_lines = [
            "# ä¸¥é‡é—®é¢˜æ±‡æ€»æŠ¥å‘Š",
            f"**é¡¹ç›®åç§°**: {filename}",
            f"**ç”Ÿæˆæ—¶é—´**: {results.get('timestamp', 'unknown')}",
            f"**æ£€æµ‹ç±»å‹**: {results.get('detection_type', 'unknown')}",
            "",
            "## æ¦‚è¿°",
            "æœ¬æŠ¥å‘Šæ±‡æ€»äº†ä»£ç æ£€æµ‹ä¸­å‘ç°çš„ä¸¥é‡é—®é¢˜ï¼Œæ’é™¤äº†æ ¼å¼åŒ–å’Œé£æ ¼é—®é¢˜ï¼Œé‡ç‚¹å…³æ³¨å¯èƒ½å½±å“åŠŸèƒ½å’Œå®‰å…¨çš„å…³é”®é—®é¢˜ã€‚",
            ""
        ]
        
        # æ”¶é›†æ‰€æœ‰ä¸¥é‡é—®é¢˜
        severe_issues = []
        
        # é™æ€åˆ†æé—®é¢˜
        if "static_analysis" in results:
            static_issues = results["static_analysis"].get("issues", [])
            for issue in static_issues:
                if self._is_severe_issue(issue):
                    severe_issues.append({
                        "type": "é™æ€åˆ†æ",
                        "severity": issue.get("severity", "unknown"),
                        "file": issue.get("file", "unknown"),
                        "line": issue.get("line", "unknown"),
                        "message": issue.get("message", "unknown"),
                        "tool": issue.get("tool", "unknown"),
                        "issue_type": issue.get("type", "unknown")
                    })
        
        # åŠ¨æ€ç›‘æ§é—®é¢˜
        if "dynamic_monitoring" in results:
            dynamic_alerts = results["dynamic_monitoring"].get("alerts", [])
            for alert in dynamic_alerts:
                if self._is_severe_alert(alert):
                    severe_issues.append({
                        "type": "åŠ¨æ€ç›‘æ§",
                        "severity": alert.get("severity", "unknown"),
                        "file": "ç³»ç»Ÿç›‘æ§",
                        "line": "N/A",
                        "message": alert.get("message", "unknown"),
                        "tool": "ç³»ç»Ÿç›‘æ§",
                        "issue_type": alert.get("type", "unknown")
                    })
        
        # è¿è¡Œæ—¶åˆ†æé—®é¢˜
        if "runtime_analysis" in results:
            runtime = results["runtime_analysis"]
            if runtime.get("error"):
                severe_issues.append({
                    "type": "è¿è¡Œæ—¶åˆ†æ",
                    "severity": "error",
                    "file": runtime.get("main_file", "unknown"),
                    "line": "N/A",
                    "message": runtime.get("error"),
                    "tool": "è¿è¡Œæ—¶åˆ†æ",
                    "issue_type": "execution_error"
                })
        
        # åŠ¨æ€æ£€æµ‹é—®é¢˜
        if "dynamic_detection" in results:
            dynamic_issues = results["dynamic_detection"].get("issues", [])
            for issue in dynamic_issues:
                if self._is_severe_dynamic_issue(issue):
                    severe_issues.append({
                        "type": "åŠ¨æ€æ£€æµ‹",
                        "severity": issue.get("severity", "unknown"),
                        "file": issue.get("file", "unknown"),
                        "line": issue.get("line", "N/A"),
                        "message": issue.get("message", "unknown"),
                        "tool": issue.get("test", "unknown"),
                        "issue_type": issue.get("type", "unknown")
                    })
        
        # æŒ‰ä¸¥é‡ç¨‹åº¦å’Œæ–‡ä»¶åˆ†ç»„
        if severe_issues:
            # æŒ‰ä¸¥é‡ç¨‹åº¦æ’åº
            severity_order = {"error": 0, "critical": 0, "warning": 1, "info": 2}
            severe_issues.sort(key=lambda x: severity_order.get(x["severity"], 3))
            
            # æŒ‰æ–‡ä»¶åˆ†ç»„
            issues_by_file = {}
            for issue in severe_issues:
                file_path = issue["file"]
                if file_path not in issues_by_file:
                    issues_by_file[file_path] = []
                issues_by_file[file_path].append(issue)
            
            # ç”ŸæˆæŠ¥å‘Šå†…å®¹
            report_lines.extend([
                f"**å‘ç°ä¸¥é‡é—®é¢˜æ€»æ•°**: {len(severe_issues)}",
                "",
                "## é—®é¢˜è¯¦æƒ…",
                ""
            ])
            
            # æŒ‰æ–‡ä»¶è¾“å‡ºé—®é¢˜
            for file_path, file_issues in issues_by_file.items():
                report_lines.extend([
                    f"### ğŸ“ {file_path}",
                    ""
                ])
                
                for issue in file_issues:
                    severity_emoji = {
                        "error": "âŒ",
                        "critical": "ğŸš¨",
                        "warning": "âš ï¸",
                        "info": "â„¹ï¸"
                    }.get(issue["severity"], "â“")
                    
                    report_lines.extend([
                        f"**{severity_emoji} {issue['severity'].upper()}** - ç¬¬ {issue['line']} è¡Œ",
                        f"- **é—®é¢˜ç±»å‹**: {issue['issue_type']}",
                        f"- **æ£€æµ‹å·¥å…·**: {issue['tool']}",
                        f"- **é—®é¢˜æè¿°**: {issue['message']}",
                        ""
                    ])
            
            # æ·»åŠ ä¿®å¤å»ºè®®
            report_lines.extend([
                "## ä¿®å¤å»ºè®®",
                "",
                "### ä¼˜å…ˆçº§æ’åº",
                "1. **ç«‹å³ä¿®å¤**: é”™è¯¯å’Œä¸¥é‡é—®é¢˜",
                "2. **å°½å¿«ä¿®å¤**: è­¦å‘Šé—®é¢˜",
                "3. **è®¡åˆ’ä¿®å¤**: ä¿¡æ¯ç±»é—®é¢˜",
                "",
                "### ä¿®å¤æ­¥éª¤",
                "1. æŒ‰æ–‡ä»¶é€ä¸ªå¤„ç†é—®é¢˜",
                "2. ä¼˜å…ˆå¤„ç†å½±å“åŠŸèƒ½çš„å…³é”®é—®é¢˜",
                "3. ä¿®å¤åé‡æ–°è¿è¡Œæ£€æµ‹éªŒè¯",
                "4. å»ºç«‹ä»£ç è´¨é‡æ£€æŸ¥æµç¨‹",
                ""
            ])
            
        else:
            report_lines.extend([
                "## æ£€æµ‹ç»“æœ",
                "",
                "âœ… **æœªå‘ç°ä¸¥é‡é—®é¢˜**",
                "",
                "é¡¹ç›®ä»£ç è´¨é‡è‰¯å¥½ï¼Œæœªå‘ç°éœ€è¦ç«‹å³å¤„ç†çš„ä¸¥é‡é—®é¢˜ã€‚",
                "å»ºè®®ç»§ç»­ä¿æŒä»£ç è´¨é‡ï¼Œå®šæœŸè¿›è¡Œä»£ç å®¡æŸ¥ã€‚",
                ""
            ])
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        summary = results.get("summary", {})
        report_lines.extend([
            "## æ£€æµ‹ç»Ÿè®¡",
            "",
            f"- **æ€»æ–‡ä»¶æ•°**: {summary.get('total_files', 0)}",
            f"- **æ€»é—®é¢˜æ•°**: {summary.get('total_issues', 0)}",
            f"- **ä¸¥é‡é—®é¢˜**: {summary.get('critical_issues', 0)}",
            f"- **è­¦å‘Šé—®é¢˜**: {summary.get('warning_issues', 0)}",
            f"- **ä¿¡æ¯é—®é¢˜**: {summary.get('info_issues', 0)}",
            f"- **æ•´ä½“çŠ¶æ€**: {summary.get('overall_status', 'unknown')}",
            "",
            "---",
            f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*"
        ])
        
        return "\n".join(report_lines)
    
    def _is_severe_issue(self, issue: Dict[str, Any]) -> bool:
        """åˆ¤æ–­é™æ€åˆ†æé—®é¢˜æ˜¯å¦ä¸ºä¸¥é‡é—®é¢˜"""
        # æ’é™¤æ ¼å¼åŒ–å’Œé£æ ¼é—®é¢˜
        excluded_types = {
            "import_style", "line_length", "trailing_whitespace", 
            "missing_whitespace", "extra_whitespace", "indentation",
            "blank_line", "spacing", "quotes", "docstring"
        }
        
        issue_type = issue.get("type", "").lower()
        severity = issue.get("severity", "").lower()
        
        # å¦‚æœæ˜¯æ ¼å¼æˆ–é£æ ¼é—®é¢˜ï¼Œç›´æ¥æ’é™¤
        if issue_type in excluded_types:
            return False
        
        # åªä¿ç•™é”™è¯¯å’Œä¸¥é‡é—®é¢˜
        if severity in ["error", "critical"]:
            return True
        
        # å¯¹äºè­¦å‘Šï¼Œåªä¿ç•™é‡è¦çš„ç±»å‹
        if severity == "warning":
            important_warning_types = {
                "security", "performance", "logic_error", "unused_variable",
                "undefined_variable", "import_error", "syntax_error"
            }
            return issue_type in important_warning_types
        
        return False
    
    def _is_severe_alert(self, alert: Dict[str, Any]) -> bool:
        """åˆ¤æ–­åŠ¨æ€ç›‘æ§å‘Šè­¦æ˜¯å¦ä¸ºä¸¥é‡é—®é¢˜"""
        severity = alert.get("severity", "").lower()
        return severity in ["error", "critical", "warning"]
    
    def _is_severe_dynamic_issue(self, issue: Dict[str, Any]) -> bool:
        """åˆ¤æ–­åŠ¨æ€æ£€æµ‹é—®é¢˜æ˜¯å¦ä¸ºä¸¥é‡é—®é¢˜"""
        severity = issue.get("severity", "").lower()
        issue_type = issue.get("type", "").lower()
        
        # åªä¿ç•™é”™è¯¯å’Œä¸¥é‡é—®é¢˜
        if severity in ["error", "critical"]:
            return True
        
        # å¯¹äºè­¦å‘Šï¼Œåªä¿ç•™é‡è¦çš„ç±»å‹
        if severity == "warning":
            important_types = {
                "security", "performance", "functionality", "compatibility"
            }
            return issue_type in important_types
        
        return False

async def generate_ai_comprehensive_report(results: Dict[str, Any], filename: str) -> str:
    """ç”ŸæˆAIç»¼åˆæ£€æµ‹æŠ¥å‘Š"""
    try:
        if not deepseek_config.is_configured():
            print("âš ï¸ DeepSeek APIæœªé…ç½®ï¼Œä½¿ç”¨åŸºç¡€æŠ¥å‘Š")
            return generate_fallback_report(results, filename)
        
        prompt = build_comprehensive_analysis_prompt(results, filename)
        
        print("ğŸ¤– æ­£åœ¨ç”ŸæˆAIç»¼åˆæŠ¥å‘Š...")
        async with httpx.AsyncClient(timeout=180.0) as client:
            response = await client.post(
                f"{deepseek_config.base_url}/chat/completions",
                headers=deepseek_config.get_headers(),
                json={
                    "model": deepseek_config.model,
                    "messages": [
                        {"role": "user", "content": prompt}
                    ],
                    "max_tokens": deepseek_config.max_tokens,
                    "temperature": deepseek_config.temperature
                }
            )
            
            if response.status_code == 200:
                result = response.json()
                ai_content = result["choices"][0]["message"]["content"]
                print("âœ… AIç»¼åˆæŠ¥å‘Šç”ŸæˆæˆåŠŸ")
                return ai_content
            else:
                print(f"âŒ AI APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                return generate_fallback_report(results, filename)
                
    except httpx.TimeoutException:
        print("âŒ AI APIè°ƒç”¨è¶…æ—¶")
        return generate_fallback_report(results, filename)
    except httpx.RequestError as e:
        print(f"âŒ AI APIè¯·æ±‚å¤±è´¥: {e}")
        return generate_fallback_report(results, filename)
    except Exception as e:
        print(f"âŒ AIæŠ¥å‘Šç”Ÿæˆå¼‚å¸¸: {e}")
        return generate_fallback_report(results, filename)

def build_comprehensive_analysis_prompt(results: Dict[str, Any], filename: str) -> str:
    """æ„å»ºç»¼åˆåˆ†ææç¤ºè¯"""
    summary = results.get("summary", {})
    
    prompt = f"""è¯·åˆ†æä»¥ä¸‹ç»¼åˆæ£€æµ‹ç»“æœï¼Œç”Ÿæˆä¸€ä»½è¯¦ç»†çš„è‡ªç„¶è¯­è¨€æŠ¥å‘Šï¼š

## é¡¹ç›®ä¿¡æ¯
- æ–‡ä»¶å: {filename}
- æ£€æµ‹æ—¶é—´: {results.get('timestamp', 'unknown')}
- æ£€æµ‹ç±»å‹: {results.get('detection_type', 'unknown')}
- æ€»æ–‡ä»¶æ•°: {summary.get('total_files', 0)}

## æ£€æµ‹ç»Ÿè®¡
- æ€»é—®é¢˜æ•°: {summary.get('total_issues', 0)}
- ä¸¥é‡é—®é¢˜: {summary.get('critical_issues', 0)}
- è­¦å‘Šé—®é¢˜: {summary.get('warning_issues', 0)}
- ä¿¡æ¯é—®é¢˜: {summary.get('info_issues', 0)}
- æ•´ä½“çŠ¶æ€: {summary.get('overall_status', 'unknown')}

## é™æ€åˆ†æç»“æœ
"""
    
    if "static_analysis" in results:
        static = results["static_analysis"]
        statistics = static.get("statistics", {})
        
        prompt += f"- åˆ†æç±»å‹: {static.get('analysis_type', 'unknown')}\n"
        prompt += f"- åˆ†ææ–‡ä»¶æ•°: {static.get('files_analyzed', 0)}\n"
        prompt += f"- æ€»æ–‡ä»¶æ•°: {statistics.get('total_files', 0)}\n"
        prompt += f"- æ€»ä»£ç è¡Œæ•°: {statistics.get('total_lines', 0)}\n"
        prompt += f"- å¹³å‡å¤æ‚åº¦: {statistics.get('average_complexity', 0)}\n"
        prompt += f"- å¯ç»´æŠ¤æ€§è¯„åˆ†: {statistics.get('maintainability_score', 0)}\n"
        prompt += f"- å‘ç°é—®é¢˜æ•°: {len(static.get('issues', []))}\n"
        
        # æ·»åŠ é—®é¢˜ç»Ÿè®¡
        issues_by_severity = statistics.get("issues_by_severity", {})
        issues_by_tool = statistics.get("issues_by_tool", {})
        
        if issues_by_severity:
            prompt += "\n### é—®é¢˜ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ:\n"
            for severity, count in issues_by_severity.items():
                prompt += f"- {severity}: {count}ä¸ª\n"
        
        if issues_by_tool:
            prompt += "\n### åˆ†æå·¥å…·ç»Ÿè®¡:\n"
            for tool, count in issues_by_tool.items():
                prompt += f"- {tool}: {count}ä¸ªé—®é¢˜\n"
    
    prompt += "\n## åŠ¨æ€ç›‘æ§ç»“æœ\n"
    if "dynamic_monitoring" in results:
        dynamic = results["dynamic_monitoring"]
        prompt += f"- ç›‘æ§æ—¶é•¿: {dynamic.get('duration', 0)}ç§’\n"
        prompt += f"- å‘Šè­¦æ•°é‡: {len(dynamic.get('alerts', []))}\n"
    
    prompt += "\n## è¿è¡Œæ—¶åˆ†æç»“æœï¼ˆç‹¬ç«‹æ£€æµ‹æ¨¡å—ï¼‰\n"
    prompt += "æ³¨æ„ï¼šè¿è¡Œæ—¶åˆ†æä»…ç”¨äºæ£€æŸ¥é¡¹ç›®ä¸»æ–‡ä»¶èƒ½å¦ç›´æ¥æ‰§è¡Œï¼Œä¸åŠ¨æ€æ£€æµ‹çš„æµ‹è¯•æˆåŠŸç‡æ˜¯ç‹¬ç«‹çš„ã€‚\n"
    if "runtime_analysis" in results:
        runtime = results["runtime_analysis"]
        prompt += f"- ä¸»æ–‡ä»¶: {runtime.get('main_file', 'N/A')}\n"
        prompt += f"- æ‰§è¡ŒçŠ¶æ€: {'æˆåŠŸ' if runtime.get('execution_successful', False) else 'å¤±è´¥'}\n"
        if runtime.get("error"):
            prompt += f"- é”™è¯¯ä¿¡æ¯: {runtime.get('error')}\n"
    
    prompt += "\n## åŠ¨æ€æ£€æµ‹ç»“æœï¼ˆFlaskåŠŸèƒ½æµ‹è¯•ï¼‰\n"
    prompt += "æ³¨æ„ï¼šåŠ¨æ€æ£€æµ‹é€šè¿‡å®é™…è¿è¡ŒFlaskåº”ç”¨å¹¶æ‰§è¡ŒåŠŸèƒ½æµ‹è¯•æ¥æ£€æµ‹ç¼ºé™·ï¼Œä¸è¿è¡Œæ—¶åˆ†ææ˜¯ç‹¬ç«‹çš„æ£€æµ‹æ¨¡å—ã€‚\n"
    if "dynamic_detection" in results:
        dynamic_detection = results["dynamic_detection"]
        prompt += f"- çŠ¶æ€: {dynamic_detection.get('status', 'unknown')}\n"
        prompt += f"- æ˜¯Flaské¡¹ç›®: {dynamic_detection.get('is_flask_project', False)}\n"
        prompt += f"- æµ‹è¯•å®Œæˆ: {dynamic_detection.get('tests_completed', False)}\n"
        prompt += f"- æµ‹è¯•æˆåŠŸç‡: {dynamic_detection.get('success_rate', 0)}%\n"
        prompt += f"- å‘ç°é—®é¢˜æ•°: {len(dynamic_detection.get('issues', []))}\n"
        prompt += "é‡è¦è¯´æ˜ï¼š\n"
        prompt += "- å¦‚æœæµ‹è¯•å®Œæˆä¸”æˆåŠŸç‡ä¸º100%ï¼Œè¯´æ˜åŠ¨æ€æ£€æµ‹æµ‹è¯•æ‰§è¡ŒæˆåŠŸ\n"
        prompt += "- è¿è¡Œæ—¶åˆ†æå¤±è´¥ä¸å½±å“åŠ¨æ€æ£€æµ‹çš„æˆåŠŸï¼ˆä¸¤è€…æ£€æµ‹æ–¹å¼ä¸åŒï¼‰\n"
        prompt += "- åŠ¨æ€æ£€æµ‹çš„æˆåŠŸç‡åæ˜ çš„æ˜¯åŠŸèƒ½æµ‹è¯•çš„é€šè¿‡ç‡ï¼Œè€Œä¸æ˜¯æ£€æµ‹æœ¬èº«çš„å¤±è´¥\n"
    
    prompt += """
è¯·ç”Ÿæˆä¸€ä»½è¯¦ç»†çš„è‡ªç„¶è¯­è¨€åˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š
1. é¡¹ç›®æ¦‚è¿°
2. é—®é¢˜åˆ†æï¼ˆè¯·æ˜ç¡®åŒºåˆ†è¿è¡Œæ—¶åˆ†æå¤±è´¥å’ŒåŠ¨æ€æ£€æµ‹å¤±è´¥ï¼Œå®ƒä»¬æ˜¯ä¸åŒçš„æ£€æµ‹æ¨¡å—ï¼‰
3. é£é™©è¯„ä¼°
4. æ”¹è¿›å»ºè®®
5. æ€»ç»“

æŠ¥å‘Šåº”è¯¥ä¸“ä¸šã€è¯¦ç»†ä¸”æ˜“äºç†è§£ã€‚
ç‰¹åˆ«æ³¨æ„ï¼š
- å¦‚æœåŠ¨æ€æ£€æµ‹æ˜¾ç¤º"æµ‹è¯•å®Œæˆ: True, æˆåŠŸç‡: 100%"ï¼Œè¯´æ˜åŠ¨æ€æ£€æµ‹æœ¬èº«æ˜¯æˆåŠŸçš„
- è¿è¡Œæ—¶åˆ†æå¤±è´¥åªè¡¨ç¤ºä¸»æ–‡ä»¶æ— æ³•ç›´æ¥æ‰§è¡Œï¼Œä¸ä»£è¡¨åŠ¨æ€æ£€æµ‹å¤±è´¥
- è¯·åœ¨æŠ¥å‘Šä¸­æ˜ç¡®è¯´æ˜è¿™ä¸¤ä¸ªæ£€æµ‹æ¨¡å—çš„åŒºåˆ«å’Œå„è‡ªçš„æ£€æµ‹ç»“æœ"""
    
    return prompt

def generate_fallback_report(results: Dict[str, Any], filename: str) -> str:
    """ç”ŸæˆåŸºç¡€æŠ¥å‘Šï¼ˆå½“AI APIä¸å¯ç”¨æ—¶ï¼‰"""
    summary = results.get("summary", {})
    
    report = f"""# ç»¼åˆæ£€æµ‹æŠ¥å‘Š

## é¡¹ç›®æ¦‚è¿°
- **é¡¹ç›®åç§°**: {filename}
- **æ£€æµ‹æ—¶é—´**: {results.get('timestamp', 'unknown')}
- **æ£€æµ‹ç±»å‹**: {results.get('detection_type', 'unknown')}
- **æ€»æ–‡ä»¶æ•°**: {summary.get('total_files', 0)}

## æ£€æµ‹ç»“æœæ‘˜è¦
- **æ€»é—®é¢˜æ•°**: {summary.get('total_issues', 0)}
- **ä¸¥é‡é—®é¢˜**: {summary.get('critical_issues', 0)}
- **è­¦å‘Šé—®é¢˜**: {summary.get('warning_issues', 0)}
- **ä¿¡æ¯é—®é¢˜**: {summary.get('info_issues', 0)}
- **æ•´ä½“çŠ¶æ€**: {summary.get('overall_status', 'unknown')}

## é—®é¢˜åˆ†æ
"""
    
    if summary.get('critical_issues', 0) > 0:
        report += "âš ï¸ **å‘ç°ä¸¥é‡é—®é¢˜**ï¼Œéœ€è¦ç«‹å³å¤„ç†\n"
    if summary.get('warning_issues', 0) > 0:
        report += "âš ï¸ **å‘ç°è­¦å‘Šé—®é¢˜**ï¼Œå»ºè®®åŠæ—¶å¤„ç†\n"
    if summary.get('info_issues', 0) > 0:
        report += "â„¹ï¸ **å‘ç°ä¿¡æ¯é—®é¢˜**ï¼Œå¯é€‰æ‹©æ€§å¤„ç†\n"
    
    if summary.get('total_issues', 0) == 0:
        report += "âœ… **æœªå‘ç°æ˜æ˜¾é—®é¢˜**\n"
    
    # æ·»åŠ å»ºè®®
    recommendations = summary.get('recommendations', [])
    if recommendations:
        report += "\n## æ”¹è¿›å»ºè®®\n"
        for i, rec in enumerate(recommendations, 1):
            report += f"{i}. {rec}\n"
    
    report += "\n## æ€»ç»“\n"
    if summary.get('overall_status') == 'good':
        report += "é¡¹ç›®æ•´ä½“è´¨é‡è‰¯å¥½ï¼Œæœªå‘ç°ä¸¥é‡é—®é¢˜ã€‚å»ºè®®ç»§ç»­ä¿æŒä»£ç è´¨é‡ï¼Œå®šæœŸè¿›è¡Œä»£ç å®¡æŸ¥ã€‚"
    elif summary.get('overall_status') == 'warning':
        report += "é¡¹ç›®å­˜åœ¨ä¸€äº›è­¦å‘Šé—®é¢˜ï¼Œå»ºè®®åŠæ—¶å¤„ç†ã€‚é‡ç‚¹å…³æ³¨ä»£ç è´¨é‡å’Œå¯ç»´æŠ¤æ€§ã€‚"
    elif summary.get('overall_status') == 'error':
        report += "é¡¹ç›®å­˜åœ¨ä¸¥é‡é—®é¢˜ï¼Œéœ€è¦ç«‹å³ä¿®å¤ã€‚å»ºè®®ä¼˜å…ˆå¤„ç†ä¸¥é‡é—®é¢˜ï¼Œç„¶åé€æ­¥æ”¹è¿›ä»£ç è´¨é‡ã€‚"
    else:
        report += "è¯·æ ¹æ®å…·ä½“é—®é¢˜æƒ…å†µè¿›è¡Œç›¸åº”å¤„ç†ã€‚å»ºè®®å®šæœŸè¿›è¡Œä»£ç è´¨é‡æ£€æŸ¥ã€‚"
    
    return report

# APIç«¯ç‚¹
@router.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "ç»¼åˆæ£€æµ‹APIè¿è¡Œä¸­",
        "version": "2.0.0",
        "timestamp": datetime.now().isoformat()
    }

@router.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "service": "comprehensive_detection"
    }

@router.post("/detect", response_model=BaseResponse)
async def comprehensive_detect(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(None),
    files: List[UploadFile] = File(None),
    static_analysis: str = Form("true"),
    dynamic_monitoring: str = Form("true"),
    runtime_analysis: str = Form("true"),
    enable_web_app_test: str = Form("false"),
    enable_dynamic_detection: str = Form("true"),
    enable_flask_specific_tests: str = Form("true"),
    enable_server_testing: str = Form("true"),
    upload_type: str = Form("file"),
    # é™æ€æ£€æµ‹å·¥å…·é€‰æ‹©å‚æ•°
    enable_pylint: str = Form("true"),
    enable_mypy: str = Form("true"),
    enable_semgrep: str = Form("true"),
    enable_ruff: str = Form("true"),
    enable_bandit: str = Form("true"),
    enable_llm_filter: str = Form("true")
):
    """ç»¼åˆæ£€æµ‹ - å¹¶è¡Œæ‰§è¡Œé™æ€æ£€æµ‹å’ŒåŠ¨æ€æ£€æµ‹"""
    
    # ç¡®ä¿æ‰€æœ‰å¸ƒå°”å‚æ•°éƒ½æ˜¯å¸ƒå°”å€¼
    def convert_to_bool(value, param_name):
        if isinstance(value, str):
            result = value.lower() in ('true', '1', 'yes', 'on')
            return result
        elif isinstance(value, bool):
            return value
        else:
            return bool(value)
    
    static_analysis = convert_to_bool(static_analysis, 'static_analysis')
    dynamic_monitoring = convert_to_bool(dynamic_monitoring, 'dynamic_monitoring')
    runtime_analysis = convert_to_bool(runtime_analysis, 'runtime_analysis')
    enable_web_app_test = convert_to_bool(enable_web_app_test, 'enable_web_app_test')
    enable_dynamic_detection = convert_to_bool(enable_dynamic_detection, 'enable_dynamic_detection')
    enable_flask_specific_tests = convert_to_bool(enable_flask_specific_tests, 'enable_flask_specific_tests')
    enable_server_testing = convert_to_bool(enable_server_testing, 'enable_server_testing')
    # é™æ€æ£€æµ‹å·¥å…·é€‰æ‹©
    enable_pylint = convert_to_bool(enable_pylint, 'enable_pylint')
    enable_mypy = convert_to_bool(enable_mypy, 'enable_mypy')
    enable_semgrep = convert_to_bool(enable_semgrep, 'enable_semgrep')
    enable_ruff = convert_to_bool(enable_ruff, 'enable_ruff')
    enable_bandit = convert_to_bool(enable_bandit, 'enable_bandit')
    enable_llm_filter = convert_to_bool(enable_llm_filter, 'enable_llm_filter')
    
    # éªŒè¯è¾“å…¥
    if not file and not files:
        raise HTTPException(status_code=400, detail="è¯·æä¾›æ–‡ä»¶æˆ–æ–‡ä»¶åˆ—è¡¨")
    
    if file and files:
        raise HTTPException(status_code=400, detail="è¯·é€‰æ‹©å•æ–‡ä»¶ä¸Šä¼ æˆ–ç›®å½•ä¸Šä¼ ï¼Œä¸èƒ½åŒæ—¶ä½¿ç”¨")
    
    # å¤„ç†å•æ–‡ä»¶ä¸Šä¼ ï¼ˆå‹ç¼©åŒ…ï¼‰
    if file:
        if not file.filename.endswith('.zip'):
            raise HTTPException(status_code=400, detail="åªæ”¯æŒZIPæ ¼å¼çš„å‹ç¼©åŒ…")
        upload_files = [file]
        filename = file.filename
    else:
        # å¤„ç†å¤šæ–‡ä»¶ä¸Šä¼ ï¼ˆç›®å½•ï¼‰
        if not files or len(files) == 0:
            raise HTTPException(status_code=400, detail="ç›®å½•ä¸Šä¼ éœ€è¦è‡³å°‘ä¸€ä¸ªæ–‡ä»¶")
        upload_files = files
        filename = f"directory_{len(files)}_files"
    
    temp_file_path = None
    temp_dir = None
    
    try:
        print(f"å¼€å§‹å¤„ç†ä¸Šä¼ æ–‡ä»¶: {filename}")
        
        if upload_type == "file":
            # å•æ–‡ä»¶ä¸Šä¼ ï¼ˆå‹ç¼©åŒ…ï¼‰
            file = upload_files[0]
            with tempfile.NamedTemporaryFile(delete=False, suffix='.zip') as tmp_file:
                content = await file.read()
                tmp_file.write(content)
                temp_file_path = tmp_file.name
            print(f"å‹ç¼©åŒ…å·²ä¿å­˜åˆ°ä¸´æ—¶ä½ç½®: {temp_file_path}")
        else:
            # ç›®å½•ä¸Šä¼ ï¼ˆå¤šæ–‡ä»¶ï¼‰
            temp_dir = tempfile.mkdtemp(prefix="comprehensive_detection_")
            print(f"åˆ›å»ºä¸´æ—¶ç›®å½•: {temp_dir}")
            
            # ä¿å­˜æ‰€æœ‰æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
            for file in upload_files:
                if file.filename:
                    # å¤„ç†æ–‡ä»¶è·¯å¾„ç»“æ„
                    if '/' in file.filename or '\\' in file.filename:
                        file_path = os.path.join(temp_dir, file.filename)
                    else:
                        file_path = os.path.join(temp_dir, file.filename)
                    
                    os.makedirs(os.path.dirname(file_path), exist_ok=True)
                    
                    with open(file_path, "wb") as f:
                        content = await file.read()
                        f.write(content)
                    print(f"ä¿å­˜æ–‡ä»¶: {file.filename} -> {file_path}")
            
            # åˆ›å»ºZIPæ–‡ä»¶
            temp_file_path = os.path.join(temp_dir, "project.zip")
            with zipfile.ZipFile(temp_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for root, dirs, files in os.walk(temp_dir):
                    for file in files:
                        if file != "project.zip":  # é¿å…åŒ…å«è‡ªå·±
                            file_path = os.path.join(root, file)
                            arcname = os.path.relpath(file_path, temp_dir)
                            zipf.write(file_path, arcname)
            
            print(f"ç›®å½•å·²æ‰“åŒ…ä¸ºZIP: {temp_file_path}")
        
        # ä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºç‹¬ç«‹çš„æ£€æµ‹å™¨å®ä¾‹
        detector = ComprehensiveDetector(static_agent, dynamic_agent)
        detector.enable_web_app_test = enable_web_app_test
        detector.enable_dynamic_detection = enable_dynamic_detection
        detector.enable_flask_specific_tests = enable_flask_specific_tests
        detector.enable_server_testing = enable_server_testing
        
        # æ‰§è¡Œæ£€æµ‹ï¼ˆæ·»åŠ è¶…æ—¶å¤„ç†ï¼‰
        print("=" * 60)
        print("ğŸš€ [API] å¼€å§‹æ‰§è¡Œç»¼åˆæ£€æµ‹...")
        print(f"ğŸ“ [API] æ–‡ä»¶è·¯å¾„: {temp_file_path}")
        print(f"âš™ï¸  [API] æ£€æµ‹é€‰é¡¹:")
        print(f"   - static_analysis: {static_analysis}")
        print(f"   - dynamic_monitoring: {dynamic_monitoring}")
        print(f"   - runtime_analysis: {runtime_analysis}")
        print(f"   - enable_dynamic_detection: {enable_dynamic_detection}")
        print(f"   - enable_flask_specific_tests: {enable_flask_specific_tests}")
        print(f"   - enable_server_testing: {enable_server_testing}")
        print(f"   - enable_pylint: {enable_pylint}")
        print(f"   - enable_mypy: {enable_mypy}")
        print(f"   - enable_semgrep: {enable_semgrep}")
        print(f"   - enable_ruff: {enable_ruff}")
        print(f"   - enable_bandit: {enable_bandit}")
        print(f"   - enable_llm_filter: {enable_llm_filter}")
        print("=" * 60)
        
        if enable_web_app_test or enable_server_testing:
            print("âš ï¸ å·²å¯ç”¨Webåº”ç”¨æµ‹è¯•ï¼Œæ£€æµ‹æ—¶é—´å¯èƒ½è¾ƒé•¿...")
        
        try:
            results = await asyncio.wait_for(
                detector.detect_defects(
                    zip_file_path=temp_file_path,
                    static_analysis=static_analysis,
                    dynamic_monitoring=dynamic_monitoring,
                    runtime_analysis=runtime_analysis,
                    enable_dynamic_detection=enable_dynamic_detection,
                    enable_flask_specific_tests=enable_flask_specific_tests,
                    enable_server_testing=enable_server_testing,
                    # é™æ€æ£€æµ‹å·¥å…·é€‰æ‹©
                    enable_pylint=enable_pylint,
                    enable_mypy=enable_mypy,
                    enable_semgrep=enable_semgrep,
                    enable_ruff=enable_ruff,
                    enable_bandit=enable_bandit,
                    enable_llm_filter=enable_llm_filter
                ),
                timeout=600  # 10åˆ†é’Ÿè¶…æ—¶
            )
            print("=" * 60)
            print("âœ… [API] æ£€æµ‹å®Œæˆ")
            print(f"ğŸ“Š [API] æ£€æµ‹ç»“æœæ‘˜è¦:")
            if results.get("summary"):
                summary = results["summary"]
                print(f"   - æ€»æ–‡ä»¶æ•°: {summary.get('total_files', 0)}")
                print(f"   - æ€»é—®é¢˜æ•°: {summary.get('total_issues', 0)}")
                print(f"   - ä¸¥é‡é—®é¢˜: {summary.get('critical_issues', 0)}")
                print(f"   - è­¦å‘Šé—®é¢˜: {summary.get('warning_issues', 0)}")
            if results.get("merged_defects"):
                print(f"   - åˆå¹¶ç¼ºé™·æ•°: {len(results['merged_defects'])}")
            if results.get("task_info_file"):
                print(f"   - ä»»åŠ¡ä¿¡æ¯æ–‡ä»¶: {results['task_info_file']}")
            if results.get("task_info"):
                print(f"   - ä»»åŠ¡æ•°é‡: {len(results['task_info'])}")
            print("=" * 60)
        except asyncio.TimeoutError:
            return BaseResponse(
                success=False,
                error="æ£€æµ‹è¶…æ—¶ï¼ˆ10åˆ†é’Ÿï¼‰",
                message="æ£€æµ‹è¿‡ç¨‹è¶…æ—¶ï¼Œè¯·å°è¯•ä¸Šä¼ è¾ƒå°çš„é¡¹ç›®"
            )
        
        print("\nğŸ“ [API] æ£€æµ‹å®Œæˆï¼Œç”ŸæˆæŠ¥å‘Š...")
        
        # ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
        report = detector.generate_report(results)
        print("âœ… [API] æ–‡æœ¬æŠ¥å‘Šå·²ç”Ÿæˆ")
        
        # ç”ŸæˆAIæŠ¥å‘Š
        try:
            filename = file.filename if file else (files[0].filename if files else "unknown")
            ai_report = await generate_ai_comprehensive_report(results, filename)
            print("âœ… [API] AIæŠ¥å‘Šç”ŸæˆæˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ [API] AIæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            ai_report = {
                "success": False,
                "error": str(e),
                "summary": "AIæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œè¯·æŸ¥çœ‹è¯¦ç»†æ£€æµ‹ç»“æœ"
            }
        
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶ï¼ˆä½¿ç”¨ç»å¯¹è·¯å¾„ï¼‰
        try:
            results_file = f"comprehensive_detection_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            # è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆAPIæ–‡ä»¶æ‰€åœ¨ç›®å½•çš„çˆ¶ç›®å½•ï¼‰
            api_dir = Path(__file__).parent
            project_root = api_dir.parent
            results_dir = project_root / "comprehensive_detection_results"
            results_dir.mkdir(exist_ok=True)
            results_path = results_dir / results_file
            results_path_abs = results_path.resolve()
            detector.save_results(results, str(results_path_abs))
            print(f"âœ… [API] ç»“æœå·²ä¿å­˜åˆ°:")
            print(f"   ç›¸å¯¹è·¯å¾„: {results_path}")
            print(f"   ç»å¯¹è·¯å¾„: {results_path_abs}")
            print(f"ğŸ“Š [API] æ–‡ä»¶å¤§å°: {results_path_abs.stat().st_size / 1024:.2f} KB")
        except Exception as e:
            print(f"âš ï¸ [API] ä¿å­˜ç»“æœæ–‡ä»¶å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            results_file = None
        
        # æ£€æŸ¥ä»»åŠ¡ä¿¡æ¯æ–‡ä»¶
        if results.get("task_info_file"):
            task_info_path = Path(results["task_info_file"])
            task_info_path_abs = task_info_path.resolve()
            if task_info_path_abs.exists():
                print(f"âœ… [API] ä»»åŠ¡ä¿¡æ¯æ–‡ä»¶å·²ä¿å­˜:")
                print(f"   ç›¸å¯¹è·¯å¾„: {task_info_path}")
                print(f"   ç»å¯¹è·¯å¾„: {task_info_path_abs}")
                print(f"ğŸ“Š [API] ä»»åŠ¡æ•°é‡: {len(results.get('task_info', []))}")
                print(f"ğŸ“Š [API] æ–‡ä»¶å¤§å°: {task_info_path_abs.stat().st_size / 1024:.2f} KB")
            else:
                print(f"âš ï¸ [API] è­¦å‘Š: ä»»åŠ¡ä¿¡æ¯æ–‡ä»¶è·¯å¾„å­˜åœ¨ä½†æ–‡ä»¶ä¸å­˜åœ¨:")
                print(f"   ç›¸å¯¹è·¯å¾„: {task_info_path}")
                print(f"   ç»å¯¹è·¯å¾„: {task_info_path_abs}")
                print(f"   å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
        else:
            print("âš ï¸ [API] è­¦å‘Š: æœªç”Ÿæˆä»»åŠ¡ä¿¡æ¯æ–‡ä»¶")
        
        # è¿”å›ç»“æœ
        return BaseResponse(
            success=True,
            message="ç»¼åˆæ£€æµ‹å®Œæˆ",
            data={
                "results": results,
                "report": report,
                "ai_report": ai_report,
                "results_file": results_file,
                "filename": file.filename,
                "detection_time": datetime.now().isoformat()
            }
        )
    
    finally:
        # æ³¨æ„ï¼šä¸´æ—¶æ–‡ä»¶ä¿ç•™ï¼Œä¸åˆ é™¤ä¸Šä¼ çš„æ–‡ä»¶ï¼Œä»¥ä¾¿ä¿®å¤Agentä½¿ç”¨
        # åªåˆ é™¤ä¸Šä¼ çš„ZIPå‹ç¼©åŒ…ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if temp_file_path and os.path.exists(temp_file_path):
            # æ£€æŸ¥æ˜¯å¦æ˜¯ZIPæ–‡ä»¶ï¼ˆä¸Šä¼ çš„å‹ç¼©åŒ…å¯ä»¥åˆ é™¤ï¼‰
            # è§£å‹åçš„ç›®å½•ä¿ç•™åœ¨extract_dirä¸­ï¼Œä¸åœ¨è¿™é‡Œåˆ é™¤
            try:
                # åªåˆ é™¤ZIPæ–‡ä»¶ï¼Œä¸åˆ é™¤è§£å‹åçš„ç›®å½•
                if temp_file_path.endswith('.zip'):
                    os.unlink(temp_file_path)
                    print(f"âœ… [API] å·²æ¸…ç†ä¸Šä¼ çš„ZIPæ–‡ä»¶: {temp_file_path}")
                else:
                    print(f"ğŸ“ [API] ä¿ç•™æ–‡ä»¶: {temp_file_path}")
            except Exception as e:
                print(f"âš ï¸ [API] æ¸…ç†ZIPæ–‡ä»¶å¤±è´¥: {e}")
        
        # ä¸æ¸…ç†ä¸´æ—¶ç›®å½•ï¼Œä¿ç•™è§£å‹åçš„é¡¹ç›®æ–‡ä»¶
        # extract_dirä¸­çš„æ–‡ä»¶éœ€è¦ä¿ç•™ä¾›ä¿®å¤Agentä½¿ç”¨
        if temp_dir and os.path.exists(temp_dir):
            print(f"ğŸ“ [API] ä¿ç•™ä¸´æ—¶ç›®å½•ï¼ˆè§£å‹åçš„é¡¹ç›®æ–‡ä»¶ï¼‰: {temp_dir}")
            print(f"âš ï¸ [API] æ³¨æ„: ä¸´æ—¶ç›®å½•æœªåˆ é™¤ï¼Œéœ€è¦å®šæœŸæ¸…ç†ä»¥é‡Šæ”¾ç£ç›˜ç©ºé—´")

@router.get("/status")
async def get_detection_status():
    """è·å–æ£€æµ‹çŠ¶æ€"""
    return {
        "status": "ready",
        "timestamp": datetime.now().isoformat(),
        "supported_formats": [".zip"],
        "features": {
            "static_analysis": True,
            "dynamic_monitoring": True,
            "runtime_analysis": True,
            "comprehensive_detection": True
        }
    }

@router.post("/generate-severe-issues-report")
async def generate_severe_issues_report(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(None),
    files: List[UploadFile] = File(None),
    static_analysis: str = Form("true"),
    dynamic_monitoring: str = Form("true"),
    runtime_analysis: str = Form("true"),
    enable_web_app_test: str = Form("false"),
    enable_dynamic_detection: str = Form("true"),
    enable_flask_specific_tests: str = Form("true"),
    enable_server_testing: str = Form("true"),
    upload_type: str = Form("file")
):
    """ç”Ÿæˆä¸¥é‡é—®é¢˜æ±‡æ€»æ–‡æ¡£"""
    
    # ç¡®ä¿æ‰€æœ‰å¸ƒå°”å‚æ•°éƒ½æ˜¯å¸ƒå°”å€¼
    def convert_to_bool(value, param_name):
        if isinstance(value, str):
            result = value.lower() in ('true', '1', 'yes', 'on')
            return result
        elif isinstance(value, bool):
            return value
        else:
            return bool(value)
    
    static_analysis = convert_to_bool(static_analysis, 'static_analysis')
    dynamic_monitoring = convert_to_bool(dynamic_monitoring, 'dynamic_monitoring')
    runtime_analysis = convert_to_bool(runtime_analysis, 'runtime_analysis')
    enable_web_app_test = convert_to_bool(enable_web_app_test, 'enable_web_app_test')
    enable_dynamic_detection = convert_to_bool(enable_dynamic_detection, 'enable_dynamic_detection')
    enable_flask_specific_tests = convert_to_bool(enable_flask_specific_tests, 'enable_flask_specific_tests')
    enable_server_testing = convert_to_bool(enable_server_testing, 'enable_server_testing')
    
    # éªŒè¯è¾“å…¥
    if not file and not files:
        raise HTTPException(status_code=400, detail="è¯·æä¾›æ–‡ä»¶æˆ–æ–‡ä»¶åˆ—è¡¨")
    
    if file and files:
        raise HTTPException(status_code=400, detail="è¯·é€‰æ‹©å•æ–‡ä»¶ä¸Šä¼ æˆ–ç›®å½•ä¸Šä¼ ï¼Œä¸èƒ½åŒæ—¶ä½¿ç”¨")
    
    # å¤„ç†å•æ–‡ä»¶ä¸Šä¼ ï¼ˆå‹ç¼©åŒ…ï¼‰
    if file:
        if not file.filename.endswith('.zip'):
            raise HTTPException(status_code=400, detail="åªæ”¯æŒZIPæ ¼å¼çš„å‹ç¼©åŒ…")
        upload_files = [file]
        filename = file.filename
    else:
        # å¤„ç†å¤šæ–‡ä»¶ä¸Šä¼ ï¼ˆç›®å½•ï¼‰
        if not files or len(files) == 0:
            raise HTTPException(status_code=400, detail="ç›®å½•ä¸Šä¼ éœ€è¦è‡³å°‘ä¸€ä¸ªæ–‡ä»¶")
        upload_files = files
        filename = f"directory_{len(files)}_files"
    
    temp_file_path = None
    temp_dir = None
    
    try:
        print(f"å¼€å§‹å¤„ç†ä¸Šä¼ æ–‡ä»¶: {filename}")
        
        if upload_type == "file":
            # å•æ–‡ä»¶ä¸Šä¼ ï¼ˆå‹ç¼©åŒ…ï¼‰
            file = upload_files[0]
            with tempfile.NamedTemporaryFile(delete=False, suffix='.zip') as tmp_file:
                content = await file.read()
                tmp_file.write(content)
                temp_file_path = tmp_file.name
            print(f"å‹ç¼©åŒ…å·²ä¿å­˜åˆ°ä¸´æ—¶ä½ç½®: {temp_file_path}")
        else:
            # ç›®å½•ä¸Šä¼ ï¼ˆå¤šæ–‡ä»¶ï¼‰
            temp_dir = tempfile.mkdtemp(prefix="comprehensive_detection_")
            print(f"åˆ›å»ºä¸´æ—¶ç›®å½•: {temp_dir}")
            
            # ä¿å­˜æ‰€æœ‰æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
            for file in upload_files:
                if file.filename:
                    # å¤„ç†æ–‡ä»¶è·¯å¾„ç»“æ„
                    if '/' in file.filename or '\\' in file.filename:
                        file_path = os.path.join(temp_dir, file.filename)
                    else:
                        file_path = os.path.join(temp_dir, file.filename)
                    
                    os.makedirs(os.path.dirname(file_path), exist_ok=True)
                    
                    with open(file_path, "wb") as f:
                        content = await file.read()
                        f.write(content)
                    print(f"ä¿å­˜æ–‡ä»¶: {file.filename} -> {file_path}")
            
            # åˆ›å»ºZIPæ–‡ä»¶
            temp_file_path = os.path.join(temp_dir, "project.zip")
            with zipfile.ZipFile(temp_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for root, dirs, files in os.walk(temp_dir):
                    for file in files:
                        if file != "project.zip":  # é¿å…åŒ…å«è‡ªå·±
                            file_path = os.path.join(root, file)
                            arcname = os.path.relpath(file_path, temp_dir)
                            zipf.write(file_path, arcname)
            
            print(f"ç›®å½•å·²æ‰“åŒ…ä¸ºZIP: {temp_file_path}")
        
        # ä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºç‹¬ç«‹çš„æ£€æµ‹å™¨å®ä¾‹
        detector = ComprehensiveDetector(static_agent, dynamic_agent)
        detector.enable_web_app_test = enable_web_app_test
        detector.enable_dynamic_detection = enable_dynamic_detection
        detector.enable_flask_specific_tests = enable_flask_specific_tests
        detector.enable_server_testing = enable_server_testing
        
        # æ‰§è¡Œæ£€æµ‹
        print("å¼€å§‹æ‰§è¡Œç»¼åˆæ£€æµ‹...")
        try:
            results = await asyncio.wait_for(
                detector.detect_defects(
                    zip_file_path=temp_file_path,
                    static_analysis=static_analysis,
                    dynamic_monitoring=dynamic_monitoring,
                    runtime_analysis=runtime_analysis,
                    enable_dynamic_detection=enable_dynamic_detection,
                    enable_flask_specific_tests=enable_flask_specific_tests,
                    enable_server_testing=enable_server_testing,
                    enable_web_app_test=enable_web_app_test
                ),
                timeout=600  # 10åˆ†é’Ÿè¶…æ—¶
            )
        except asyncio.TimeoutError:
            return BaseResponse(
                success=False,
                error="æ£€æµ‹è¶…æ—¶ï¼ˆ10åˆ†é’Ÿï¼‰",
                message="æ£€æµ‹è¿‡ç¨‹è¶…æ—¶ï¼Œè¯·å°è¯•ä¸Šä¼ è¾ƒå°çš„é¡¹ç›®"
            )
        
        print("æ£€æµ‹å®Œæˆï¼Œç”Ÿæˆä¸¥é‡é—®é¢˜æ±‡æ€»æ–‡æ¡£...")
        
        # ç”Ÿæˆä¸¥é‡é—®é¢˜æ±‡æ€»æ–‡æ¡£
        severe_issues_report = detector.generate_severe_issues_report(results, filename)
        
        # ä¿å­˜æ–‡æ¡£åˆ°resultæ–‡ä»¶å¤¹
        try:
            report_filename = f"severe_issues_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
            result_dir = Path("result")
            result_dir.mkdir(exist_ok=True)
            report_path = result_dir / report_filename
            
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(severe_issues_report)
            
            print(f"âœ… ä¸¥é‡é—®é¢˜æ±‡æ€»æ–‡æ¡£å·²ä¿å­˜åˆ°: {report_path}")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜æ–‡æ¡£æ–‡ä»¶å¤±è´¥: {e}")
            report_filename = None
        
        # è¿”å›ç»“æœ
        return BaseResponse(
            success=True,
            message="ä¸¥é‡é—®é¢˜æ±‡æ€»æ–‡æ¡£ç”Ÿæˆå®Œæˆ",
            data={
                "severe_issues_report": severe_issues_report,
                "report_filename": report_filename,
                "report_path": str(report_path) if report_filename else None,
                "filename": filename,
                "generation_time": datetime.now().isoformat(),
                "summary": results.get("summary", {})
            }
        )
    
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_file_path and os.path.exists(temp_file_path):
            try:
                os.unlink(temp_file_path)
                print(f"å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_file_path}")
            except Exception as e:
                print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
        
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        if temp_dir and os.path.exists(temp_dir):
            try:
                import shutil
                shutil.rmtree(temp_dir)
                print(f"å·²æ¸…ç†ä¸´æ—¶ç›®å½•: {temp_dir}")
            except Exception as e:
                print(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")
