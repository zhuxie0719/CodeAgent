"""
ç»¼åˆæ£€æµ‹API
ç»Ÿä¸€çš„æ£€æµ‹å…¥å£ï¼Œé›†æˆé™æ€æ£€æµ‹å’ŒåŠ¨æ€æ£€æµ‹åŠŸèƒ½
"""

import asyncio
import tempfile
import os
import json
import sys
import httpx
import zipfile
import shutil
from datetime import datetime
from typing import Dict, Any, Optional, List
from pathlib import Path

from fastapi import APIRouter, File, UploadFile, HTTPException, BackgroundTasks, Form
from pydantic import BaseModel, Field

# å¯¼å…¥æ£€æµ‹ç»„ä»¶
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from agents.dynamic_detection_agent.agent import DynamicDetectionAgent
from agents.bug_detection_agent.agent import BugDetectionAgent
from api.deepseek_config import deepseek_config

# æ•°æ®æ¨¡å‹
class BaseResponse(BaseModel):
    """åŸºç¡€å“åº”æ¨¡å‹"""
    success: bool = Field(True, description="æ˜¯å¦æˆåŠŸ")
    message: str = Field("", description="å“åº”æ¶ˆæ¯")
    data: Optional[Dict[str, Any]] = Field(None, description="å“åº”æ•°æ®")
    error: Optional[str] = Field(None, description="é”™è¯¯ä¿¡æ¯")

class DetectionRequest(BaseModel):
    """æ£€æµ‹è¯·æ±‚æ¨¡å‹"""
    static_analysis: bool = Field(True, description="æ˜¯å¦è¿›è¡Œé™æ€åˆ†æ")
    dynamic_monitoring: bool = Field(True, description="æ˜¯å¦è¿›è¡ŒåŠ¨æ€ç›‘æ§")
    runtime_analysis: bool = Field(True, description="æ˜¯å¦è¿›è¡Œè¿è¡Œæ—¶åˆ†æ")

# åˆ›å»ºAPIRouter
router = APIRouter()

# å…¨å±€ç®¡ç†å™¨å¼•ç”¨ï¼ˆåœ¨ main_api.py ä¸­è®¾ç½®ï¼‰
_coordinator_manager = None
_agent_manager = None

def set_managers(coord_mgr, agent_mgr):
    """è®¾ç½®å…¨å±€ç®¡ç†å™¨å¼•ç”¨"""
    global _coordinator_manager, _agent_manager
    _coordinator_manager = coord_mgr
    _agent_manager = agent_mgr

# å…¨å±€æ£€æµ‹å™¨ï¼ˆä¿ç•™ç”¨äºç›´æ¥è°ƒç”¨ï¼Œä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆï¼‰
dynamic_agent = DynamicDetectionAgent({
    "monitor_interval": 5,
    "alert_thresholds": {
        "cpu_threshold": 80,
        "memory_threshold": 85,
        "disk_threshold": 90,
        "network_threshold": 80
    },
    "enable_web_app_test": False,
    "enable_dynamic_detection": True,
    "enable_flask_specific_tests": True,
    "enable_server_testing": True
})

# æ£€æŸ¥æ˜¯å¦å¯ç”¨Dockeræ”¯æŒï¼ˆé€šè¿‡ç¯å¢ƒå˜é‡ï¼Œé»˜è®¤ç¦ç”¨ï¼‰
use_docker = os.getenv("USE_DOCKER", "true").lower() == "true"

static_agent = BugDetectionAgent({
    "enable_ai_analysis": True,
    "analysis_depth": "comprehensive",
    "use_docker": use_docker
})

# æ³¨æ„ï¼šåŠ¨æ€æ£€æµ‹ä¸ä½¿ç”¨Dockerï¼Œå®ƒç›´æ¥ä½¿ç”¨æœ¬åœ°è™šæ‹Ÿç¯å¢ƒ

class ComprehensiveDetector:
    """ç»¼åˆæ£€æµ‹å™¨ï¼Œé›†æˆé™æ€æ£€æµ‹å’ŒåŠ¨æ€æ£€æµ‹åŠŸèƒ½"""
    
    def __init__(self, static_agent, dynamic_agent):
        self.static_agent = static_agent
        self.dynamic_agent = dynamic_agent
        self.enable_web_app_test = False
        self.enable_dynamic_detection = True
        self.enable_flask_specific_tests = True
        self.enable_server_testing = True
    
    async def detect_defects(self, zip_file_path: str, 
                           static_analysis: bool = True,
                           dynamic_monitoring: bool = True,
                           runtime_analysis: bool = True,
                           enable_web_app_test: bool = False,
                           enable_dynamic_detection: bool = True,
                           enable_flask_specific_tests: bool = True,
                           enable_server_testing: bool = True,
                           # é™æ€æ£€æµ‹å·¥å…·é€‰æ‹©
                           enable_pylint: bool = True,
                           enable_mypy: bool = True,
                           enable_semgrep: bool = True,
                           enable_ruff: bool = True,
                           enable_bandit: bool = True,
                           enable_llm_filter: bool = True) -> Dict[str, Any]:
        """æ‰§è¡Œç»¼åˆæ£€æµ‹"""
        # è®¾ç½®enable_web_app_testå±æ€§ï¼Œå¹¶åŒæ­¥åˆ°dynamic_agent
        self.enable_web_app_test = enable_web_app_test
        if hasattr(self.dynamic_agent, 'enable_web_app_test'):
            self.dynamic_agent.enable_web_app_test = enable_web_app_test
        
        results = {
            "detection_type": "comprehensive",
            "timestamp": datetime.now().isoformat(),
            "zip_file": zip_file_path,
            "analysis_options": {
                "static_analysis": static_analysis,
                "dynamic_monitoring": dynamic_monitoring,
                "runtime_analysis": runtime_analysis,
                "enable_web_app_test": enable_web_app_test,
                "enable_dynamic_detection": enable_dynamic_detection,
                "enable_flask_specific_tests": enable_flask_specific_tests,
                "enable_server_testing": enable_server_testing,
                # é™æ€æ£€æµ‹å·¥å…·é€‰æ‹©
                "enable_pylint": enable_pylint,
                "enable_mypy": enable_mypy,
                "enable_semgrep": enable_semgrep,
                "enable_ruff": enable_ruff,
                "enable_bandit": enable_bandit,
                "enable_llm_filter": enable_llm_filter
            }
        }
        
        try:
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(zip_file_path)
            max_size = 50 * 1024 * 1024  # 50MBé™åˆ¶
            
            if file_size > max_size:
                results["error"] = f"æ–‡ä»¶è¿‡å¤§ ({file_size // (1024*1024)}MB > {max_size // (1024*1024)}MB)"
                return results
            
            # ä½¿ç”¨BugDetectionAgentçš„extract_projectæ–¹æ³•æ¥è§£å‹é¡¹ç›®å¹¶åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
            print(f"ğŸ”§ å¼€å§‹è§£å‹é¡¹ç›®å¹¶åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ: {zip_file_path}")
            print(f"â±ï¸  æ³¨æ„ï¼šè™šæ‹Ÿç¯å¢ƒåˆ›å»ºå’Œä¾èµ–å®‰è£…å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼ˆæœ€å¤š5åˆ†é’Ÿï¼‰...")
            extract_dir = None  # åˆå§‹åŒ–ä¸ºNoneï¼Œç¡®ä¿åœ¨æ‰€æœ‰æƒ…å†µä¸‹éƒ½æœ‰å€¼
            try:
                # è®¾ç½®æ›´é•¿çš„è¶…æ—¶æ—¶é—´ï¼Œç»™è™šæ‹Ÿç¯å¢ƒåˆ›å»ºå’Œä¾èµ–å®‰è£…è¶³å¤Ÿæ—¶é—´
                # è™šæ‹Ÿç¯å¢ƒåˆ›å»ºå¯èƒ½éœ€è¦30-180ç§’ï¼Œä¾èµ–å®‰è£…å¯èƒ½éœ€è¦1-5åˆ†é’Ÿ
                extract_dir = await asyncio.wait_for(
                    self.static_agent.extract_project(zip_file_path),
                    timeout=300.0  # å¢åŠ åˆ°5åˆ†é’Ÿï¼ˆ300ç§’ï¼‰
                )
                print(f"âœ… é¡¹ç›®è§£å‹å®Œæˆï¼Œè™šæ‹Ÿç¯å¢ƒå·²åˆ›å»º: {extract_dir}")
            except asyncio.TimeoutError:
                print("âš ï¸ è™šæ‹Ÿç¯å¢ƒåˆ›å»ºè¶…æ—¶ï¼ˆ5åˆ†é’Ÿï¼‰ï¼Œä½¿ç”¨ç®€å•è§£å‹æ¨¡å¼")
                print("   æç¤ºï¼šå¦‚æœé¡¹ç›®ä¾èµ–è¾ƒå¤šï¼Œå»ºè®®å¯ç”¨Dockeræˆ–å¢åŠ è¶…æ—¶æ—¶é—´")
                try:
                    extract_dir = await self._simple_extract_project(zip_file_path)
                    results["warning"] = "è™šæ‹Ÿç¯å¢ƒåˆ›å»ºè¶…æ—¶ï¼ˆ5åˆ†é’Ÿï¼‰ï¼Œä½¿ç”¨ç®€å•è§£å‹æ¨¡å¼ã€‚å¦‚éœ€å®Œæ•´åŠŸèƒ½ï¼Œå»ºè®®å¯ç”¨Dockeræˆ–å¢åŠ è¶…æ—¶æ—¶é—´"
                except Exception as e2:
                    print(f"âŒ ç®€å•è§£å‹ä¹Ÿå¤±è´¥: {e2}")
                    extract_dir = None
                    results["error"] = f"é¡¹ç›®è§£å‹å¤±è´¥: {e2}"
            except KeyboardInterrupt:
                print("âš ï¸ è™šæ‹Ÿç¯å¢ƒåˆ›å»ºè¢«ä¸­æ–­ï¼Œä½¿ç”¨ç®€å•è§£å‹æ¨¡å¼")
                try:
                    extract_dir = await self._simple_extract_project(zip_file_path)
                    results["warning"] = "è™šæ‹Ÿç¯å¢ƒåˆ›å»ºè¢«ä¸­æ–­ï¼Œä½¿ç”¨ç®€å•è§£å‹æ¨¡å¼"
                except Exception as e2:
                    print(f"âŒ ç®€å•è§£å‹ä¹Ÿå¤±è´¥: {e2}")
                    extract_dir = None
                    results["error"] = f"é¡¹ç›®è§£å‹å¤±è´¥: {e2}"
            except Exception as e:
                print(f"âŒ é¡¹ç›®è§£å‹å¤±è´¥: {e}")
                import traceback
                print(f"é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")
                # å¦‚æœè™šæ‹Ÿç¯å¢ƒåˆ›å»ºå¤±è´¥ï¼Œå°è¯•ç®€å•çš„æ–‡ä»¶è§£å‹
                try:
                    extract_dir = await self._simple_extract_project(zip_file_path)
                    results["warning"] = f"è™šæ‹Ÿç¯å¢ƒåˆ›å»ºå¤±è´¥ï¼Œä½¿ç”¨ç®€å•è§£å‹æ¨¡å¼: {e}"
                except Exception as e2:
                    print(f"âŒ ç®€å•è§£å‹ä¹Ÿå¤±è´¥: {e2}")
                    extract_dir = None
                    results["error"] = f"é¡¹ç›®è§£å‹å¤±è´¥: {e2}"
            
            # æ£€æŸ¥extract_diræ˜¯å¦æœ‰æ•ˆ
            if not extract_dir:
                print("âŒ æ— æ³•è·å–æœ‰æ•ˆçš„è§£å‹ç›®å½•ï¼Œç»ˆæ­¢æ£€æµ‹")
                results["error"] = "æ— æ³•è§£å‹é¡¹ç›®æ–‡ä»¶"
                return results
            
            results["extracted_path"] = extract_dir

            # åœ¨åˆ†æå‰ç§»é™¤å¸¸è§è™šæ‹Ÿç¯å¢ƒç›®å½•ï¼Œé¿å…ç¬¬ä¸‰æ–¹åº“å¹²æ‰°
            removed_virtualenvs = self._prune_virtualenv_dirs(
                extract_dir,
                virtualenv_names=["venv", ".venv", "env", ".env"]
            )
            if removed_virtualenvs:
                print("ğŸ§¹ [DEBUG] å·²æ’é™¤è™šæ‹Ÿç¯å¢ƒç›®å½•:")
                for removed_dir in removed_virtualenvs:
                    print(f"   - {removed_dir}")
            results["removed_virtualenv_dirs"] = removed_virtualenvs

            results["files"] = self._list_files(extract_dir)
            
            # é™åˆ¶æ–‡ä»¶æ•°é‡ï¼Œé¿å…å¤„ç†è¿‡å¤šæ–‡ä»¶
            if len(results["files"]) > 1000:
                results["warning"] = f"æ–‡ä»¶æ•°é‡è¿‡å¤š ({len(results['files'])} > 1000)ï¼Œå°†è¿›è¡Œé‡‡æ ·åˆ†æ"
                results["files"] = results["files"][:1000]  # åªå–å‰1000ä¸ªæ–‡ä»¶
            
            # ========== æ­¥éª¤1: æ‰§è¡Œåˆæ­¥ä»£ç åˆ†æ ==========
            print("ğŸ” å¼€å§‹åˆæ­¥ä»£ç åˆ†æ...")
            preliminary_analysis = await self._perform_preliminary_analysis(extract_dir)
            results["preliminary_analysis"] = preliminary_analysis
            
            # ç”Ÿæˆä»“åº“ç»“æ„æ–‡ä»¶
            repository_structure_file = await self._generate_repository_structure(extract_dir)
            if repository_structure_file:
                results["repository_structure_file"] = repository_structure_file
            
            # ä¿å­˜åˆæ­¥åˆ†æç»“æœä¾›é™æ€æ£€æµ‹ä½¿ç”¨
            self._current_preliminary_analysis = preliminary_analysis
            
            # ========== æ­¥éª¤2: æ‰§è¡Œé™æ€åˆ†æå’ŒåŠ¨æ€æ£€æµ‹ ==========
            # éªŒè¯ä¸¤ä¸ªæ£€æµ‹éƒ½ä½¿ç”¨åŒä¸€ä¸ªä¸´æ—¶ç›®å½•
            print(f"ğŸ“ [DEBUG] éªŒè¯ä¸´æ—¶ç›®å½•è·¯å¾„:")
            print(f"   - extract_dir: {extract_dir}")
            print(f"   - extract_dirå­˜åœ¨: {os.path.exists(extract_dir) if extract_dir else False}")
            
            # éªŒè¯Coordinatoræ˜¯å¦å¯ç”¨
            coordinator_available = _coordinator_manager and _coordinator_manager.coordinator
            print(f"ğŸ”§ [DEBUG] CoordinatorçŠ¶æ€:")
            print(f"   - Coordinatorå¯ç”¨: {coordinator_available}")
            if coordinator_available:
                coordinator = _coordinator_manager.coordinator
                registered_agents = list(coordinator.agents.keys())
                print(f"   - å·²æ³¨å†Œçš„Agent: {registered_agents}")
                print(f"   - bug_detection_agentå·²æ³¨å†Œ: {'bug_detection_agent' in coordinator.agents}")
                print(f"   - dynamic_detection_agentå·²æ³¨å†Œ: {'dynamic_detection_agent' in coordinator.agents}")
            
            # å¹¶è¡Œæ‰§è¡Œé™æ€åˆ†æå’ŒåŠ¨æ€æ£€æµ‹
            tasks = []
            
            # é™æ€åˆ†æ
            if static_analysis:
                print(f"ğŸ“‹ [DEBUG] åˆ›å»ºé™æ€æ£€æµ‹ä»»åŠ¡ï¼Œä½¿ç”¨ä¸´æ—¶ç›®å½•: {extract_dir}")
                tasks.append(self._perform_static_analysis_async(
                    extract_dir,
                    enable_pylint=enable_pylint,
                    enable_mypy=enable_mypy,
                    enable_semgrep=enable_semgrep,
                    enable_ruff=enable_ruff,
                    enable_bandit=enable_bandit,
                    enable_llm_filter=enable_llm_filter
                ))
            
            # åŠ¨æ€ç›‘æ§
            if dynamic_monitoring:
                tasks.append(self._perform_dynamic_monitoring_async())
            
            # è¿è¡Œæ—¶åˆ†æ
            if runtime_analysis:
                tasks.append(self._perform_runtime_analysis_async(extract_dir))
            
            # åŠ¨æ€ç¼ºé™·æ£€æµ‹
            if enable_dynamic_detection:
                print(f"ğŸ“‹ [DEBUG] åˆ›å»ºåŠ¨æ€æ£€æµ‹ä»»åŠ¡ï¼Œä½¿ç”¨ä¸´æ—¶ç›®å½•: {extract_dir}")
                tasks.append(self._perform_dynamic_detection_async(extract_dir, enable_flask_specific_tests, enable_server_testing))
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼ˆæ·»åŠ è¶…æ—¶æœºåˆ¶ï¼‰
            if tasks:
                print(f"ğŸ”„ [DEBUG] å¼€å§‹ç­‰å¾… {len(tasks)} ä¸ªæ£€æµ‹ä»»åŠ¡å®Œæˆ...")
                try:
                    # è®¾ç½®30åˆ†é’Ÿè¶…æ—¶ï¼Œç»™æ£€æµ‹è¶³å¤Ÿæ—¶é—´
                    task_results = await asyncio.wait_for(
                        asyncio.gather(*tasks, return_exceptions=True),
                        timeout=1800.0  # 30åˆ†é’Ÿï¼ˆ1800ç§’ï¼‰
                    )
                    print(f"âœ… [DEBUG] æ‰€æœ‰æ£€æµ‹ä»»åŠ¡å®Œæˆï¼Œå¼€å§‹å¤„ç†ç»“æœ...")
                except asyncio.TimeoutError:
                    print("âš ï¸ æ£€æµ‹ä»»åŠ¡è¶…æ—¶ï¼ˆ30åˆ†é’Ÿï¼‰ï¼Œä½¿ç”¨é»˜è®¤ç»“æœ")
                    results["warning"] = "æ£€æµ‹ä»»åŠ¡è¶…æ—¶ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½æœªå®Œæˆ"
                    # åˆ›å»ºé»˜è®¤çš„å¤±è´¥ç»“æœ
                    task_results = []
                    for i, task in enumerate(tasks):
                        if i == 0 and static_analysis:
                            task_results.append({"error": "æ£€æµ‹è¶…æ—¶", "issues": []})
                        elif i == 1 and dynamic_monitoring:
                            task_results.append({"error": "æ£€æµ‹è¶…æ—¶", "alerts": []})
                        elif i == 2 and runtime_analysis:
                            task_results.append({"error": "æ£€æµ‹è¶…æ—¶", "execution_successful": False})
                        elif i == 3 and enable_dynamic_detection:
                            task_results.append({"error": "æ£€æµ‹è¶…æ—¶", "tests_completed": False})
                except Exception as gather_error:
                    print(f"âŒ [DEBUG] asyncio.gatheræ‰§è¡Œå¼‚å¸¸: {gather_error}")
                    import traceback
                    traceback.print_exc()
                    # åˆ›å»ºé»˜è®¤çš„å¤±è´¥ç»“æœ
                    task_results = []
                    for i, task in enumerate(tasks):
                        if i == 0 and static_analysis:
                            task_results.append({"error": f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {gather_error}", "issues": []})
                        elif i == 1 and dynamic_monitoring:
                            task_results.append({"error": f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {gather_error}", "alerts": []})
                        elif i == 2 and runtime_analysis:
                            task_results.append({"error": f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {gather_error}", "execution_successful": False})
                        elif i == 3 and enable_dynamic_detection:
                            task_results.append({"error": f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {gather_error}", "tests_completed": False})
                
                # å¤„ç†ç»“æœ
                print(f"ğŸ“Š [DEBUG] å¼€å§‹å¤„ç†ä»»åŠ¡ç»“æœï¼Œtask_resultsæ•°é‡: {len(task_results) if task_results else 0}")
                task_index = 0
                if static_analysis:
                    print(f"ğŸ“Š [DEBUG] å¤„ç†é™æ€åˆ†æç»“æœï¼Œç´¢å¼•: {task_index}")
                    if isinstance(task_results[task_index], Exception):
                        print(f"âš ï¸ [DEBUG] é™æ€åˆ†æä»»åŠ¡å¼‚å¸¸: {task_results[task_index]}")
                        results["static_analysis"] = {"error": str(task_results[task_index]), "issues": []}
                    else:
                        static_result = task_results[task_index]
                        print(f"âœ… [DEBUG] é™æ€åˆ†æä»»åŠ¡å®Œæˆï¼Œç»“æœç±»å‹: {type(static_result)}")
                        
                        # éªŒè¯å¹¶è®°å½•LLMè¿‡æ»¤çŠ¶æ€
                        if isinstance(static_result, dict) and not static_result.get("error"):
                            issues_count = len(static_result.get("issues", []))
                            llm_filter_info = static_result.get("llm_filter", {})
                            original_count = llm_filter_info.get("original_count", issues_count)
                            filtered_count = llm_filter_info.get("filtered_count", issues_count)
                            is_enabled = llm_filter_info.get("enabled", False)
                            
                            print(f"ğŸ“Š [DEBUG] é™æ€åˆ†æç»“æœç»Ÿè®¡:")
                            print(f"   - å½“å‰é—®é¢˜æ•°: {issues_count}")
                            print(f"   - LLMè¿‡æ»¤å¯ç”¨: {is_enabled}")
                            if is_enabled:
                                print(f"   - åŸå§‹é—®é¢˜æ•°: {original_count}")
                                print(f"   - è¿‡æ»¤åé—®é¢˜æ•°: {filtered_count}")
                                print(f"   - è¿‡æ»¤æ‰çš„é—®é¢˜æ•°: {original_count - filtered_count}")
                                
                                # éªŒè¯æ˜¯å¦ä½¿ç”¨äº†è¿‡æ»¤åçš„ç»“æœ
                                if issues_count > filtered_count * 1.5:
                                    print(f"âš ï¸ [DEBUG] è­¦å‘Š: é—®é¢˜æ•°é‡ ({issues_count}) è¿œå¤§äºè¿‡æ»¤åé¢„æœŸæ•°é‡ ({filtered_count})")
                                    print(f"âš ï¸ [DEBUG] å¯èƒ½ä½¿ç”¨äº†æœªè¿‡æ»¤çš„ç»“æœï¼Œå°†é™åˆ¶ä¸ºè¿‡æ»¤åçš„æ•°é‡")
                                    # å¦‚æœé—®é¢˜æ•°é‡å¼‚å¸¸ï¼Œåªä¿ç•™å‰filtered_countä¸ª
                                    if issues_count > filtered_count * 2:
                                        static_result["issues"] = static_result["issues"][:filtered_count]
                                        static_result["issues_truncated"] = True
                                        print(f"âš ï¸ [DEBUG] å·²é™åˆ¶é—®é¢˜æ•°é‡ä¸º: {filtered_count}")
                            
                            # ç¡®ä¿ä½¿ç”¨è¿‡æ»¤åçš„issues
                            if static_result.get("issues_truncated", False):
                                total_issues = static_result.get("total_issues_count", issues_count)
                                print(f"âš ï¸ [DEBUG] è­¦å‘Š: é—®é¢˜åˆ—è¡¨è¢«æˆªæ–­ï¼Œå®é™…æ€»æ•°: {total_issues}, è¿”å›æ•°: {len(static_result.get('issues', []))}")
                        
                        results["static_analysis"] = static_result
                    task_index += 1
                
                if dynamic_monitoring:
                    print(f"ğŸ“Š [DEBUG] å¤„ç†åŠ¨æ€ç›‘æ§ç»“æœï¼Œç´¢å¼•: {task_index}")
                    if isinstance(task_results[task_index], Exception):
                        print(f"âš ï¸ [DEBUG] åŠ¨æ€ç›‘æ§ä»»åŠ¡å¼‚å¸¸: {task_results[task_index]}")
                        results["dynamic_monitoring"] = {"error": str(task_results[task_index]), "alerts": []}
                    else:
                        results["dynamic_monitoring"] = task_results[task_index]
                    task_index += 1
                
                if runtime_analysis:
                    print(f"ğŸ“Š [DEBUG] å¤„ç†è¿è¡Œæ—¶åˆ†æç»“æœï¼Œç´¢å¼•: {task_index}")
                    if isinstance(task_results[task_index], Exception):
                        print(f"âš ï¸ [DEBUG] è¿è¡Œæ—¶åˆ†æä»»åŠ¡å¼‚å¸¸: {task_results[task_index]}")
                        results["runtime_analysis"] = {"error": str(task_results[task_index]), "execution_successful": False}
                    else:
                        results["runtime_analysis"] = task_results[task_index]
                    task_index += 1
                
                if enable_dynamic_detection:
                    print(f"ğŸ“Š [DEBUG] å¤„ç†åŠ¨æ€æ£€æµ‹ç»“æœï¼Œç´¢å¼•: {task_index}")
                    if isinstance(task_results[task_index], Exception):
                        print(f"âš ï¸ [DEBUG] åŠ¨æ€æ£€æµ‹ä»»åŠ¡å¼‚å¸¸: {task_results[task_index]}")
                        results["dynamic_detection"] = {"error": str(task_results[task_index]), "tests_completed": False}
                    else:
                        dynamic_result = task_results[task_index]
                        print(f"âœ… [DEBUG] åŠ¨æ€æ£€æµ‹ä»»åŠ¡å®Œæˆï¼Œç»“æœç±»å‹: {type(dynamic_result)}")
                        if isinstance(dynamic_result, dict) and not dynamic_result.get("error"):
                            issues_count = len(dynamic_result.get("issues", []))
                            print(f"ğŸ“Š [DEBUG] åŠ¨æ€æ£€æµ‹ç»“æœç»Ÿè®¡: é—®é¢˜æ•°={issues_count}")
                        results["dynamic_detection"] = dynamic_result
            
            # ç”Ÿæˆç»¼åˆæ‘˜è¦
            print("ğŸ“ [DEBUG] å¼€å§‹ç”Ÿæˆç»¼åˆæ‘˜è¦...")
            results["summary"] = self._generate_summary(results)
            print("âœ… [DEBUG] ç»¼åˆæ‘˜è¦ç”Ÿæˆå®Œæˆ")
            
            # ========== æ­¥éª¤3: åˆå¹¶é™æ€å’ŒåŠ¨æ€æ£€æµ‹ç¼ºé™·æ¸…å• ==========
            # æ³¨æ„ï¼šå¿…é¡»åœ¨æ¸…ç†ä¸´æ—¶ç›®å½•ä¹‹å‰åˆå¹¶ï¼Œå› ä¸ºåˆå¹¶æ—¶éœ€è¦è®¿é—®æ–‡ä»¶è·¯å¾„
            print("ğŸ“‹ [DEBUG] å¼€å§‹åˆå¹¶ç¼ºé™·æ¸…å•...")
            print(f"ğŸ“ [DEBUG] åˆå¹¶æ—¶ä½¿ç”¨çš„ä¸´æ—¶ç›®å½•: {extract_dir}")
            print(f"ğŸ“ [DEBUG] ä¸´æ—¶ç›®å½•å­˜åœ¨: {os.path.exists(extract_dir) if extract_dir else False}")
            
            # åœ¨åˆå¹¶å‰éªŒè¯é™æ€åˆ†æç»“æœ
            if "static_analysis" in results:
                static_result = results["static_analysis"]
                if isinstance(static_result, dict) and not static_result.get("error"):
                    issues_count = len(static_result.get("issues", []))
                    llm_filter = static_result.get("llm_filter", {})
                    print(f"ğŸ“‹ [DEBUG] åˆå¹¶å‰éªŒè¯: é™æ€åˆ†æé—®é¢˜æ•°={issues_count}, LLMè¿‡æ»¤å¯ç”¨={llm_filter.get('enabled', False)}")
                    if llm_filter.get("enabled", False):
                        expected_count = llm_filter.get("filtered_count", issues_count)
                        print(f"ğŸ“‹ [DEBUG] LLMè¿‡æ»¤åé¢„æœŸæ•°é‡: {expected_count}, å®é™…æ•°é‡: {issues_count}")
            
            merged_defects = []
            try:
                merged_defects = self._merge_defects_list(results, extract_dir)
                results["merged_defects"] = merged_defects
                print(f"ğŸ“‹ [DEBUG] åˆå¹¶åçš„ç¼ºé™·æ•°é‡: {len(merged_defects)}")
                
                # å¦‚æœåˆå¹¶åçš„æ•°é‡å¼‚å¸¸å¤šï¼Œå‘å‡ºè­¦å‘Šå¹¶é™åˆ¶
                if len(merged_defects) > 500:
                    print(f"âš ï¸ [DEBUG] è­¦å‘Š: åˆå¹¶åçš„ç¼ºé™·æ•°é‡å¼‚å¸¸å¤š ({len(merged_defects)})ï¼Œå¯èƒ½ä½¿ç”¨äº†æœªè¿‡æ»¤çš„ç»“æœ")
                    # æ£€æŸ¥æ˜¯å¦æœ‰LLMè¿‡æ»¤ä¿¡æ¯
                    if "static_analysis" in results:
                        static_result = results["static_analysis"]
                        llm_filter = static_result.get("llm_filter", {})
                        if llm_filter.get("enabled", False):
                            expected_count = llm_filter.get("filtered_count", len(merged_defects))
                            print(f"âš ï¸ [DEBUG] LLMè¿‡æ»¤åé¢„æœŸæ•°é‡: {expected_count}, å®é™…åˆå¹¶æ•°é‡: {len(merged_defects)}")
                            
                            # å¦‚æœå®é™…æ•°é‡è¿œå¤§äºé¢„æœŸï¼Œåªä¿ç•™å‰expected_countä¸ªï¼ˆé¿å…å‰ç«¯å­˜å‚¨æº¢å‡ºï¼‰
                            if len(merged_defects) > expected_count * 2:
                                print(f"âš ï¸ [DEBUG] ç¼ºé™·æ•°é‡å¼‚å¸¸ï¼Œé™åˆ¶ä¸ºå‰{expected_count}ä¸ªä»¥é¿å…å‰ç«¯å­˜å‚¨æº¢å‡º")
                                merged_defects = merged_defects[:expected_count]
                                results["merged_defects"] = merged_defects
                                results["warning"] = results.get("warning", "") + f" ç¼ºé™·æ•°é‡å¼‚å¸¸å¤šï¼Œå·²é™åˆ¶ä¸º{expected_count}ä¸ª"
            except Exception as merge_error:
                print(f"âŒ [DEBUG] åˆå¹¶ç¼ºé™·æ¸…å•å¤±è´¥: {merge_error}")
                import traceback
                traceback.print_exc()
                results["merged_defects"] = []
                merged_defects = []
                results["warning"] = results.get("warning", "") + f" åˆå¹¶ç¼ºé™·æ¸…å•å¤±è´¥: {merge_error}"
            
            if merged_defects:
                print(f"ğŸ“‹ [DEBUG] å‰3ä¸ªç¼ºé™·ç¤ºä¾‹:")
                for i, defect in enumerate(merged_defects[:3], 1):
                    print(f"  {i}. æ–‡ä»¶: {defect.get('file', 'N/A')}, è¡Œå·: {defect.get('line', 'N/A')}, æ¥æº: {defect.get('source', 'N/A')}")
            else:
                print("âš ï¸ [DEBUG] è­¦å‘Š: merged_defects ä¸ºç©ºï¼")
            
            # ç”Ÿæˆä»»åŠ¡ä¿¡æ¯JSONæ–‡ä»¶ä¾›ä¿®å¤å·¥ä½œæµä½¿ç”¨ï¼ˆä¿å­˜åˆ°æ°¸ä¹…ä½ç½®ï¼‰
            print("ğŸ“ [DEBUG] å¼€å§‹ç”Ÿæˆä»»åŠ¡ä¿¡æ¯JSON...")
            try:
                task_info_path = self._generate_task_info_json(merged_defects, extract_dir)
                print(f"ğŸ“ [DEBUG] task_info_path = {task_info_path}")
            except Exception as task_info_error:
                print(f"âŒ [DEBUG] ç”Ÿæˆä»»åŠ¡ä¿¡æ¯JSONå¤±è´¥: {task_info_error}")
                import traceback
                traceback.print_exc()
                task_info_path = None
                results["warning"] = results.get("warning", "") + f" ç”Ÿæˆä»»åŠ¡ä¿¡æ¯JSONå¤±è´¥: {task_info_error}"
            if task_info_path:
                print(f"ğŸ“ [DEBUG] æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {os.path.exists(task_info_path)}")
            else:
                print("âš ï¸ [DEBUG] è­¦å‘Š: task_info_path ä¸º Noneï¼Œå¯èƒ½æ²¡æœ‰ç”Ÿæˆä»»åŠ¡ä¿¡æ¯")
            
            if task_info_path and os.path.exists(task_info_path):
                # å°†ä»»åŠ¡ä¿¡æ¯æ–‡ä»¶å¤åˆ¶åˆ°ç»“æœç›®å½•ï¼ˆä½¿ç”¨ç»å¯¹è·¯å¾„ï¼Œç¡®ä¿ä¿å­˜åœ¨é¡¹ç›®æ ¹ç›®å½•ï¼‰
                # è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆAPIæ–‡ä»¶æ‰€åœ¨ç›®å½•çš„çˆ¶ç›®å½•ï¼‰
                api_dir = Path(__file__).parent
                project_root = api_dir.parent
                results_dir = project_root / "comprehensive_detection_results"
                results_dir.mkdir(exist_ok=True)
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                permanent_task_info_file = results_dir / f"agent_task_info_{timestamp}.json"
                permanent_task_info_file_abs = permanent_task_info_file.resolve()
                print(f"ğŸ“ [DEBUG] å¤åˆ¶ä»»åŠ¡ä¿¡æ¯æ–‡ä»¶åˆ°æ°¸ä¹…ä½ç½®:")
                print(f"   ç›¸å¯¹è·¯å¾„: {permanent_task_info_file}")
                print(f"   ç»å¯¹è·¯å¾„: {permanent_task_info_file_abs}")
                shutil.copy2(task_info_path, permanent_task_info_file_abs)
                results["task_info_file"] = str(permanent_task_info_file_abs)
                print(f"âœ… [DEBUG] æ–‡ä»¶å·²å¤åˆ¶ï¼ŒéªŒè¯æ–‡ä»¶å­˜åœ¨: {permanent_task_info_file_abs.exists()}")
                # åŒæ—¶å°†ä»»åŠ¡ä¿¡æ¯å†…å®¹åŒ…å«åœ¨ç»“æœä¸­
                with open(permanent_task_info_file_abs, 'r', encoding='utf-8') as f:
                    task_info_data = json.load(f)
                    results["task_info"] = task_info_data
                print(f"âœ… [DEBUG] ä»»åŠ¡ä¿¡æ¯å·²ä¿å­˜ï¼Œä»»åŠ¡æ•°é‡: {len(task_info_data)}")
                print(f"ğŸ“ [DEBUG] æ³¨æ„: ä»»åŠ¡ä¿¡æ¯ä¸­çš„æ–‡ä»¶è·¯å¾„ä¸ºç»å¯¹è·¯å¾„")
                print(f"ğŸ“ [DEBUG] ä¸´æ—¶ç›®å½•: {extract_dir}")
                print(f"ğŸ“ [DEBUG] ä¸´æ—¶ç›®å½•å°†ä¿ç•™ï¼Œä»¥ä¾¿ä¿®å¤Agentä½¿ç”¨")
            else:
                print("âš ï¸ [DEBUG] è­¦å‘Š: æœªä¿å­˜ä»»åŠ¡ä¿¡æ¯æ–‡ä»¶åˆ°æ°¸ä¹…ä½ç½®")
                results["task_info_file"] = None
                results["task_info"] = []
            
            # ä¸åˆ é™¤ä¸´æ—¶ç›®å½•ï¼Œä¿ç•™ä¸Šä¼ çš„æ–‡ä»¶ä»¥ä¾¿åç»­ä¿®å¤ä½¿ç”¨
            # æ³¨æ„ï¼šä¸´æ—¶ç›®å½•ä¼šåœ¨ä¿®å¤å®Œæˆåç”±ä¿®å¤Agentæ¸…ç†
            print(f"ğŸ“ [DEBUG] ä¿ç•™ä¸´æ—¶ç›®å½•: {extract_dir}")
            print(f"ğŸ“ [DEBUG] æ³¨æ„: ä¸´æ—¶ç›®å½•å°†åœ¨ä¿®å¤å®Œæˆåç”±ä¿®å¤Agentæ¸…ç†")
            results["temp_dir"] = extract_dir  # ä¿å­˜ä¸´æ—¶ç›®å½•è·¯å¾„ï¼Œä¾›ä¿®å¤Agentä½¿ç”¨
            
            return results
            
        except Exception as e:
            results["error"] = str(e)
            # å³ä½¿å‡ºç°é”™è¯¯ä¹Ÿè¦ç”Ÿæˆsummary
            results["summary"] = self._generate_summary(results)
            return results
    
    async def _simple_extract_project(self, zip_file_path: str) -> str:
        """ç®€å•çš„é¡¹ç›®è§£å‹æ–¹æ³•ï¼ˆä¸åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼‰"""
        try:
            import zipfile
            import tempfile
            
            # åˆ›å»ºä¸´æ—¶è§£å‹ç›®å½•
            temp_dir = tempfile.mkdtemp(prefix="comprehensive_extract_")
            
            # è§£å‹ZIPæ–‡ä»¶
            with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
                zip_ref.extractall(temp_dir)
            
            print(f"âš ï¸ ä½¿ç”¨ç®€å•è§£å‹æ¨¡å¼: {temp_dir}")
            return temp_dir
            
        except Exception as e:
            print(f"âŒ ç®€å•è§£å‹ä¹Ÿå¤±è´¥: {e}")
            raise e
    
    def _list_files(self, project_path: str) -> List[str]:
        """åˆ—å‡ºé¡¹ç›®æ–‡ä»¶ï¼ˆæ’é™¤è™šæ‹Ÿç¯å¢ƒå’Œç¼“å­˜æ–‡ä»¶ï¼‰"""
        files = []
        skip_dirs = {'venv', '.venv', 'env', '.env', '__pycache__', '.git', 'node_modules', '.pytest_cache', '.mypy_cache'}
        
        for root, dirs, filenames in os.walk(project_path):
            # è·³è¿‡ä¸éœ€è¦çš„ç›®å½•
            dirs[:] = [d for d in dirs if d not in skip_dirs]
            
            for filename in filenames:
                # è·³è¿‡éšè—æ–‡ä»¶å’Œç¼“å­˜æ–‡ä»¶
                if filename.startswith('.') or filename.endswith(('.pyc', '.pyo', '.pyd')):
                    continue
                    
                file_path = os.path.relpath(os.path.join(root, filename), project_path)
                files.append(file_path)
        return files

    def _prune_virtualenv_dirs(self, project_path: str, virtualenv_names: Optional[List[str]] = None) -> List[str]:
        """åˆ é™¤é¡¹ç›®ä¸­çš„è™šæ‹Ÿç¯å¢ƒç›®å½•ï¼Œé¿å…å°†ç¬¬ä¸‰æ–¹ä¾èµ–çº³å…¥åˆ†æç»“æœ"""
        if virtualenv_names is None:
            virtualenv_names = ["venv", ".venv", "env", ".env"]

        normalized_targets = {name.lower() for name in virtualenv_names}
        removed_dirs: List[str] = []

        for root, dirs, _ in os.walk(project_path, topdown=True):
            # æ‰¾åˆ°éœ€è¦åˆ é™¤çš„ç›®å½•ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰
            target_dirs = [d for d in dirs if d.lower() in normalized_targets]

            for target in target_dirs:
                full_path = os.path.join(root, target)
                rel_path = os.path.relpath(full_path, project_path)
                try:
                    shutil.rmtree(full_path, ignore_errors=True)
                    removed_dirs.append(rel_path)
                except Exception as exc:
                    print(f"âš ï¸ [DEBUG] åˆ é™¤è™šæ‹Ÿç¯å¢ƒç›®å½•å¤±è´¥: {full_path} -> {exc}")

            # ä»éå†åˆ—è¡¨ä¸­ç§»é™¤å·²åˆ é™¤çš„ç›®å½•ï¼Œé¿å…ç»§ç»­æ·±å…¥
            dirs[:] = [d for d in dirs if d.lower() not in normalized_targets]

        return removed_dirs
    
    async def _perform_preliminary_analysis(self, project_path: str) -> Dict[str, Any]:
        """æ‰§è¡Œåˆæ­¥ä»£ç åˆ†æï¼ˆé¡¹ç›®ç»“æ„ã€ä»£ç è´¨é‡ã€ä¾èµ–å…³ç³»ï¼‰"""
        try:
            from agents.code_analysis_agent.agent import CodeAnalysisAgent
            
            # åˆå§‹åŒ–ä»£ç åˆ†æä»£ç†
            code_analysis_agent = CodeAnalysisAgent({
                "enable_ai_analysis": True,
                "analysis_depth": "comprehensive"
            })
            
            print("  ğŸ“Š æ‰§è¡Œé¡¹ç›®ç»“æ„åˆ†æ...")
            project_structure = await code_analysis_agent.project_analyzer.analyze_project_structure(project_path)
            
            print("  ğŸ“ˆ æ‰§è¡Œä»£ç è´¨é‡åˆ†æ...")
            print("     â³ è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...")
            try:
                # ä¸ºä»£ç è´¨é‡åˆ†ææ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼ˆæœ€å¤š3åˆ†é’Ÿï¼‰
                code_quality = await asyncio.wait_for(
                    code_analysis_agent.code_analyzer.analyze_code_quality(project_path),
                    timeout=180.0  # 3åˆ†é’Ÿè¶…æ—¶
                )
                print("     âœ… ä»£ç è´¨é‡åˆ†æå®Œæˆ")
            except asyncio.TimeoutError:
                print("     âš ï¸ ä»£ç è´¨é‡åˆ†æè¶…æ—¶ï¼ˆ3åˆ†é’Ÿï¼‰ï¼Œä½¿ç”¨ç®€åŒ–ç»“æœ")
                code_quality = {
                    'total_files': 0,
                    'analyzed_files': 0,
                    'error': 'åˆ†æè¶…æ—¶',
                    'file_analysis': []
                }
            except Exception as e:
                print(f"     âš ï¸ ä»£ç è´¨é‡åˆ†æå¤±è´¥: {e}ï¼Œä½¿ç”¨ç®€åŒ–ç»“æœ")
                code_quality = {
                    'total_files': 0,
                    'analyzed_files': 0,
                    'error': str(e),
                    'file_analysis': []
                }
            
            print("  ğŸ”— æ‰§è¡Œä¾èµ–å…³ç³»åˆ†æ...")
            try:
                # ä¸ºä¾èµ–åˆ†ææ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼ˆæœ€å¤š1åˆ†é’Ÿï¼‰
                dependencies = await asyncio.wait_for(
                    code_analysis_agent.dependency_analyzer.analyze_dependencies(project_path),
                    timeout=60.0  # 1åˆ†é’Ÿè¶…æ—¶
                )
                print("     âœ… ä¾èµ–å…³ç³»åˆ†æå®Œæˆ")
            except asyncio.TimeoutError:
                print("     âš ï¸ ä¾èµ–å…³ç³»åˆ†æè¶…æ—¶ï¼ˆ1åˆ†é’Ÿï¼‰ï¼Œä½¿ç”¨ç®€åŒ–ç»“æœ")
                dependencies = {
                    'error': 'åˆ†æè¶…æ—¶',
                    'dependencies': []
                }
            except Exception as e:
                print(f"     âš ï¸ ä¾èµ–å…³ç³»åˆ†æå¤±è´¥: {e}ï¼Œä½¿ç”¨ç®€åŒ–ç»“æœ")
                dependencies = {
                    'error': str(e),
                    'dependencies': []
                }
            
            print("âœ… åˆæ­¥ä»£ç åˆ†æå®Œæˆ")
            
            return {
                "success": True,
                "project_structure": project_structure,
                "code_quality": code_quality,
                "dependencies": dependencies
            }
        except Exception as e:
            print(f"âŒ åˆæ­¥ä»£ç åˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {
                "success": False,
                "error": str(e),
                "project_structure": {},
                "code_quality": {},
                "dependencies": {}
            }
    
    async def _generate_repository_structure(self, project_path: str) -> Optional[str]:
        """ç”Ÿæˆä»“åº“ç»“æ„æ–‡ä»¶ï¼ˆtreeæ ¼å¼ï¼‰"""
        try:
            from tools.repository_structure_generator import repository_structure_generator
            
            # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆä½¿ç”¨ç»å¯¹è·¯å¾„ï¼‰
            api_dir = Path(__file__).parent
            project_root = api_dir.parent
            structure_dir = project_root / "comprehensive_detection_results"
            structure_dir.mkdir(exist_ok=True)
            
            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            structure_file = structure_dir / f"repository_structure_{timestamp}.txt"
            
            # ç”Ÿæˆå¹¶ä¿å­˜æ ‘å½¢ç»“æ„
            success = repository_structure_generator.save_tree_structure(
                project_path, 
                str(structure_file),
                max_depth=10
            )
            
            if success:
                print(f"âœ… ä»“åº“ç»“æ„æ–‡ä»¶å·²ç”Ÿæˆ: {structure_file}")
                return str(structure_file)
            else:
                print("âš ï¸ ä»“åº“ç»“æ„æ–‡ä»¶ç”Ÿæˆå¤±è´¥")
                return None
        except Exception as e:
            print(f"âŒ ç”Ÿæˆä»“åº“ç»“æ„æ–‡ä»¶å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    async def _perform_static_analysis_async(self, project_path: str,
                                             enable_pylint: bool = True,
                                             enable_mypy: bool = True,
                                             enable_semgrep: bool = True,
                                             enable_ruff: bool = True,
                                             enable_bandit: bool = True,
                                             enable_llm_filter: bool = True) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡Œé™æ€åˆ†æ - ä¼˜å…ˆä½¿ç”¨Coordinatorï¼Œå¦åˆ™ç›´æ¥è°ƒç”¨Agent"""
        try:
            # ä¼˜å…ˆä½¿ç”¨Coordinatorï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if _coordinator_manager and _coordinator_manager.coordinator:
                coordinator = _coordinator_manager.coordinator
                
                try:
                    # è·å–åˆæ­¥åˆ†æç»“æœï¼ˆå¦‚æœå·²æ‰§è¡Œï¼‰
                    preliminary_analysis = None
                    if hasattr(self, '_current_preliminary_analysis'):
                        preliminary_analysis = self._current_preliminary_analysis
                    
                    print(f"ğŸš€ [Coordinator] é€šè¿‡Coordinatoråˆ›å»ºé™æ€æ£€æµ‹ä»»åŠ¡: {project_path}")
                    print(f"   å·¥å…·é€‰æ‹©: pylint={enable_pylint}, mypy={enable_mypy}, semgrep={enable_semgrep}, ruff={enable_ruff}, bandit={enable_bandit}")
                    
                    # åˆ›å»ºä»»åŠ¡æ•°æ®
                    # æ³¨æ„ï¼šproject_path å·²ç»æ˜¯è§£å‹åçš„ç›®å½•ï¼Œä¸æ˜¯zipæ–‡ä»¶
                    # åº”è¯¥ä½¿ç”¨ project_path è€Œä¸æ˜¯ file_pathï¼Œé¿å…å†æ¬¡è§£å‹
                    task_data = {
                        "project_path": project_path,  # ä½¿ç”¨ project_path è€Œä¸æ˜¯ file_path
                        "analysis_type": "project",
                        "options": {
                            "enable_static": True,
                            "enable_pylint": enable_pylint,
                            "enable_mypy": enable_mypy,
                            "enable_semgrep": enable_semgrep,
                            "enable_ruff": enable_ruff,
                            "enable_bandit": enable_bandit,
                            "enable_llm_filter": enable_llm_filter,
                            "enable_ai_analysis": True,
                            "preliminary_analysis": preliminary_analysis,
                            "pylint_directory_mode": False,
                            "max_parallel_files": 10,
                            "max_issues_to_return": 1000
                        }
                    }
                    
                    # é€šè¿‡Coordinatoråˆ›å»ºä»»åŠ¡å¹¶åˆ†é…
                    task_id = await coordinator.create_task('detect_bugs', task_data)
                    await coordinator.assign_task(task_id, 'bug_detection_agent')
                    
                    print(f"âœ… [Coordinator] é™æ€æ£€æµ‹ä»»åŠ¡å·²åˆ›å»ºå¹¶åˆ†é…: {task_id}")
                    
                    # ç­‰å¾…ä»»åŠ¡å®Œæˆï¼ˆæœ€å¤š30åˆ†é’Ÿï¼‰
                    try:
                        print(f"â³ [Coordinator] å¼€å§‹ç­‰å¾…é™æ€æ£€æµ‹ä»»åŠ¡å®Œæˆ (task_id: {task_id})...")
                        analysis_result = await coordinator.task_manager.get_task_result(task_id, timeout=1800.0)
                        print(f"âœ… [Coordinator] é™æ€æ£€æµ‹ä»»åŠ¡å®Œæˆï¼Œæ”¶åˆ°ç»“æœ")
                        print(f"ğŸ“Š [Coordinator] ç»“æœç±»å‹: {type(analysis_result)}, æˆåŠŸ: {analysis_result.get('success') if analysis_result else 'None'}")
                        
                        if analysis_result and analysis_result.get("success", False):
                            detection_results = analysis_result.get("detection_results", {})
                            if preliminary_analysis and preliminary_analysis.get("success"):
                                detection_results["preliminary_analysis"] = preliminary_analysis
                            print(f"âœ… [Coordinator] è¿”å›æ£€æµ‹ç»“æœï¼Œé—®é¢˜æ•°é‡: {len(detection_results.get('issues', []))}")
                            return detection_results
                        else:
                            error_msg = analysis_result.get("error", "é™æ€åˆ†æå¤±è´¥") if analysis_result else "ä»»åŠ¡æ‰§è¡Œå¤±è´¥"
                            print(f"âš ï¸ [Coordinator] é™æ€åˆ†æå¤±è´¥: {error_msg}")
                            return {
                                "error": error_msg,
                                "issues": [],
                                "statistics": {
                                    "total_files": 0,
                                    "total_lines": 0,
                                    "average_complexity": 0,
                                    "maintainability_score": 0
                                },
                                "files_analyzed": 0
                            }
                    except Exception as e:
                        print(f"âš ï¸ [Coordinator] è·å–é™æ€æ£€æµ‹ç»“æœå¤±è´¥: {e}ï¼Œå›é€€åˆ°ç›´æ¥è°ƒç”¨")
                        import traceback
                        traceback.print_exc()
                        # å›é€€åˆ°ç›´æ¥è°ƒç”¨æ–¹å¼
                except Exception as e:
                    print(f"âš ï¸ [Coordinator] Coordinatorè°ƒç”¨å¼‚å¸¸: {e}ï¼Œå›é€€åˆ°ç›´æ¥è°ƒç”¨")
                    import traceback
                    traceback.print_exc()
                    # å›é€€åˆ°ç›´æ¥è°ƒç”¨æ–¹å¼
            
            # å¤‡ç”¨æ–¹æ¡ˆï¼šç›´æ¥è°ƒç”¨Agentï¼ˆå¦‚æœCoordinatorä¸å¯ç”¨ï¼‰
            print(f"âš ï¸ [Direct] Coordinatorä¸å¯ç”¨ï¼Œç›´æ¥è°ƒç”¨é™æ€æ£€æµ‹Agent")
            
            # ç¡®ä¿é™æ€æ£€æµ‹agentå·²åˆå§‹åŒ–ï¼ˆå·¥å…·åˆå§‹åŒ–ï¼‰
            if not hasattr(self.static_agent, '_tools_initialized') or not self.static_agent._tools_initialized:
                print("ğŸ”§ åˆå§‹åŒ–é™æ€æ£€æµ‹å·¥å…·...")
                try:
                    # æ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼Œé¿å…åˆå§‹åŒ–å¡æ­»
                    await asyncio.wait_for(
                        self.static_agent.initialize(),
                        timeout=30.0  # 30ç§’è¶…æ—¶
                    )
                    self.static_agent._tools_initialized = True
                    print("âœ… é™æ€æ£€æµ‹å·¥å…·åˆå§‹åŒ–å®Œæˆ")
                except asyncio.TimeoutError:
                    print("âš ï¸ é™æ€æ£€æµ‹å·¥å…·åˆå§‹åŒ–è¶…æ—¶ï¼Œç»§ç»­ä½¿ç”¨éƒ¨åˆ†å·¥å…·")
                    self.static_agent._tools_initialized = True  # æ ‡è®°ä¸ºå·²åˆå§‹åŒ–ï¼Œé¿å…é‡å¤å°è¯•
                except Exception as e:
                    print(f"âš ï¸ é™æ€æ£€æµ‹å·¥å…·åˆå§‹åŒ–å¼‚å¸¸: {e}")
                    self.static_agent._tools_initialized = True  # æ ‡è®°ä¸ºå·²åˆå§‹åŒ–ï¼Œé¿å…é‡å¤å°è¯•
            
            # è·å–åˆæ­¥åˆ†æç»“æœï¼ˆå¦‚æœå·²æ‰§è¡Œï¼‰
            preliminary_analysis = None
            if hasattr(self, '_current_preliminary_analysis'):
                preliminary_analysis = self._current_preliminary_analysis
            
            print(f"ğŸš€ å¼€å§‹è°ƒç”¨é™æ€æ£€æµ‹agentåˆ†æé¡¹ç›®: {project_path}")
            print(f"   å·¥å…·é€‰æ‹©: pylint={enable_pylint}, mypy={enable_mypy}, semgrep={enable_semgrep}, ruff={enable_ruff}, bandit={enable_bandit}")
            
            # è°ƒç”¨é™æ€æ£€æµ‹agentï¼ˆä¼ é€’åˆæ­¥åˆ†æç»“æœå’Œå·¥å…·é€‰æ‹©ï¼‰
            # æ·»åŠ è¶…æ—¶ä¿æŠ¤å’Œè¿›åº¦æ—¥å¿—
            try:
                analysis_result = await asyncio.wait_for(
                    self.static_agent.analyze_project(project_path, {
                        "enable_static": True,
                        "enable_pylint": enable_pylint,
                        "enable_mypy": enable_mypy,
                        "enable_semgrep": enable_semgrep,
                        "enable_ruff": enable_ruff,
                        "enable_bandit": enable_bandit,
                        "enable_llm_filter": enable_llm_filter,
                        "enable_ai_analysis": True,
                        "preliminary_analysis": preliminary_analysis,  # ä¼ é€’åˆæ­¥åˆ†æç»“æœ
                        "pylint_directory_mode": False,  # ç¦ç”¨ç›®å½•æ¨¡å¼ï¼Œä½¿ç”¨å•æ–‡ä»¶æ¨¡å¼ä»¥ç¡®ä¿é—®é¢˜ä¸è¢«è¿‡æ»¤æ‰
                        "max_parallel_files": 10,  # å¹¶è¡Œæ–‡ä»¶æ•°é™åˆ¶
                        "max_issues_to_return": 1000  # é™åˆ¶è¿”å›çš„é—®é¢˜æ•°é‡ï¼Œé¿å…æ•°æ®è¿‡å¤§
                    }),
                    timeout=1800.0  # 30åˆ†é’Ÿè¶…æ—¶
                )
                print(f"âœ… é™æ€æ£€æµ‹åˆ†æå®Œæˆ")
            except asyncio.TimeoutError:
                print(f"âš ï¸ é™æ€æ£€æµ‹åˆ†æè¶…æ—¶ï¼ˆ30åˆ†é’Ÿï¼‰ï¼Œè¿”å›éƒ¨åˆ†ç»“æœ")
                analysis_result = {
                    "success": False,
                    "error": "é™æ€æ£€æµ‹åˆ†æè¶…æ—¶",
                    "detection_results": {
                        "project_path": project_path,
                        "total_issues": 0,
                        "issues": [],
                        "summary": {"error_count": 0, "warning_count": 0, "info_count": 0}
                    }
                }
            except Exception as e:
                print(f"âŒ é™æ€æ£€æµ‹åˆ†æå¼‚å¸¸: {e}")
                import traceback
                print(f"é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")
                analysis_result = {
                    "success": False,
                    "error": str(e),
                    "detection_results": {
                        "project_path": project_path,
                        "total_issues": 0,
                        "issues": [],
                        "summary": {"error_count": 0, "warning_count": 0, "info_count": 0}
                    }
                }
            
            if analysis_result.get("success", False):
                detection_results = analysis_result.get("detection_results", {})
                # è°ƒè¯•ï¼šæ£€æŸ¥ç»“æœç»“æ„
                import logging
                logger = logging.getLogger(__name__)
                logger.info(f"é™æ€åˆ†æç»“æœ: success={analysis_result.get('success')}, detection_results keys={list(detection_results.keys()) if detection_results else 'None'}")
                if detection_results:
                    logger.info(f"æ£€æµ‹åˆ°çš„é—®é¢˜æ•°: {len(detection_results.get('issues', []))}")
                    logger.info(f"å·¥å…·è¦†ç›–ç‡: {detection_results.get('tool_coverage', {})}")
                # å¦‚æœæœ‰åˆæ­¥åˆ†æç»“æœï¼Œåˆå¹¶è¿›å»
                if preliminary_analysis and preliminary_analysis.get("success"):
                    detection_results["preliminary_analysis"] = preliminary_analysis
                return detection_results
            else:
                return {
                    "error": analysis_result.get("error", "é™æ€åˆ†æå¤±è´¥"),
                    "issues": [],
                    "statistics": {
                        "total_files": 0,
                        "total_lines": 0,
                        "average_complexity": 0,
                        "maintainability_score": 0
                    },
                    "files_analyzed": 0
                }
        except Exception as e:
            return {
                "error": str(e), 
                "issues": [],
                "statistics": {
                    "total_files": 0,
                    "total_lines": 0,
                    "average_complexity": 0,
                    "maintainability_score": 0
                },
                "files_analyzed": 0
            }
    
    async def _perform_dynamic_monitoring_async(self) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡ŒåŠ¨æ€ç›‘æ§"""
        try:
            return await self.dynamic_agent.start_monitoring(duration=60)
        except Exception as e:
            return {"error": str(e), "alerts": []}
    
    async def _perform_runtime_analysis_async(self, project_path: str) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡Œè¿è¡Œæ—¶åˆ†æ"""
        try:
            return await self.dynamic_agent.perform_runtime_analysis(project_path)
        except Exception as e:
            return {"error": str(e), "execution_successful": False}
    
    async def _perform_dynamic_detection_async(self, project_path: str, enable_flask_tests: bool = True, enable_server_tests: bool = True) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡ŒåŠ¨æ€ç¼ºé™·æ£€æµ‹ - ä¼˜å…ˆä½¿ç”¨Coordinatorï¼Œå¦åˆ™ç›´æ¥è°ƒç”¨Agent"""
        try:
            # ä¼˜å…ˆä½¿ç”¨Coordinatorï¼ˆå¦‚æœå¯ç”¨ä¸”dynamic_detection_agentå·²æ³¨å†Œï¼‰
            if _coordinator_manager and _coordinator_manager.coordinator:
                coordinator = _coordinator_manager.coordinator
                
                try:
                    # æ£€æŸ¥æ˜¯å¦æœ‰dynamic_detection_agentï¼ˆå¯èƒ½æœªæ³¨å†Œï¼‰
                    if 'dynamic_detection_agent' in coordinator.agents:
                        print(f"ğŸš€ [Coordinator] é€šè¿‡Coordinatoråˆ›å»ºåŠ¨æ€æ£€æµ‹ä»»åŠ¡: {project_path}")
                        
                        # åˆ›å»ºä»»åŠ¡æ•°æ®
                        task_data = {
                            "project_path": project_path,
                            "enable_flask_tests": enable_flask_tests,
                            "enable_server_tests": enable_server_tests,
                            "enable_web_app_test": self.enable_web_app_test,
                            "enable_dynamic_detection": self.enable_dynamic_detection,
                            "enable_flask_specific_tests": self.enable_flask_specific_tests,
                            "enable_server_testing": self.enable_server_testing
                        }
                        
                        # é€šè¿‡Coordinatoråˆ›å»ºä»»åŠ¡å¹¶åˆ†é…
                        task_id = await coordinator.create_task('dynamic_detect', task_data)
                        await coordinator.assign_task(task_id, 'dynamic_detection_agent')
                        
                        print(f"âœ… [Coordinator] åŠ¨æ€æ£€æµ‹ä»»åŠ¡å·²åˆ›å»ºå¹¶åˆ†é…: {task_id}")
                        
                        # ç­‰å¾…ä»»åŠ¡å®Œæˆï¼ˆæœ€å¤š30åˆ†é’Ÿï¼‰ï¼Œå¢åŠ è¿›åº¦æ—¥å¿—
                        try:
                            print(f"â³ [Coordinator] å¼€å§‹ç­‰å¾…åŠ¨æ€æ£€æµ‹ä»»åŠ¡å®Œæˆ (task_id: {task_id})ï¼Œæœ€é•¿ç­‰å¾…30åˆ†é’Ÿ...")
                            
                            # ä½¿ç”¨è½®è¯¢æ–¹å¼ç­‰å¾…ï¼Œæ¯30ç§’æ‰“å°ä¸€æ¬¡è¿›åº¦
                            import time
                            start_wait_time = time.time()
                            check_interval = 30  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
                            last_check_time = start_wait_time
                            
                            # åˆ›å»ºä¸€ä¸ªåŒ…è£…å‡½æ•°æ¥æ£€æŸ¥è¿›åº¦
                            async def wait_with_progress():
                                while True:
                                    elapsed = time.time() - start_wait_time
                                    # æ¯30ç§’æ‰“å°ä¸€æ¬¡è¿›åº¦
                                    if time.time() - last_check_time >= check_interval:
                                        print(f"â³ [Coordinator] åŠ¨æ€æ£€æµ‹ä»åœ¨è¿›è¡Œä¸­... å·²ç­‰å¾… {int(elapsed)} ç§’")
                                        last_check_time = time.time()
                                    
                                    # å°è¯•è·å–ç»“æœï¼ˆéé˜»å¡ï¼‰
                                    try:
                                        # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
                                        task_status = coordinator.task_manager.tasks.get(task_id)
                                        if task_status:
                                            status = task_status.get('status', 'unknown')
                                            if status == 'completed':
                                                result = await coordinator.task_manager.get_task_result(task_id, timeout=1.0)
                                                return result
                                            elif status == 'failed':
                                                error = task_status.get('error', 'ä»»åŠ¡æ‰§è¡Œå¤±è´¥')
                                                print(f"âŒ [Coordinator] åŠ¨æ€æ£€æµ‹ä»»åŠ¡å¤±è´¥: {error}")
                                                return {"error": error, "tests_completed": False}
                                    except Exception:
                                        pass  # ä»»åŠ¡å¯èƒ½è¿˜åœ¨æ‰§è¡Œä¸­
                                    
                                    # ç­‰å¾…ä¸€å°æ®µæ—¶é—´å†æ£€æŸ¥
                                    await asyncio.sleep(5)
                            
                            # ä½¿ç”¨asyncio.wait_foråŒ…è£…ï¼Œè®¾ç½®æ€»è¶…æ—¶æ—¶é—´
                            result = await asyncio.wait_for(
                                wait_with_progress(),
                                timeout=1800.0  # 30åˆ†é’Ÿæ€»è¶…æ—¶
                            )
                            
                            print(f"âœ… [Coordinator] åŠ¨æ€æ£€æµ‹ä»»åŠ¡å®Œæˆ")
                            if result:
                                print(f"ğŸ“Š [Coordinator] åŠ¨æ€æ£€æµ‹ç»“æœ: tests_completed={result.get('tests_completed', False)}, issues={len(result.get('issues', []))}")
                            return result if result else {"error": "ä»»åŠ¡æ‰§è¡Œå¤±è´¥", "tests_completed": False}
                        except Exception as e:
                            print(f"âš ï¸ [Coordinator] è·å–åŠ¨æ€æ£€æµ‹ç»“æœå¤±è´¥: {e}ï¼Œå›é€€åˆ°ç›´æ¥è°ƒç”¨")
                            import traceback
                            traceback.print_exc()
                            # å›é€€åˆ°ç›´æ¥è°ƒç”¨æ–¹å¼
                    else:
                        print(f"âš ï¸ [Coordinator] dynamic_detection_agentæœªæ³¨å†Œï¼Œä½¿ç”¨ç›´æ¥è°ƒç”¨")
                except Exception as e:
                    print(f"âš ï¸ [Coordinator] Coordinatorè°ƒç”¨å¼‚å¸¸: {e}ï¼Œå›é€€åˆ°ç›´æ¥è°ƒç”¨")
                    import traceback
                    traceback.print_exc()
                    # å›é€€åˆ°ç›´æ¥è°ƒç”¨æ–¹å¼
            
            # å¤‡ç”¨æ–¹æ¡ˆï¼šç›´æ¥è°ƒç”¨Agent
            print(f"âš ï¸ [Direct] ç›´æ¥è°ƒç”¨åŠ¨æ€æ£€æµ‹Agent")
            return await self.dynamic_agent.perform_dynamic_detection(project_path, enable_flask_tests, enable_server_tests)
        except Exception as e:
            return {"error": str(e), "tests_completed": False}
    
    def _generate_summary(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆæ‘˜è¦"""
        summary = {
            "total_files": len(results.get("files", [])),
            "analysis_completed": not bool(results.get("error")),
            "issues_summary": {}
        }
        
        # ç»Ÿè®¡é—®é¢˜æ•°é‡
        total_issues = 0
        critical_issues = 0
        warning_issues = 0
        info_issues = 0
        
        # ç»Ÿè®¡é™æ€åˆ†æé—®é¢˜
        if "static_analysis" in results:
            static = results["static_analysis"]
            issues = static.get("issues", [])
            statistics = static.get("statistics", {})
            
            summary["issues_summary"]["static"] = {
                "analysis_type": static.get("analysis_type", "unknown"),
                "files_analyzed": static.get("files_analyzed", 0),
                "issues_found": len(issues),
                "total_files": statistics.get("total_files", 0),
                "total_lines": statistics.get("total_lines", 0),
                "average_complexity": statistics.get("average_complexity", 0),
                "maintainability_score": statistics.get("maintainability_score", 0),
                "issues_by_severity": statistics.get("issues_by_severity", {}),
                "issues_by_type": statistics.get("issues_by_type", {}),
                "issues_by_tool": statistics.get("issues_by_tool", {})
            }
            
            # ç»Ÿè®¡é—®é¢˜ä¸¥é‡ç¨‹åº¦
            for issue in issues:
                total_issues += 1
                severity = issue.get("severity", "info").lower()
                if severity == "error" or severity == "critical":
                    critical_issues += 1
                elif severity == "warning":
                    warning_issues += 1
                else:
                    info_issues += 1
        
        # ç»Ÿè®¡åŠ¨æ€ç›‘æ§ç»“æœ
        if "dynamic_monitoring" in results:
            dynamic = results["dynamic_monitoring"]
            alerts = dynamic.get("alerts", [])
            summary["issues_summary"]["dynamic"] = {
                "monitoring_duration": dynamic.get("duration", 0),
                "alerts_generated": len(alerts)
            }
            
            # ç»Ÿè®¡å‘Šè­¦æ•°é‡
            for alert in alerts:
                total_issues += 1
                severity = alert.get("severity", "info").lower()
                if severity == "error" or severity == "critical":
                    critical_issues += 1
                elif severity == "warning":
                    warning_issues += 1
                else:
                    info_issues += 1
        
        # ç»Ÿè®¡è¿è¡Œæ—¶åˆ†æç»“æœ
        if "runtime_analysis" in results:
            runtime = results["runtime_analysis"]
            summary["issues_summary"]["runtime"] = {
                "execution_successful": runtime.get("execution_successful", False),
                "main_file": runtime.get("main_file", "unknown")
            }
            
            # å¦‚æœæœ‰è¿è¡Œæ—¶é”™è¯¯ï¼Œè®¡å…¥é—®é¢˜
            if runtime.get("error"):
                total_issues += 1
                critical_issues += 1
        
        # ç»Ÿè®¡åŠ¨æ€æ£€æµ‹ç»“æœ
        if "dynamic_detection" in results:
            dynamic_detection = results["dynamic_detection"]
            summary["issues_summary"]["dynamic_detection"] = {
                "status": dynamic_detection.get("status", "unknown"),
                "is_flask_project": dynamic_detection.get("is_flask_project", False),
                "tests_completed": dynamic_detection.get("tests_completed", False),
                "success_rate": dynamic_detection.get("success_rate", 0)
            }
            
            # ç»Ÿè®¡åŠ¨æ€æ£€æµ‹é—®é¢˜
            dynamic_issues = dynamic_detection.get("issues", [])
            for issue in dynamic_issues:
                total_issues += 1
                severity = issue.get("severity", "info").lower()
                if severity == "error" or severity == "critical":
                    critical_issues += 1
                elif severity == "warning":
                    warning_issues += 1
                else:
                    info_issues += 1
        
        # è®¾ç½®æ•´ä½“çŠ¶æ€
        if critical_issues > 0:
            overall_status = "error"
        elif warning_issues > 0:
            overall_status = "warning"
        elif info_issues > 0:
            overall_status = "info"
        else:
            overall_status = "good"
        
        # ç”Ÿæˆå»ºè®®
        recommendations = []
        if critical_issues > 0:
            recommendations.append("å‘ç°ä¸¥é‡é—®é¢˜ï¼Œå»ºè®®ç«‹å³ä¿®å¤")
        if warning_issues > 0:
            recommendations.append("å‘ç°è­¦å‘Šé—®é¢˜ï¼Œå»ºè®®åŠæ—¶å¤„ç†")
        
        # æ£€æŸ¥è¿è¡Œæ—¶åˆ†æå’ŒåŠ¨æ€æ£€æµ‹çš„çŠ¶æ€
        runtime_analysis = results.get("runtime_analysis", {})
        dynamic_detection = results.get("dynamic_detection", {})
        runtime_failed = not runtime_analysis.get("execution_successful", True)
        dynamic_success = dynamic_detection.get("tests_completed", False) and dynamic_detection.get("success_rate", 0) >= 100
        
        if runtime_failed:
            if dynamic_success:
                # è¿è¡Œæ—¶åˆ†æå¤±è´¥ä½†åŠ¨æ€æ£€æµ‹æˆåŠŸï¼Œè¯´æ˜é¡¹ç›®éœ€è¦Flaskç¯å¢ƒæ‰èƒ½è¿è¡Œ
                recommendations.append("è¿è¡Œæ—¶åˆ†æå¤±è´¥ï¼Œä½†åŠ¨æ€æ£€æµ‹æˆåŠŸã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºé¡¹ç›®éœ€è¦Flaskç¯å¢ƒæ‰èƒ½è¿è¡Œï¼Œå±äºæ­£å¸¸æƒ…å†µ")
            else:
                # ä¸¤è€…éƒ½å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥é…ç½®
                recommendations.append("è¿è¡Œæ—¶åˆ†æå¤±è´¥ï¼Œæ£€æŸ¥é¡¹ç›®é…ç½®å’Œä¾èµ–")
        
        # æ·»åŠ æ‘˜è¦å­—æ®µ
        summary.update({
            "total_issues": total_issues,
            "critical_issues": critical_issues,
            "warning_issues": warning_issues,
            "info_issues": info_issues,
            "overall_status": overall_status,
            "recommendations": recommendations
        })
        
        return summary
    
    def _generate_natural_language_description(self, issue: Dict[str, Any], source: str = "static") -> str:
        """
        ä¸ºæ¯ä¸ªç¼ºé™·ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°
        
        Args:
            issue: ç¼ºé™·ä¿¡æ¯å­—å…¸
            source: æ¥æºï¼ˆ"static" æˆ– "dynamic"ï¼‰
        
        Returns:
            è‡ªç„¶è¯­è¨€æè¿°å­—ç¬¦ä¸²
        """
        if source == "static":
            tool = issue.get("tool", "unknown")
            message = issue.get("message", "")
            severity = issue.get("severity", "info")
            file_path = issue.get("file", "unknown")
            line = issue.get("line", 0)
            symbol = issue.get("symbol", "")
            
            # æ ¹æ®å·¥å…·å’Œé—®é¢˜ç±»å‹ç”Ÿæˆæè¿°
            if tool == "pylint":
                if "import" in message.lower() and "error" in message.lower():
                    return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼Œå­˜åœ¨å¯¼å…¥é”™è¯¯ï¼š{message}"
                elif "missing" in message.lower() and "docstring" in message.lower():
                    return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼Œç¼ºå°‘å‡½æ•°æˆ–æ–¹æ³•çš„æ–‡æ¡£å­—ç¬¦ä¸²"
                elif "unused" in message.lower():
                    return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼Œå­˜åœ¨æœªä½¿ç”¨çš„å˜é‡æˆ–å‚æ•°ï¼š{message}"
                elif severity == "error":
                    return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼Œå‘ç°ä¸¥é‡é”™è¯¯ï¼š{message}"
                else:
                    return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼Œ{tool} æ£€æµ‹åˆ°é—®é¢˜ï¼š{message}"
            
            elif tool == "mypy":
                return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼Œç±»å‹æ£€æŸ¥å‘ç°é—®é¢˜ï¼š{message}"
            
            elif tool == "semgrep":
                rule_id = issue.get("check_id", "")
                return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼Œæ£€æµ‹åˆ°å®‰å…¨æˆ–ä»£ç è´¨é‡é—®é¢˜ï¼ˆè§„åˆ™ï¼š{rule_id}ï¼‰ï¼š{message}"
            
            elif tool == "ruff":
                rule_code = issue.get("code", "")
                return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼Œä»£ç è§„èŒƒé—®é¢˜ï¼ˆè§„åˆ™ï¼š{rule_code}ï¼‰ï¼š{message}"
            
            elif tool == "bandit":
                test_id = issue.get("test_id", "")
                return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼Œå‘ç°å®‰å…¨é—®é¢˜ï¼ˆæ£€æµ‹é¡¹ï¼š{test_id}ï¼‰ï¼š{message}"
            
            else:
                return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼Œ{tool} æ£€æµ‹åˆ°{severity}çº§åˆ«é—®é¢˜ï¼š{message}"
        
        elif source == "dynamic":
            issue_type = issue.get("type", "unknown")
            message = issue.get("message", "")
            file_path = issue.get("file", "unknown")
            line = issue.get("line", 0)
            
            if issue_type == "import_error":
                import_name = issue.get("import", "")
                return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼ŒåŠ¨æ€æ£€æµ‹å‘ç°å¯¼å…¥é”™è¯¯ï¼šæ— æ³•å¯¼å…¥æ¨¡å— '{import_name}'"
            
            elif "flask" in issue_type.lower() or "functionality" in issue_type.lower():
                return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼ŒFlaskåŠŸèƒ½æµ‹è¯•å‘ç°é—®é¢˜ï¼š{message}"
            
            elif "runtime" in issue_type.lower():
                return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼Œè¿è¡Œæ—¶æ£€æµ‹å‘ç°é—®é¢˜ï¼š{message}"
            
            elif issue_type in ["cpu_high", "memory_high", "disk_high", "network_high"]:
                return f"ç³»ç»Ÿèµ„æºç›‘æ§å‘Šè­¦ï¼š{message}"
            
            else:
                return f"åœ¨ {file_path} çš„ç¬¬ {line} è¡Œï¼ŒåŠ¨æ€æ£€æµ‹å‘ç°é—®é¢˜ï¼š{message}"
        
        else:
            return issue.get("message", "æ£€æµ‹åˆ°é—®é¢˜")
    
    def _merge_defects_list(self, results: Dict[str, Any], project_path: str) -> List[Dict[str, Any]]:
        """
        åˆå¹¶é™æ€æ£€æµ‹å’ŒåŠ¨æ€æ£€æµ‹çš„ç¼ºé™·æ¸…å•ï¼Œç”Ÿæˆç»Ÿä¸€æ ¼å¼
        
        Args:
            results: æ£€æµ‹ç»“æœå­—å…¸
            project_path: é¡¹ç›®è·¯å¾„
        
        Returns:
            åˆå¹¶åçš„ç¼ºé™·åˆ—è¡¨ï¼Œæ¯ä¸ªç¼ºé™·åŒ…å«ï¼š
            - description: è‡ªç„¶è¯­è¨€æè¿°
            - file: æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
            - line: è¡Œå·
            - severity: ä¸¥é‡ç¨‹åº¦
            - source: æ¥æºï¼ˆ"static" æˆ– "dynamic"ï¼‰
            - tool: æ£€æµ‹å·¥å…·
            - original_issue: åŸå§‹é—®é¢˜ä¿¡æ¯
        """
        merged_defects = []
        
        # å¤„ç†é™æ€åˆ†æç»“æœ
        if "static_analysis" in results:
            static_result = results["static_analysis"]
            if isinstance(static_result, dict) and not static_result.get("error"):
                issues = static_result.get("issues", [])
                for issue in issues:
                    file_path = issue.get("file", "")
                    line = issue.get("line", 0)
                    
                    # è§„èŒƒåŒ–æ–‡ä»¶è·¯å¾„å¤„ç†ï¼ˆä¿®å¤è·¯å¾„åµŒå¥—é—®é¢˜ï¼‰
                    original_file_path = file_path
                    if file_path:
                        # è§„èŒƒåŒ–è·¯å¾„
                        norm_project = os.path.normpath(project_path)
                        
                        # å¤„ç†ç»å¯¹è·¯å¾„
                        if os.path.isabs(file_path):
                            norm_file = os.path.normpath(file_path)
                            # æ£€æŸ¥è·¯å¾„æ˜¯å¦å·²ç»åŒ…å«é¡¹ç›®è·¯å¾„ï¼ˆé¿å…é‡å¤åµŒå¥—ï¼‰
                            if norm_project in norm_file:
                                # æå–ç›¸å¯¹äºé¡¹ç›®è·¯å¾„çš„éƒ¨åˆ†
                                file_path = norm_file.replace(norm_project, "").lstrip(os.sep)
                                # å¦‚æœæå–åä»ç„¶åŒ…å«temp_extractï¼Œè¯´æ˜è·¯å¾„è¢«é‡å¤åµŒå¥—äº†
                                if "temp_extract" in file_path:
                                    # ç§»é™¤é‡å¤çš„temp_extractéƒ¨åˆ†
                                    parts = file_path.split(os.sep)
                                    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªproject_å¼€å¤´çš„éƒ¨åˆ†ï¼Œä¹‹å‰çš„éƒ½æ˜¯é‡å¤çš„
                                    project_idx = -1
                                    for i, part in enumerate(parts):
                                        if part.startswith("project_"):
                                            project_idx = i
                                            break
                                    if project_idx > 0:
                                        file_path = os.sep.join(parts[project_idx:])
                                    else:
                                        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œåªä¿ç•™æœ€åä¸€éƒ¨åˆ†
                                        file_path = os.path.basename(file_path)
                            else:
                                # å°è¯•ä½¿ç”¨relpath
                                try:
                                    file_path = os.path.relpath(file_path, project_path)
                                    if ".." in file_path:
                                        # è·¯å¾„ä¸åœ¨é¡¹ç›®å†…ï¼Œä½¿ç”¨æ–‡ä»¶å
                                        file_path = os.path.basename(original_file_path)
                                except (ValueError, OSError):
                                    file_path = os.path.basename(original_file_path)
                        else:
                            # ç›¸å¯¹è·¯å¾„ï¼Œè§„èŒƒåŒ–å¤„ç†
                            file_path = file_path.lstrip('./').lstrip('../')
                            # æ£€æŸ¥æ˜¯å¦åŒ…å«temp_extractï¼ˆè¯´æ˜è·¯å¾„å¯èƒ½å·²ç»åŒ…å«äº†å®Œæ•´è·¯å¾„ï¼‰
                            if "temp_extract" in file_path:
                                # æå–project_xxxä¹‹åçš„éƒ¨åˆ†
                                parts = file_path.split(os.sep)
                                project_idx = -1
                                for i, part in enumerate(parts):
                                    if part.startswith("project_"):
                                        project_idx = i
                                        break
                                if project_idx >= 0:
                                    file_path = os.sep.join(parts[project_idx + 1:]) if project_idx + 1 < len(parts) else os.path.basename(file_path)
                                else:
                                    # å¦‚æœæ‰¾ä¸åˆ°project_ï¼Œåªä¿ç•™æœ€åä¸€éƒ¨åˆ†
                                    file_path = os.path.basename(file_path)
                    
                    # ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°æ—¶ä½¿ç”¨ç›¸å¯¹è·¯å¾„
                    issue_for_desc = issue.copy()
                    issue_for_desc["file"] = file_path  # ä½¿ç”¨å·²è½¬æ¢çš„ç›¸å¯¹è·¯å¾„
                    merged_defect = {
                        "description": self._generate_natural_language_description(issue_for_desc, "static"),
                        "file": file_path,
                        "line": line,
                        "severity": issue.get("severity", "info"),
                        "source": "static",
                        "tool": issue.get("tool", "unknown"),
                        "original_issue": issue
                    }
                    merged_defects.append(merged_defect)
        
        # å¤„ç†åŠ¨æ€ç›‘æ§ç»“æœ
        if "dynamic_monitoring" in results:
            dynamic_result = results["dynamic_monitoring"]
            if isinstance(dynamic_result, dict) and not dynamic_result.get("error"):
                alerts = dynamic_result.get("alerts", [])
                for alert in alerts:
                    # åŠ¨æ€ç›‘æ§å‘Šè­¦å¯èƒ½æ²¡æœ‰æ–‡ä»¶ä¿¡æ¯
                    file_path = alert.get("file", "")
                    line = alert.get("line", 0)
                    
                    if file_path and os.path.isabs(file_path):
                        try:
                            file_path = os.path.relpath(file_path, project_path)
                        except:
                            pass
                    
                    # ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°æ—¶ä½¿ç”¨ç›¸å¯¹è·¯å¾„
                    alert_for_desc = alert.copy()
                    alert_for_desc["file"] = file_path if file_path else "system"
                    merged_defect = {
                        "description": self._generate_natural_language_description(alert_for_desc, "dynamic"),
                        "file": file_path if file_path else "system",
                        "line": line if line else 0,
                        "severity": alert.get("severity", "warning"),
                        "source": "dynamic",
                        "tool": "dynamic_monitoring",
                        "original_issue": alert
                    }
                    merged_defects.append(merged_defect)
        
        # å¤„ç†åŠ¨æ€æ£€æµ‹ç»“æœ
        if "dynamic_detection" in results:
            dynamic_detection_result = results["dynamic_detection"]
            if isinstance(dynamic_detection_result, dict) and not dynamic_detection_result.get("error"):
                issues = dynamic_detection_result.get("issues", [])
                for issue in issues:
                    file_path = issue.get("file", "")
                    line = issue.get("line", 0)
                    
                    # è§„èŒƒåŒ–æ–‡ä»¶è·¯å¾„å¤„ç†ï¼ˆä¿®å¤è·¯å¾„åµŒå¥—é—®é¢˜ï¼Œä¸é™æ€æ£€æµ‹ä¸€è‡´ï¼‰
                    original_file_path = file_path
                    if file_path and file_path not in ["system", "unknown"]:
                        # è§„èŒƒåŒ–è·¯å¾„
                        norm_project = os.path.normpath(project_path)
                        
                        # å¤„ç†ç»å¯¹è·¯å¾„
                        if os.path.isabs(file_path):
                            norm_file = os.path.normpath(file_path)
                            # æ£€æŸ¥è·¯å¾„æ˜¯å¦å·²ç»åŒ…å«é¡¹ç›®è·¯å¾„ï¼ˆé¿å…é‡å¤åµŒå¥—ï¼‰
                            if norm_project in norm_file:
                                # æå–ç›¸å¯¹äºé¡¹ç›®è·¯å¾„çš„éƒ¨åˆ†
                                file_path = norm_file.replace(norm_project, "").lstrip(os.sep)
                                # å¦‚æœæå–åä»ç„¶åŒ…å«temp_extractï¼Œè¯´æ˜è·¯å¾„è¢«é‡å¤åµŒå¥—äº†
                                if "temp_extract" in file_path:
                                    # ç§»é™¤é‡å¤çš„temp_extractéƒ¨åˆ†
                                    parts = file_path.split(os.sep)
                                    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªproject_å¼€å¤´çš„éƒ¨åˆ†ï¼Œä¹‹å‰çš„éƒ½æ˜¯é‡å¤çš„
                                    project_idx = -1
                                    for i, part in enumerate(parts):
                                        if part.startswith("project_"):
                                            project_idx = i
                                            break
                                    if project_idx > 0:
                                        file_path = os.sep.join(parts[project_idx:])
                                    else:
                                        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œåªä¿ç•™æœ€åä¸€éƒ¨åˆ†
                                        file_path = os.path.basename(file_path)
                            else:
                                # å°è¯•ä½¿ç”¨relpath
                                try:
                                    file_path = os.path.relpath(file_path, project_path)
                                    if ".." in file_path:
                                        # è·¯å¾„ä¸åœ¨é¡¹ç›®å†…ï¼Œä½¿ç”¨æ–‡ä»¶å
                                        file_path = os.path.basename(original_file_path)
                                except (ValueError, OSError):
                                    file_path = os.path.basename(original_file_path)
                        elif file_path:
                            # ç›¸å¯¹è·¯å¾„ï¼Œè§„èŒƒåŒ–å¤„ç†
                            file_path = file_path.lstrip('./').lstrip('../')
                            # æ£€æŸ¥æ˜¯å¦åŒ…å«temp_extractï¼ˆè¯´æ˜è·¯å¾„å¯èƒ½å·²ç»åŒ…å«äº†å®Œæ•´è·¯å¾„ï¼‰
                            if "temp_extract" in file_path:
                                # æå–project_xxxä¹‹åçš„éƒ¨åˆ†
                                parts = file_path.split(os.sep)
                                project_idx = -1
                                for i, part in enumerate(parts):
                                    if part.startswith("project_"):
                                        project_idx = i
                                        break
                                if project_idx >= 0:
                                    file_path = os.sep.join(parts[project_idx + 1:]) if project_idx + 1 < len(parts) else os.path.basename(file_path)
                                else:
                                    # å¦‚æœæ‰¾ä¸åˆ°project_ï¼Œåªä¿ç•™æœ€åä¸€éƒ¨åˆ†
                                    file_path = os.path.basename(file_path)
                    
                    # ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°æ—¶ä½¿ç”¨ç›¸å¯¹è·¯å¾„
                    issue_for_desc = issue.copy()
                    issue_for_desc["file"] = file_path if file_path else "unknown"
                    merged_defect = {
                        "description": self._generate_natural_language_description(issue_for_desc, "dynamic"),
                        "file": file_path if file_path else "unknown",
                        "line": line if line else 0,
                        "severity": issue.get("severity", "error"),
                        "source": "dynamic",
                        "tool": "dynamic_detection",
                        "original_issue": issue
                    }
                    merged_defects.append(merged_defect)
        
        # æŒ‰æ–‡ä»¶è·¯å¾„å’Œè¡Œå·æ’åº
        merged_defects.sort(key=lambda x: (x.get("file", ""), x.get("line", 0)))
        
        return merged_defects
    
    def _generate_task_info_json(self, merged_defects: List[Dict[str, Any]], project_path: str) -> Optional[str]:
        """
        ç”Ÿæˆä»»åŠ¡ä¿¡æ¯JSONæ–‡ä»¶ä¾›ä¿®å¤å·¥ä½œæµä½¿ç”¨
        æ¯ä¸ªç¼ºé™·ç”Ÿæˆä¸€ä¸ªç‹¬ç«‹ä»»åŠ¡ï¼Œtaskå­—æ®µä¸ºç¼ºé™·çš„ç®€å•æè¿°
        
        Args:
            merged_defects: åˆå¹¶åçš„ç¼ºé™·åˆ—è¡¨
            project_path: é¡¹ç›®è·¯å¾„
        
        Returns:
            ç”Ÿæˆçš„ä»»åŠ¡ä¿¡æ¯JSONæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœç”Ÿæˆå¤±è´¥åˆ™è¿”å›None
        """
        try:
            print(f"ğŸ“ [DEBUG] _generate_task_info_json: è¾“å…¥ç¼ºé™·æ•°é‡={len(merged_defects)}, é¡¹ç›®è·¯å¾„={project_path}")
            
            # ä¸ºæ¯ä¸ªç¼ºé™·ç”Ÿæˆä¸€ä¸ªä»»åŠ¡
            tasks = []
            skipped_count = 0
            not_exist_count = 0
            
            for defect in merged_defects:
                file_path = defect.get("file", "")
                if not file_path or file_path in ["system", "unknown"]:
                    skipped_count += 1
                    print(f"  âš ï¸ [DEBUG] è·³è¿‡æ— æ•ˆæ–‡ä»¶è·¯å¾„çš„ç¼ºé™·: {file_path}")
                    continue
                
                # è§„èŒƒåŒ–æ–‡ä»¶è·¯å¾„ï¼šä¿®å¤è·¯å¾„åµŒå¥—é—®é¢˜
                norm_project_path = os.path.normpath(project_path)
                
                if os.path.isabs(file_path):
                    # å·²ç»æ˜¯ç»å¯¹è·¯å¾„
                    abs_file_path = os.path.normpath(file_path)
                    
                    # æ£€æŸ¥è·¯å¾„æ˜¯å¦åŒ…å«project_pathï¼ˆé¿å…é‡å¤åµŒå¥—ï¼‰
                    if norm_project_path in abs_file_path:
                        # è·¯å¾„å·²ç»åŒ…å«é¡¹ç›®è·¯å¾„ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰é‡å¤åµŒå¥—
                        # ä¾‹å¦‚ï¼šproject_path/temp_extract/project_xxx/temp_extract/project_xxx/file.py
                        # åº”è¯¥å˜æˆï¼šproject_path/temp_extract/project_xxx/file.py
                        path_parts = abs_file_path.split(os.sep)
                        project_parts = norm_project_path.split(os.sep)
                        
                        # æŸ¥æ‰¾é‡å¤çš„è·¯å¾„æ®µåºåˆ—
                        if len(path_parts) > len(project_parts) + 2:
                            max_pattern_len = min((len(path_parts) - len(project_parts)) // 2, 10)
                            for pattern_len in range(max_pattern_len, 0, -1):
                                start_idx = len(project_parts)
                                if len(path_parts) >= start_idx + pattern_len * 2:
                                    pattern = path_parts[start_idx:start_idx + pattern_len]
                                    next_pattern = path_parts[start_idx + pattern_len:start_idx + pattern_len * 2]
                                    if pattern == next_pattern:
                                        # æ‰¾åˆ°é‡å¤æ¨¡å¼ï¼Œç§»é™¤é‡å¤çš„éƒ¨åˆ†
                                        print(f"  ğŸ”§ [DEBUG] æ£€æµ‹åˆ°è·¯å¾„é‡å¤åµŒå¥—ï¼Œç§»é™¤é‡å¤æ®µ: {os.sep.join(pattern)}")
                                        abs_file_path = os.sep.join(project_parts + path_parts[start_idx + pattern_len:])
                                        abs_file_path = os.path.normpath(abs_file_path)
                                        break
                    else:
                        # è·¯å¾„ä¸åŒ…å«é¡¹ç›®è·¯å¾„ï¼Œä½†å·²ç»æ˜¯ç»å¯¹è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨
                        # è¿™ç§æƒ…å†µå¯èƒ½å‘ç”Ÿåœ¨Dockerç¯å¢ƒä¸‹ï¼Œè·¯å¾„æ˜ å°„ä¸åŒ
                        print(f"  âš ï¸ [DEBUG] ç»å¯¹è·¯å¾„ä¸åŒ…å«é¡¹ç›®è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨: {abs_file_path}")
                else:
                    # ç›¸å¯¹è·¯å¾„ï¼Œå…ˆæ£€æŸ¥æ˜¯å¦åŒ…å«temp_extractï¼ˆè¯´æ˜å¯èƒ½å·²ç»åŒ…å«äº†å®Œæ•´è·¯å¾„ï¼‰
                    original_relative_path = file_path.lstrip('./').lstrip('../')
                    
                    if "temp_extract" in original_relative_path:
                        # è·¯å¾„å¯èƒ½å·²ç»åŒ…å«äº†temp_extractï¼Œæå–project_xxxä¹‹åçš„éƒ¨åˆ†
                        parts = original_relative_path.split(os.sep)
                        project_idx = -1
                        for i, part in enumerate(parts):
                            if part.startswith("project_"):
                                project_idx = i
                                break
                        if project_idx >= 0:
                            # æå–project_xxxä¹‹åçš„éƒ¨åˆ†ä½œä¸ºç›¸å¯¹è·¯å¾„
                            file_path = os.sep.join(parts[project_idx + 1:]) if project_idx + 1 < len(parts) else os.path.basename(original_relative_path)
                        else:
                            # å¦‚æœæ‰¾ä¸åˆ°project_ï¼Œåªä¿ç•™æœ€åä¸€éƒ¨åˆ†
                            file_path = os.path.basename(original_relative_path)
                    else:
                        # æ­£å¸¸çš„ç›¸å¯¹è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨
                        file_path = original_relative_path
                    
                    # æ‹¼æ¥é¡¹ç›®è·¯å¾„
                    abs_file_path = os.path.normpath(os.path.join(project_path, file_path))
                
                # æœ€ç»ˆè§„èŒƒåŒ–è·¯å¾„
                abs_file_path = os.path.normpath(abs_file_path)
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if not os.path.exists(abs_file_path):
                    not_exist_count += 1
                    print(f"  âš ï¸ [DEBUG] æ–‡ä»¶ä¸å­˜åœ¨: {abs_file_path}")
                    print(f"     project_path: {project_path}")
                    print(f"     file_path: {file_path}")
                    # æ³¨æ„ï¼šå³ä½¿æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä¹Ÿåˆ›å»ºä»»åŠ¡ï¼ˆæ–‡ä»¶å¯èƒ½åœ¨åç»­æ­¥éª¤ä¸­åˆ›å»ºï¼‰
                
                # è·å–ç¼ºé™·æè¿°ä½œä¸ºä»»åŠ¡æè¿°
                task_description = defect.get("description", "")
                if not task_description:
                    # å¦‚æœæ²¡æœ‰æè¿°ï¼Œç”Ÿæˆä¸€ä¸ªç®€å•çš„æè¿°
                    severity = defect.get("severity", "unknown")
                    tool = defect.get("tool", "unknown")
                    line = defect.get("line", 0)
                    file_name = os.path.basename(file_path)
                    task_description = f"ä¿®å¤ {file_name} ç¬¬ {line} è¡Œçš„ {tool} {severity} çº§åˆ«é—®é¢˜"
                
                # ç»Ÿä¸€ä½¿ç”¨æ­£æ–œæ ï¼ˆè·¨å¹³å°å…¼å®¹ï¼‰
                problem_file = abs_file_path.replace("\\", "/")
                
                task = {
                    "task": task_description,  # ä½¿ç”¨ç¼ºé™·çš„ç®€å•æè¿°
                    "problem_file": problem_file,  # ä¿å­˜ç»å¯¹è·¯å¾„
                    "project_root": project_path.replace("\\", "/"),
                    "agent_test_path": os.path.join(project_path, "agent-test").replace("\\", "/"),
                    "backup_agent_path": os.path.join(project_path, "backup-agent").replace("\\", "/"),
                    # å¯é€‰ï¼šæ·»åŠ ç¼ºé™·çš„è¯¦ç»†ä¿¡æ¯ï¼Œæ–¹ä¾¿åç»­å¤„ç†
                    "defect_info": {
                        "line": defect.get("line", 0),
                        "severity": defect.get("severity", "unknown"),
                        "tool": defect.get("tool", "unknown"),
                        "source": defect.get("source", "unknown")
                    }
                }
                tasks.append(task)
            
            print(f"ğŸ“ [DEBUG] ç”Ÿæˆä»»åŠ¡ç»Ÿè®¡:")
            print(f"   æ€»ç¼ºé™·æ•°: {len(merged_defects)}")
            print(f"   ç”Ÿæˆä»»åŠ¡æ•°: {len(tasks)}")
            print(f"   è·³è¿‡ç¼ºé™·æ•°: {skipped_count}")
            print(f"   æ–‡ä»¶ä¸å­˜åœ¨æ•°: {not_exist_count}")
            
            if not tasks:
                print("âš ï¸ [DEBUG] è­¦å‘Š: tasks ä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆä»»åŠ¡ä¿¡æ¯JSONæ–‡ä»¶")
                return None
            
            # ä¿å­˜ä»»åŠ¡ä¿¡æ¯JSONæ–‡ä»¶
            task_info_dir = Path(project_path)
            task_info_dir.mkdir(parents=True, exist_ok=True)
            task_info_file = task_info_dir / "agent_task_info.json"
            
            print(f"ğŸ“ [DEBUG] ä¿å­˜ä»»åŠ¡ä¿¡æ¯åˆ°: {task_info_file}")
            with open(task_info_file, 'w', encoding='utf-8') as f:
                json.dump(tasks, f, indent=2, ensure_ascii=False)
            
            print(f"âœ… [DEBUG] ä»»åŠ¡ä¿¡æ¯JSONæ–‡ä»¶å·²ç”Ÿæˆ: {task_info_file}")
            print(f"âœ… [DEBUG] æ¯ä¸ªç¼ºé™·éƒ½ç”Ÿæˆäº†ä¸€ä¸ªç‹¬ç«‹ä»»åŠ¡")
            return str(task_info_file)
        
        except Exception as e:
            print(f"âŒ [DEBUG] ç”Ÿæˆä»»åŠ¡ä¿¡æ¯JSONæ–‡ä»¶å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def generate_report(self, results: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š"""
        report_lines = [
            "# ç»¼åˆæ£€æµ‹æŠ¥å‘Š",
            f"ç”Ÿæˆæ—¶é—´: {results.get('timestamp', 'unknown')}",
            f"æ£€æµ‹ç±»å‹: {results.get('detection_type', 'unknown')}",
            "",
            "## æ£€æµ‹æ‘˜è¦",
        ]
        
        summary = results.get("summary", {})
        report_lines.extend([
            f"- æ€»æ–‡ä»¶æ•°: {summary.get('total_files', 0)}",
            f"- åˆ†æå®Œæˆ: {summary.get('analysis_completed', False)}",
            ""
        ])
        
        # æ·»åŠ é—®é¢˜æ‘˜è¦
        issues_summary = summary.get("issues_summary", {})
        if issues_summary:
            report_lines.append("## é—®é¢˜ç»Ÿè®¡")
            for analysis_type, stats in issues_summary.items():
                report_lines.append(f"### {analysis_type.upper()}")
                for key, value in stats.items():
                    report_lines.append(f"- {key}: {value}")
                report_lines.append("")
        
        return "\n".join(report_lines)
    
    def save_results(self, results: Dict[str, Any], file_path: str):
        """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
        try:
            # é€’å½’å¤„ç†ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡ï¼ˆå¦‚setç±»å‹ï¼‰
            def convert_to_serializable(obj):
                if isinstance(obj, set):
                    return list(obj)
                elif isinstance(obj, dict):
                    return {k: convert_to_serializable(v) for k, v in obj.items()}
                elif isinstance(obj, (list, tuple)):
                    return [convert_to_serializable(item) for item in obj]
                elif hasattr(obj, '__dict__'):
                    return convert_to_serializable(obj.__dict__)
                else:
                    return obj
            
            # è½¬æ¢ç»“æœæ•°æ®
            serializable_results = convert_to_serializable(results)
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(serializable_results, f, indent=2, ensure_ascii=False)
            print(f"æ£€æµ‹ç»“æœå·²ä¿å­˜åˆ°: {file_path}")
        except Exception as e:
            print(f"ä¿å­˜ç»“æœå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    def generate_severe_issues_report(self, results: Dict[str, Any], filename: str) -> str:
        """ç”Ÿæˆä¸¥é‡é—®é¢˜æ±‡æ€»æ–‡æ¡£"""
        report_lines = [
            "# ä¸¥é‡é—®é¢˜æ±‡æ€»æŠ¥å‘Š",
            f"**é¡¹ç›®åç§°**: {filename}",
            f"**ç”Ÿæˆæ—¶é—´**: {results.get('timestamp', 'unknown')}",
            f"**æ£€æµ‹ç±»å‹**: {results.get('detection_type', 'unknown')}",
            "",
            "## æ¦‚è¿°",
            "æœ¬æŠ¥å‘Šæ±‡æ€»äº†ä»£ç æ£€æµ‹ä¸­å‘ç°çš„ä¸¥é‡é—®é¢˜ï¼Œæ’é™¤äº†æ ¼å¼åŒ–å’Œé£æ ¼é—®é¢˜ï¼Œé‡ç‚¹å…³æ³¨å¯èƒ½å½±å“åŠŸèƒ½å’Œå®‰å…¨çš„å…³é”®é—®é¢˜ã€‚",
            ""
        ]
        
        # æ”¶é›†æ‰€æœ‰ä¸¥é‡é—®é¢˜
        severe_issues = []
        
        # é™æ€åˆ†æé—®é¢˜
        if "static_analysis" in results:
            static_issues = results["static_analysis"].get("issues", [])
            for issue in static_issues:
                if self._is_severe_issue(issue):
                    severe_issues.append({
                        "type": "é™æ€åˆ†æ",
                        "severity": issue.get("severity", "unknown"),
                        "file": issue.get("file", "unknown"),
                        "line": issue.get("line", "unknown"),
                        "message": issue.get("message", "unknown"),
                        "tool": issue.get("tool", "unknown"),
                        "issue_type": issue.get("type", "unknown")
                    })
        
        # åŠ¨æ€ç›‘æ§é—®é¢˜
        if "dynamic_monitoring" in results:
            dynamic_alerts = results["dynamic_monitoring"].get("alerts", [])
            for alert in dynamic_alerts:
                if self._is_severe_alert(alert):
                    severe_issues.append({
                        "type": "åŠ¨æ€ç›‘æ§",
                        "severity": alert.get("severity", "unknown"),
                        "file": "ç³»ç»Ÿç›‘æ§",
                        "line": "N/A",
                        "message": alert.get("message", "unknown"),
                        "tool": "ç³»ç»Ÿç›‘æ§",
                        "issue_type": alert.get("type", "unknown")
                    })
        
        # è¿è¡Œæ—¶åˆ†æé—®é¢˜
        if "runtime_analysis" in results:
            runtime = results["runtime_analysis"]
            if runtime.get("error"):
                severe_issues.append({
                    "type": "è¿è¡Œæ—¶åˆ†æ",
                    "severity": "error",
                    "file": runtime.get("main_file", "unknown"),
                    "line": "N/A",
                    "message": runtime.get("error"),
                    "tool": "è¿è¡Œæ—¶åˆ†æ",
                    "issue_type": "execution_error"
                })
        
        # åŠ¨æ€æ£€æµ‹é—®é¢˜
        if "dynamic_detection" in results:
            dynamic_issues = results["dynamic_detection"].get("issues", [])
            for issue in dynamic_issues:
                if self._is_severe_dynamic_issue(issue):
                    severe_issues.append({
                        "type": "åŠ¨æ€æ£€æµ‹",
                        "severity": issue.get("severity", "unknown"),
                        "file": issue.get("file", "unknown"),
                        "line": issue.get("line", "N/A"),
                        "message": issue.get("message", "unknown"),
                        "tool": issue.get("test", "unknown"),
                        "issue_type": issue.get("type", "unknown")
                    })
        
        # æŒ‰ä¸¥é‡ç¨‹åº¦å’Œæ–‡ä»¶åˆ†ç»„
        if severe_issues:
            # æŒ‰ä¸¥é‡ç¨‹åº¦æ’åº
            severity_order = {"error": 0, "critical": 0, "warning": 1, "info": 2}
            severe_issues.sort(key=lambda x: severity_order.get(x["severity"], 3))
            
            # æŒ‰æ–‡ä»¶åˆ†ç»„
            issues_by_file = {}
            for issue in severe_issues:
                file_path = issue["file"]
                if file_path not in issues_by_file:
                    issues_by_file[file_path] = []
                issues_by_file[file_path].append(issue)
            
            # ç”ŸæˆæŠ¥å‘Šå†…å®¹
            report_lines.extend([
                f"**å‘ç°ä¸¥é‡é—®é¢˜æ€»æ•°**: {len(severe_issues)}",
                "",
                "## é—®é¢˜è¯¦æƒ…",
                ""
            ])
            
            # æŒ‰æ–‡ä»¶è¾“å‡ºé—®é¢˜
            for file_path, file_issues in issues_by_file.items():
                report_lines.extend([
                    f"### ğŸ“ {file_path}",
                    ""
                ])
                
                for issue in file_issues:
                    severity_emoji = {
                        "error": "âŒ",
                        "critical": "ğŸš¨",
                        "warning": "âš ï¸",
                        "info": "â„¹ï¸"
                    }.get(issue["severity"], "â“")
                    
                    report_lines.extend([
                        f"**{severity_emoji} {issue['severity'].upper()}** - ç¬¬ {issue['line']} è¡Œ",
                        f"- **é—®é¢˜ç±»å‹**: {issue['issue_type']}",
                        f"- **æ£€æµ‹å·¥å…·**: {issue['tool']}",
                        f"- **é—®é¢˜æè¿°**: {issue['message']}",
                        ""
                    ])
            
            # æ·»åŠ ä¿®å¤å»ºè®®
            report_lines.extend([
                "## ä¿®å¤å»ºè®®",
                "",
                "### ä¼˜å…ˆçº§æ’åº",
                "1. **ç«‹å³ä¿®å¤**: é”™è¯¯å’Œä¸¥é‡é—®é¢˜",
                "2. **å°½å¿«ä¿®å¤**: è­¦å‘Šé—®é¢˜",
                "3. **è®¡åˆ’ä¿®å¤**: ä¿¡æ¯ç±»é—®é¢˜",
                "",
                "### ä¿®å¤æ­¥éª¤",
                "1. æŒ‰æ–‡ä»¶é€ä¸ªå¤„ç†é—®é¢˜",
                "2. ä¼˜å…ˆå¤„ç†å½±å“åŠŸèƒ½çš„å…³é”®é—®é¢˜",
                "3. ä¿®å¤åé‡æ–°è¿è¡Œæ£€æµ‹éªŒè¯",
                "4. å»ºç«‹ä»£ç è´¨é‡æ£€æŸ¥æµç¨‹",
                ""
            ])
            
        else:
            report_lines.extend([
                "## æ£€æµ‹ç»“æœ",
                "",
                "âœ… **æœªå‘ç°ä¸¥é‡é—®é¢˜**",
                "",
                "é¡¹ç›®ä»£ç è´¨é‡è‰¯å¥½ï¼Œæœªå‘ç°éœ€è¦ç«‹å³å¤„ç†çš„ä¸¥é‡é—®é¢˜ã€‚",
                "å»ºè®®ç»§ç»­ä¿æŒä»£ç è´¨é‡ï¼Œå®šæœŸè¿›è¡Œä»£ç å®¡æŸ¥ã€‚",
                ""
            ])
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        summary = results.get("summary", {})
        report_lines.extend([
            "## æ£€æµ‹ç»Ÿè®¡",
            "",
            f"- **æ€»æ–‡ä»¶æ•°**: {summary.get('total_files', 0)}",
            f"- **æ€»é—®é¢˜æ•°**: {summary.get('total_issues', 0)}",
            f"- **ä¸¥é‡é—®é¢˜**: {summary.get('critical_issues', 0)}",
            f"- **è­¦å‘Šé—®é¢˜**: {summary.get('warning_issues', 0)}",
            f"- **ä¿¡æ¯é—®é¢˜**: {summary.get('info_issues', 0)}",
            f"- **æ•´ä½“çŠ¶æ€**: {summary.get('overall_status', 'unknown')}",
            "",
            "---",
            f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*"
        ])
        
        return "\n".join(report_lines)
    
    def _is_severe_issue(self, issue: Dict[str, Any]) -> bool:
        """åˆ¤æ–­é™æ€åˆ†æé—®é¢˜æ˜¯å¦ä¸ºä¸¥é‡é—®é¢˜"""
        # æ’é™¤æ ¼å¼åŒ–å’Œé£æ ¼é—®é¢˜
        excluded_types = {
            "import_style", "line_length", "trailing_whitespace", 
            "missing_whitespace", "extra_whitespace", "indentation",
            "blank_line", "spacing", "quotes", "docstring"
        }
        
        issue_type = issue.get("type", "").lower()
        severity = issue.get("severity", "").lower()
        
        # å¦‚æœæ˜¯æ ¼å¼æˆ–é£æ ¼é—®é¢˜ï¼Œç›´æ¥æ’é™¤
        if issue_type in excluded_types:
            return False
        
        # åªä¿ç•™é”™è¯¯å’Œä¸¥é‡é—®é¢˜
        if severity in ["error", "critical"]:
            return True
        
        # å¯¹äºè­¦å‘Šï¼Œåªä¿ç•™é‡è¦çš„ç±»å‹
        if severity == "warning":
            important_warning_types = {
                "security", "performance", "logic_error", "unused_variable",
                "undefined_variable", "import_error", "syntax_error"
            }
            return issue_type in important_warning_types
        
        return False
    
    def _is_severe_alert(self, alert: Dict[str, Any]) -> bool:
        """åˆ¤æ–­åŠ¨æ€ç›‘æ§å‘Šè­¦æ˜¯å¦ä¸ºä¸¥é‡é—®é¢˜"""
        severity = alert.get("severity", "").lower()
        return severity in ["error", "critical", "warning"]
    
    def _is_severe_dynamic_issue(self, issue: Dict[str, Any]) -> bool:
        """åˆ¤æ–­åŠ¨æ€æ£€æµ‹é—®é¢˜æ˜¯å¦ä¸ºä¸¥é‡é—®é¢˜"""
        severity = issue.get("severity", "").lower()
        issue_type = issue.get("type", "").lower()
        
        # åªä¿ç•™é”™è¯¯å’Œä¸¥é‡é—®é¢˜
        if severity in ["error", "critical"]:
            return True
        
        # å¯¹äºè­¦å‘Šï¼Œåªä¿ç•™é‡è¦çš„ç±»å‹
        if severity == "warning":
            important_types = {
                "security", "performance", "functionality", "compatibility"
            }
            return issue_type in important_types
        
        return False

async def generate_ai_comprehensive_report(results: Dict[str, Any], filename: str) -> str:
    """ç”ŸæˆAIç»¼åˆæ£€æµ‹æŠ¥å‘Š"""
    try:
        if not deepseek_config.is_configured():
            print("âš ï¸ DeepSeek APIæœªé…ç½®ï¼Œä½¿ç”¨åŸºç¡€æŠ¥å‘Š")
            return generate_fallback_report(results, filename)
        
        prompt = build_comprehensive_analysis_prompt(results, filename)
        
        print("ğŸ¤– æ­£åœ¨ç”ŸæˆAIç»¼åˆæŠ¥å‘Š...")
        async with httpx.AsyncClient(timeout=180.0) as client:
            response = await client.post(
                f"{deepseek_config.base_url}/chat/completions",
                headers=deepseek_config.get_headers(),
                json={
                    "model": deepseek_config.model,
                    "messages": [
                        {"role": "user", "content": prompt}
                    ],
                    "max_tokens": deepseek_config.max_tokens,
                    "temperature": deepseek_config.temperature
                }
            )
            
            if response.status_code == 200:
                result = response.json()
                ai_content = result["choices"][0]["message"]["content"]
                print("âœ… AIç»¼åˆæŠ¥å‘Šç”ŸæˆæˆåŠŸ")
                return ai_content
            else:
                print(f"âŒ AI APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                return generate_fallback_report(results, filename)
                
    except httpx.TimeoutException:
        print("âŒ AI APIè°ƒç”¨è¶…æ—¶")
        return generate_fallback_report(results, filename)
    except httpx.RequestError as e:
        print(f"âŒ AI APIè¯·æ±‚å¤±è´¥: {e}")
        return generate_fallback_report(results, filename)
    except Exception as e:
        print(f"âŒ AIæŠ¥å‘Šç”Ÿæˆå¼‚å¸¸: {e}")
        return generate_fallback_report(results, filename)

def build_comprehensive_analysis_prompt(results: Dict[str, Any], filename: str) -> str:
    """æ„å»ºç»¼åˆåˆ†ææç¤ºè¯"""
    summary = results.get("summary", {})
    
    prompt = f"""è¯·åˆ†æä»¥ä¸‹ç»¼åˆæ£€æµ‹ç»“æœï¼Œç”Ÿæˆä¸€ä»½è¯¦ç»†çš„è‡ªç„¶è¯­è¨€æŠ¥å‘Šï¼š

## é¡¹ç›®ä¿¡æ¯
- æ–‡ä»¶å: {filename}
- æ£€æµ‹æ—¶é—´: {results.get('timestamp', 'unknown')}
- æ£€æµ‹ç±»å‹: {results.get('detection_type', 'unknown')}
- æ€»æ–‡ä»¶æ•°: {summary.get('total_files', 0)}

## æ£€æµ‹ç»Ÿè®¡
- æ€»é—®é¢˜æ•°: {summary.get('total_issues', 0)}
- ä¸¥é‡é—®é¢˜: {summary.get('critical_issues', 0)}
- è­¦å‘Šé—®é¢˜: {summary.get('warning_issues', 0)}
- ä¿¡æ¯é—®é¢˜: {summary.get('info_issues', 0)}
- æ•´ä½“çŠ¶æ€: {summary.get('overall_status', 'unknown')}

## é™æ€åˆ†æç»“æœ
"""
    
    if "static_analysis" in results:
        static = results["static_analysis"]
        statistics = static.get("statistics", {})
        
        prompt += f"- åˆ†æç±»å‹: {static.get('analysis_type', 'unknown')}\n"
        prompt += f"- åˆ†ææ–‡ä»¶æ•°: {static.get('files_analyzed', 0)}\n"
        prompt += f"- æ€»æ–‡ä»¶æ•°: {statistics.get('total_files', 0)}\n"
        prompt += f"- æ€»ä»£ç è¡Œæ•°: {statistics.get('total_lines', 0)}\n"
        prompt += f"- å¹³å‡å¤æ‚åº¦: {statistics.get('average_complexity', 0)}\n"
        prompt += f"- å¯ç»´æŠ¤æ€§è¯„åˆ†: {statistics.get('maintainability_score', 0)}\n"
        prompt += f"- å‘ç°é—®é¢˜æ•°: {len(static.get('issues', []))}\n"
        
        # æ·»åŠ é—®é¢˜ç»Ÿè®¡
        issues_by_severity = statistics.get("issues_by_severity", {})
        issues_by_tool = statistics.get("issues_by_tool", {})
        
        if issues_by_severity:
            prompt += "\n### é—®é¢˜ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ:\n"
            for severity, count in issues_by_severity.items():
                prompt += f"- {severity}: {count}ä¸ª\n"
        
        if issues_by_tool:
            prompt += "\n### åˆ†æå·¥å…·ç»Ÿè®¡:\n"
            for tool, count in issues_by_tool.items():
                prompt += f"- {tool}: {count}ä¸ªé—®é¢˜\n"
    
    prompt += "\n## åŠ¨æ€ç›‘æ§ç»“æœ\n"
    if "dynamic_monitoring" in results:
        dynamic = results["dynamic_monitoring"]
        prompt += f"- ç›‘æ§æ—¶é•¿: {dynamic.get('duration', 0)}ç§’\n"
        prompt += f"- å‘Šè­¦æ•°é‡: {len(dynamic.get('alerts', []))}\n"
    
    prompt += "\n## è¿è¡Œæ—¶åˆ†æç»“æœï¼ˆç‹¬ç«‹æ£€æµ‹æ¨¡å—ï¼‰\n"
    prompt += "æ³¨æ„ï¼šè¿è¡Œæ—¶åˆ†æä»…ç”¨äºæ£€æŸ¥é¡¹ç›®ä¸»æ–‡ä»¶èƒ½å¦ç›´æ¥æ‰§è¡Œï¼Œä¸åŠ¨æ€æ£€æµ‹çš„æµ‹è¯•æˆåŠŸç‡æ˜¯ç‹¬ç«‹çš„ã€‚\n"
    if "runtime_analysis" in results:
        runtime = results["runtime_analysis"]
        prompt += f"- ä¸»æ–‡ä»¶: {runtime.get('main_file', 'N/A')}\n"
        prompt += f"- æ‰§è¡ŒçŠ¶æ€: {'æˆåŠŸ' if runtime.get('execution_successful', False) else 'å¤±è´¥'}\n"
        if runtime.get("error"):
            prompt += f"- é”™è¯¯ä¿¡æ¯: {runtime.get('error')}\n"
    
    prompt += "\n## åŠ¨æ€æ£€æµ‹ç»“æœï¼ˆFlaskåŠŸèƒ½æµ‹è¯•ï¼‰\n"
    prompt += "æ³¨æ„ï¼šåŠ¨æ€æ£€æµ‹é€šè¿‡å®é™…è¿è¡ŒFlaskåº”ç”¨å¹¶æ‰§è¡ŒåŠŸèƒ½æµ‹è¯•æ¥æ£€æµ‹ç¼ºé™·ï¼Œä¸è¿è¡Œæ—¶åˆ†ææ˜¯ç‹¬ç«‹çš„æ£€æµ‹æ¨¡å—ã€‚\n"
    if "dynamic_detection" in results:
        dynamic_detection = results["dynamic_detection"]
        prompt += f"- çŠ¶æ€: {dynamic_detection.get('status', 'unknown')}\n"
        prompt += f"- æ˜¯Flaské¡¹ç›®: {dynamic_detection.get('is_flask_project', False)}\n"
        prompt += f"- æµ‹è¯•å®Œæˆ: {dynamic_detection.get('tests_completed', False)}\n"
        prompt += f"- æµ‹è¯•æˆåŠŸç‡: {dynamic_detection.get('success_rate', 0)}%\n"
        prompt += f"- å‘ç°é—®é¢˜æ•°: {len(dynamic_detection.get('issues', []))}\n"
        prompt += "é‡è¦è¯´æ˜ï¼š\n"
        prompt += "- å¦‚æœæµ‹è¯•å®Œæˆä¸”æˆåŠŸç‡ä¸º100%ï¼Œè¯´æ˜åŠ¨æ€æ£€æµ‹æµ‹è¯•æ‰§è¡ŒæˆåŠŸ\n"
        prompt += "- è¿è¡Œæ—¶åˆ†æå¤±è´¥ä¸å½±å“åŠ¨æ€æ£€æµ‹çš„æˆåŠŸï¼ˆä¸¤è€…æ£€æµ‹æ–¹å¼ä¸åŒï¼‰\n"
        prompt += "- åŠ¨æ€æ£€æµ‹çš„æˆåŠŸç‡åæ˜ çš„æ˜¯åŠŸèƒ½æµ‹è¯•çš„é€šè¿‡ç‡ï¼Œè€Œä¸æ˜¯æ£€æµ‹æœ¬èº«çš„å¤±è´¥\n"
    
    prompt += """
è¯·ç”Ÿæˆä¸€ä»½è¯¦ç»†çš„è‡ªç„¶è¯­è¨€åˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š
1. é¡¹ç›®æ¦‚è¿°
2. é—®é¢˜åˆ†æï¼ˆè¯·æ˜ç¡®åŒºåˆ†è¿è¡Œæ—¶åˆ†æå¤±è´¥å’ŒåŠ¨æ€æ£€æµ‹å¤±è´¥ï¼Œå®ƒä»¬æ˜¯ä¸åŒçš„æ£€æµ‹æ¨¡å—ï¼‰
3. é£é™©è¯„ä¼°
4. æ”¹è¿›å»ºè®®
5. æ€»ç»“

æŠ¥å‘Šåº”è¯¥ä¸“ä¸šã€è¯¦ç»†ä¸”æ˜“äºç†è§£ã€‚
ç‰¹åˆ«æ³¨æ„ï¼š
- å¦‚æœåŠ¨æ€æ£€æµ‹æ˜¾ç¤º"æµ‹è¯•å®Œæˆ: True, æˆåŠŸç‡: 100%"ï¼Œè¯´æ˜åŠ¨æ€æ£€æµ‹æœ¬èº«æ˜¯æˆåŠŸçš„
- è¿è¡Œæ—¶åˆ†æå¤±è´¥åªè¡¨ç¤ºä¸»æ–‡ä»¶æ— æ³•ç›´æ¥æ‰§è¡Œï¼Œä¸ä»£è¡¨åŠ¨æ€æ£€æµ‹å¤±è´¥
- è¯·åœ¨æŠ¥å‘Šä¸­æ˜ç¡®è¯´æ˜è¿™ä¸¤ä¸ªæ£€æµ‹æ¨¡å—çš„åŒºåˆ«å’Œå„è‡ªçš„æ£€æµ‹ç»“æœ"""
    
    return prompt

def generate_fallback_report(results: Dict[str, Any], filename: str) -> str:
    """ç”ŸæˆåŸºç¡€æŠ¥å‘Šï¼ˆå½“AI APIä¸å¯ç”¨æ—¶ï¼‰"""
    summary = results.get("summary", {})
    
    report = f"""# ç»¼åˆæ£€æµ‹æŠ¥å‘Š

## é¡¹ç›®æ¦‚è¿°
- **é¡¹ç›®åç§°**: {filename}
- **æ£€æµ‹æ—¶é—´**: {results.get('timestamp', 'unknown')}
- **æ£€æµ‹ç±»å‹**: {results.get('detection_type', 'unknown')}
- **æ€»æ–‡ä»¶æ•°**: {summary.get('total_files', 0)}

## æ£€æµ‹ç»“æœæ‘˜è¦
- **æ€»é—®é¢˜æ•°**: {summary.get('total_issues', 0)}
- **ä¸¥é‡é—®é¢˜**: {summary.get('critical_issues', 0)}
- **è­¦å‘Šé—®é¢˜**: {summary.get('warning_issues', 0)}
- **ä¿¡æ¯é—®é¢˜**: {summary.get('info_issues', 0)}
- **æ•´ä½“çŠ¶æ€**: {summary.get('overall_status', 'unknown')}

## é—®é¢˜åˆ†æ
"""
    
    if summary.get('critical_issues', 0) > 0:
        report += "âš ï¸ **å‘ç°ä¸¥é‡é—®é¢˜**ï¼Œéœ€è¦ç«‹å³å¤„ç†\n"
    if summary.get('warning_issues', 0) > 0:
        report += "âš ï¸ **å‘ç°è­¦å‘Šé—®é¢˜**ï¼Œå»ºè®®åŠæ—¶å¤„ç†\n"
    if summary.get('info_issues', 0) > 0:
        report += "â„¹ï¸ **å‘ç°ä¿¡æ¯é—®é¢˜**ï¼Œå¯é€‰æ‹©æ€§å¤„ç†\n"
    
    if summary.get('total_issues', 0) == 0:
        report += "âœ… **æœªå‘ç°æ˜æ˜¾é—®é¢˜**\n"
    
    # æ·»åŠ å»ºè®®
    recommendations = summary.get('recommendations', [])
    if recommendations:
        report += "\n## æ”¹è¿›å»ºè®®\n"
        for i, rec in enumerate(recommendations, 1):
            report += f"{i}. {rec}\n"
    
    report += "\n## æ€»ç»“\n"
    if summary.get('overall_status') == 'good':
        report += "é¡¹ç›®æ•´ä½“è´¨é‡è‰¯å¥½ï¼Œæœªå‘ç°ä¸¥é‡é—®é¢˜ã€‚å»ºè®®ç»§ç»­ä¿æŒä»£ç è´¨é‡ï¼Œå®šæœŸè¿›è¡Œä»£ç å®¡æŸ¥ã€‚"
    elif summary.get('overall_status') == 'warning':
        report += "é¡¹ç›®å­˜åœ¨ä¸€äº›è­¦å‘Šé—®é¢˜ï¼Œå»ºè®®åŠæ—¶å¤„ç†ã€‚é‡ç‚¹å…³æ³¨ä»£ç è´¨é‡å’Œå¯ç»´æŠ¤æ€§ã€‚"
    elif summary.get('overall_status') == 'error':
        report += "é¡¹ç›®å­˜åœ¨ä¸¥é‡é—®é¢˜ï¼Œéœ€è¦ç«‹å³ä¿®å¤ã€‚å»ºè®®ä¼˜å…ˆå¤„ç†ä¸¥é‡é—®é¢˜ï¼Œç„¶åé€æ­¥æ”¹è¿›ä»£ç è´¨é‡ã€‚"
    else:
        report += "è¯·æ ¹æ®å…·ä½“é—®é¢˜æƒ…å†µè¿›è¡Œç›¸åº”å¤„ç†ã€‚å»ºè®®å®šæœŸè¿›è¡Œä»£ç è´¨é‡æ£€æŸ¥ã€‚"
    
    return report

# APIç«¯ç‚¹
@router.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "ç»¼åˆæ£€æµ‹APIè¿è¡Œä¸­",
        "version": "2.0.0",
        "timestamp": datetime.now().isoformat()
    }

@router.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "service": "comprehensive_detection"
    }

@router.post("/detect", response_model=BaseResponse)
async def comprehensive_detect(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(None),
    files: List[UploadFile] = File(None),
    static_analysis: str = Form("true"),
    dynamic_monitoring: str = Form("true"),
    runtime_analysis: str = Form("true"),
    enable_web_app_test: str = Form("false"),
    enable_dynamic_detection: str = Form("true"),
    enable_flask_specific_tests: str = Form("true"),
    enable_server_testing: str = Form("true"),
    upload_type: str = Form("file"),
    # é™æ€æ£€æµ‹å·¥å…·é€‰æ‹©å‚æ•°
    enable_pylint: str = Form("true"),
    enable_mypy: str = Form("true"),
    enable_semgrep: str = Form("true"),
    enable_ruff: str = Form("true"),
    enable_bandit: str = Form("true"),
    enable_llm_filter: str = Form("true")
):
    """ç»¼åˆæ£€æµ‹ - å¹¶è¡Œæ‰§è¡Œé™æ€æ£€æµ‹å’ŒåŠ¨æ€æ£€æµ‹"""
    
    # ç¡®ä¿æ‰€æœ‰å¸ƒå°”å‚æ•°éƒ½æ˜¯å¸ƒå°”å€¼
    def convert_to_bool(value, param_name):
        if isinstance(value, str):
            result = value.lower() in ('true', '1', 'yes', 'on')
            return result
        elif isinstance(value, bool):
            return value
        else:
            return bool(value)
    
    static_analysis = convert_to_bool(static_analysis, 'static_analysis')
    dynamic_monitoring = convert_to_bool(dynamic_monitoring, 'dynamic_monitoring')
    runtime_analysis = convert_to_bool(runtime_analysis, 'runtime_analysis')
    enable_web_app_test = convert_to_bool(enable_web_app_test, 'enable_web_app_test')
    enable_dynamic_detection = convert_to_bool(enable_dynamic_detection, 'enable_dynamic_detection')
    enable_flask_specific_tests = convert_to_bool(enable_flask_specific_tests, 'enable_flask_specific_tests')
    enable_server_testing = convert_to_bool(enable_server_testing, 'enable_server_testing')
    # é™æ€æ£€æµ‹å·¥å…·é€‰æ‹©
    enable_pylint = convert_to_bool(enable_pylint, 'enable_pylint')
    enable_mypy = convert_to_bool(enable_mypy, 'enable_mypy')
    enable_semgrep = convert_to_bool(enable_semgrep, 'enable_semgrep')
    enable_ruff = convert_to_bool(enable_ruff, 'enable_ruff')
    enable_bandit = convert_to_bool(enable_bandit, 'enable_bandit')
    enable_llm_filter = convert_to_bool(enable_llm_filter, 'enable_llm_filter')
    
    # éªŒè¯è¾“å…¥
    if not file and not files:
        raise HTTPException(status_code=400, detail="è¯·æä¾›æ–‡ä»¶æˆ–æ–‡ä»¶åˆ—è¡¨")
    
    if file and files:
        raise HTTPException(status_code=400, detail="è¯·é€‰æ‹©å•æ–‡ä»¶ä¸Šä¼ æˆ–ç›®å½•ä¸Šä¼ ï¼Œä¸èƒ½åŒæ—¶ä½¿ç”¨")
    
    # å¤„ç†å•æ–‡ä»¶ä¸Šä¼ ï¼ˆå‹ç¼©åŒ…ï¼‰
    if file:
        if not file.filename.endswith('.zip'):
            raise HTTPException(status_code=400, detail="åªæ”¯æŒZIPæ ¼å¼çš„å‹ç¼©åŒ…")
        upload_files = [file]
        filename = file.filename
    else:
        # å¤„ç†å¤šæ–‡ä»¶ä¸Šä¼ ï¼ˆç›®å½•ï¼‰
        if not files or len(files) == 0:
            raise HTTPException(status_code=400, detail="ç›®å½•ä¸Šä¼ éœ€è¦è‡³å°‘ä¸€ä¸ªæ–‡ä»¶")
        upload_files = files
        filename = f"directory_{len(files)}_files"
    
    temp_file_path = None
    temp_dir = None
    
    try:
        print(f"å¼€å§‹å¤„ç†ä¸Šä¼ æ–‡ä»¶: {filename}")
        
        if upload_type == "file":
            # å•æ–‡ä»¶ä¸Šä¼ ï¼ˆå‹ç¼©åŒ…ï¼‰
            file = upload_files[0]
            with tempfile.NamedTemporaryFile(delete=False, suffix='.zip') as tmp_file:
                content = await file.read()
                tmp_file.write(content)
                temp_file_path = tmp_file.name
            print(f"å‹ç¼©åŒ…å·²ä¿å­˜åˆ°ä¸´æ—¶ä½ç½®: {temp_file_path}")
        else:
            # ç›®å½•ä¸Šä¼ ï¼ˆå¤šæ–‡ä»¶ï¼‰
            temp_dir = tempfile.mkdtemp(prefix="comprehensive_detection_")
            print(f"åˆ›å»ºä¸´æ—¶ç›®å½•: {temp_dir}")
            
            # ä¿å­˜æ‰€æœ‰æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
            for file in upload_files:
                if file.filename:
                    # å¤„ç†æ–‡ä»¶è·¯å¾„ç»“æ„
                    if '/' in file.filename or '\\' in file.filename:
                        file_path = os.path.join(temp_dir, file.filename)
                    else:
                        file_path = os.path.join(temp_dir, file.filename)
                    
                    os.makedirs(os.path.dirname(file_path), exist_ok=True)
                    
                    with open(file_path, "wb") as f:
                        content = await file.read()
                        f.write(content)
                    print(f"ä¿å­˜æ–‡ä»¶: {file.filename} -> {file_path}")
            
            # åˆ›å»ºZIPæ–‡ä»¶
            temp_file_path = os.path.join(temp_dir, "project.zip")
            with zipfile.ZipFile(temp_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for root, dirs, files in os.walk(temp_dir):
                    for file in files:
                        if file != "project.zip":  # é¿å…åŒ…å«è‡ªå·±
                            file_path = os.path.join(root, file)
                            arcname = os.path.relpath(file_path, temp_dir)
                            zipf.write(file_path, arcname)
            
            print(f"ç›®å½•å·²æ‰“åŒ…ä¸ºZIP: {temp_file_path}")
        
        # ä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºç‹¬ç«‹çš„æ£€æµ‹å™¨å®ä¾‹
        detector = ComprehensiveDetector(static_agent, dynamic_agent)
        detector.enable_web_app_test = enable_web_app_test
        detector.enable_dynamic_detection = enable_dynamic_detection
        detector.enable_flask_specific_tests = enable_flask_specific_tests
        detector.enable_server_testing = enable_server_testing
        
        # æ‰§è¡Œæ£€æµ‹ï¼ˆæ·»åŠ è¶…æ—¶å¤„ç†ï¼‰
        print("=" * 60)
        print("ğŸš€ [API] å¼€å§‹æ‰§è¡Œç»¼åˆæ£€æµ‹...")
        print(f"ğŸ“ [API] æ–‡ä»¶è·¯å¾„: {temp_file_path}")
        print(f"âš™ï¸  [API] æ£€æµ‹é€‰é¡¹:")
        print(f"   - static_analysis: {static_analysis}")
        print(f"   - dynamic_monitoring: {dynamic_monitoring}")
        print(f"   - runtime_analysis: {runtime_analysis}")
        print(f"   - enable_dynamic_detection: {enable_dynamic_detection}")
        print(f"   - enable_flask_specific_tests: {enable_flask_specific_tests}")
        print(f"   - enable_server_testing: {enable_server_testing}")
        print(f"   - enable_pylint: {enable_pylint}")
        print(f"   - enable_mypy: {enable_mypy}")
        print(f"   - enable_semgrep: {enable_semgrep}")
        print(f"   - enable_ruff: {enable_ruff}")
        print(f"   - enable_bandit: {enable_bandit}")
        print(f"   - enable_llm_filter: {enable_llm_filter}")
        print("=" * 60)
        
        if enable_web_app_test or enable_server_testing:
            print("âš ï¸ å·²å¯ç”¨Webåº”ç”¨æµ‹è¯•ï¼Œæ£€æµ‹æ—¶é—´å¯èƒ½è¾ƒé•¿...")
        
        try:
            results = await asyncio.wait_for(
                detector.detect_defects(
                    zip_file_path=temp_file_path,
                    static_analysis=static_analysis,
                    dynamic_monitoring=dynamic_monitoring,
                    runtime_analysis=runtime_analysis,
                    enable_web_app_test=enable_web_app_test,
                    enable_dynamic_detection=enable_dynamic_detection,
                    enable_flask_specific_tests=enable_flask_specific_tests,
                    enable_server_testing=enable_server_testing,
                    # é™æ€æ£€æµ‹å·¥å…·é€‰æ‹©
                    enable_pylint=enable_pylint,
                    enable_mypy=enable_mypy,
                    enable_semgrep=enable_semgrep,
                    enable_ruff=enable_ruff,
                    enable_bandit=enable_bandit,
                    enable_llm_filter=enable_llm_filter
                ),
                timeout=1800  # 30åˆ†é’Ÿè¶…æ—¶ï¼ˆ1800ç§’ï¼‰
            )
        except asyncio.TimeoutError:
            return BaseResponse(
                success=False,
                error="æ£€æµ‹è¶…æ—¶ï¼ˆ30åˆ†é’Ÿï¼‰",
                message="æ£€æµ‹è¿‡ç¨‹è¶…æ—¶ï¼Œè¯·å°è¯•ä¸Šä¼ è¾ƒå°çš„é¡¹ç›®"
            )
        except Exception as e:
            print(f"âŒ [API] æ£€æµ‹è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return BaseResponse(
                success=False,
                error=f"æ£€æµ‹è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {str(e)}",
                message="æ£€æµ‹å¤±è´¥ï¼Œè¯·æŸ¥çœ‹é”™è¯¯ä¿¡æ¯"
            )
        
            print("=" * 60)
            print("âœ… [API] æ£€æµ‹å®Œæˆ")
            print(f"ğŸ“Š [API] æ£€æµ‹ç»“æœæ‘˜è¦:")
            if results.get("summary"):
                summary = results["summary"]
                print(f"   - æ€»æ–‡ä»¶æ•°: {summary.get('total_files', 0)}")
                print(f"   - æ€»é—®é¢˜æ•°: {summary.get('total_issues', 0)}")
                print(f"   - ä¸¥é‡é—®é¢˜: {summary.get('critical_issues', 0)}")
                print(f"   - è­¦å‘Šé—®é¢˜: {summary.get('warning_issues', 0)}")
            if results.get("merged_defects"):
                print(f"   - åˆå¹¶ç¼ºé™·æ•°: {len(results['merged_defects'])}")
            if results.get("task_info_file"):
                print(f"   - ä»»åŠ¡ä¿¡æ¯æ–‡ä»¶: {results['task_info_file']}")
            if results.get("task_info"):
                print(f"   - ä»»åŠ¡æ•°é‡: {len(results['task_info'])}")
            print("=" * 60)
        
        print("\nğŸ“ [API] æ£€æµ‹å®Œæˆï¼Œç”ŸæˆæŠ¥å‘Š...")
        
        # ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
        report = detector.generate_report(results)
        print("âœ… [API] æ–‡æœ¬æŠ¥å‘Šå·²ç”Ÿæˆ")
        
        # ç”ŸæˆAIæŠ¥å‘Š
        try:
            filename = file.filename if file else (files[0].filename if files else "unknown")
            ai_report = await generate_ai_comprehensive_report(results, filename)
            print("âœ… [API] AIæŠ¥å‘Šç”ŸæˆæˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ [API] AIæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            ai_report = {
                "success": False,
                "error": str(e),
                "summary": "AIæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œè¯·æŸ¥çœ‹è¯¦ç»†æ£€æµ‹ç»“æœ"
            }
        
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶ï¼ˆä½¿ç”¨ç»å¯¹è·¯å¾„ï¼‰
        try:
            results_file = f"comprehensive_detection_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            # è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆAPIæ–‡ä»¶æ‰€åœ¨ç›®å½•çš„çˆ¶ç›®å½•ï¼‰
            api_dir = Path(__file__).parent
            project_root = api_dir.parent
            results_dir = project_root / "comprehensive_detection_results"
            results_dir.mkdir(exist_ok=True)
            results_path = results_dir / results_file
            results_path_abs = results_path.resolve()
            detector.save_results(results, str(results_path_abs))
            print(f"âœ… [API] ç»“æœå·²ä¿å­˜åˆ°:")
            print(f"   ç›¸å¯¹è·¯å¾„: {results_path}")
            print(f"   ç»å¯¹è·¯å¾„: {results_path_abs}")
            print(f"ğŸ“Š [API] æ–‡ä»¶å¤§å°: {results_path_abs.stat().st_size / 1024:.2f} KB")
        except Exception as e:
            print(f"âš ï¸ [API] ä¿å­˜ç»“æœæ–‡ä»¶å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            results_file = None
        
        # æ£€æŸ¥ä»»åŠ¡ä¿¡æ¯æ–‡ä»¶
        if results.get("task_info_file"):
            task_info_path = Path(results["task_info_file"])
            task_info_path_abs = task_info_path.resolve()
            if task_info_path_abs.exists():
                print(f"âœ… [API] ä»»åŠ¡ä¿¡æ¯æ–‡ä»¶å·²ä¿å­˜:")
                print(f"   ç›¸å¯¹è·¯å¾„: {task_info_path}")
                print(f"   ç»å¯¹è·¯å¾„: {task_info_path_abs}")
                print(f"ğŸ“Š [API] ä»»åŠ¡æ•°é‡: {len(results.get('task_info', []))}")
                print(f"ğŸ“Š [API] æ–‡ä»¶å¤§å°: {task_info_path_abs.stat().st_size / 1024:.2f} KB")
            else:
                print(f"âš ï¸ [API] è­¦å‘Š: ä»»åŠ¡ä¿¡æ¯æ–‡ä»¶è·¯å¾„å­˜åœ¨ä½†æ–‡ä»¶ä¸å­˜åœ¨:")
                print(f"   ç›¸å¯¹è·¯å¾„: {task_info_path}")
                print(f"   ç»å¯¹è·¯å¾„: {task_info_path_abs}")
                print(f"   å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
        else:
            print("âš ï¸ [API] è­¦å‘Š: æœªç”Ÿæˆä»»åŠ¡ä¿¡æ¯æ–‡ä»¶")
        
        # è¿”å›ç»“æœ
        return BaseResponse(
            success=True,
            message="ç»¼åˆæ£€æµ‹å®Œæˆ",
            data={
                "results": results,
                "report": report,
                "ai_report": ai_report,
                "results_file": results_file,
                "filename": file.filename,
                "detection_time": datetime.now().isoformat()
            }
        )
    
    finally:
        # æ³¨æ„ï¼šä¸´æ—¶æ–‡ä»¶ä¿ç•™ï¼Œä¸åˆ é™¤ä¸Šä¼ çš„æ–‡ä»¶ï¼Œä»¥ä¾¿ä¿®å¤Agentä½¿ç”¨
        # åªåˆ é™¤ä¸Šä¼ çš„ZIPå‹ç¼©åŒ…ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if temp_file_path and os.path.exists(temp_file_path):
            # æ£€æŸ¥æ˜¯å¦æ˜¯ZIPæ–‡ä»¶ï¼ˆä¸Šä¼ çš„å‹ç¼©åŒ…å¯ä»¥åˆ é™¤ï¼‰
            # è§£å‹åçš„ç›®å½•ä¿ç•™åœ¨extract_dirä¸­ï¼Œä¸åœ¨è¿™é‡Œåˆ é™¤
            try:
                # åªåˆ é™¤ZIPæ–‡ä»¶ï¼Œä¸åˆ é™¤è§£å‹åçš„ç›®å½•
                if temp_file_path.endswith('.zip'):
                    os.unlink(temp_file_path)
                    print(f"âœ… [API] å·²æ¸…ç†ä¸Šä¼ çš„ZIPæ–‡ä»¶: {temp_file_path}")
                else:
                    print(f"ğŸ“ [API] ä¿ç•™æ–‡ä»¶: {temp_file_path}")
            except Exception as e:
                print(f"âš ï¸ [API] æ¸…ç†ZIPæ–‡ä»¶å¤±è´¥: {e}")
        
        # ä¸æ¸…ç†ä¸´æ—¶ç›®å½•ï¼Œä¿ç•™è§£å‹åçš„é¡¹ç›®æ–‡ä»¶
        # extract_dirä¸­çš„æ–‡ä»¶éœ€è¦ä¿ç•™ä¾›ä¿®å¤Agentä½¿ç”¨
        if temp_dir and os.path.exists(temp_dir):
            print(f"ğŸ“ [API] ä¿ç•™ä¸´æ—¶ç›®å½•ï¼ˆè§£å‹åçš„é¡¹ç›®æ–‡ä»¶ï¼‰: {temp_dir}")
            print(f"âš ï¸ [API] æ³¨æ„: ä¸´æ—¶ç›®å½•æœªåˆ é™¤ï¼Œéœ€è¦å®šæœŸæ¸…ç†ä»¥é‡Šæ”¾ç£ç›˜ç©ºé—´")

@router.get("/status")
async def get_detection_status():
    """è·å–æ£€æµ‹çŠ¶æ€"""
    return {
        "status": "ready",
        "timestamp": datetime.now().isoformat(),
        "supported_formats": [".zip"],
        "features": {
            "static_analysis": True,
            "dynamic_monitoring": True,
            "runtime_analysis": True,
            "comprehensive_detection": True
        }
    }

@router.post("/generate-severe-issues-report")
async def generate_severe_issues_report(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(None),
    files: List[UploadFile] = File(None),
    static_analysis: str = Form("true"),
    dynamic_monitoring: str = Form("true"),
    runtime_analysis: str = Form("true"),
    enable_web_app_test: str = Form("false"),
    enable_dynamic_detection: str = Form("true"),
    enable_flask_specific_tests: str = Form("true"),
    enable_server_testing: str = Form("true"),
    upload_type: str = Form("file")
):
    """ç”Ÿæˆä¸¥é‡é—®é¢˜æ±‡æ€»æ–‡æ¡£"""
    
    # ç¡®ä¿æ‰€æœ‰å¸ƒå°”å‚æ•°éƒ½æ˜¯å¸ƒå°”å€¼
    def convert_to_bool(value, param_name):
        if isinstance(value, str):
            result = value.lower() in ('true', '1', 'yes', 'on')
            return result
        elif isinstance(value, bool):
            return value
        else:
            return bool(value)
    
    static_analysis = convert_to_bool(static_analysis, 'static_analysis')
    dynamic_monitoring = convert_to_bool(dynamic_monitoring, 'dynamic_monitoring')
    runtime_analysis = convert_to_bool(runtime_analysis, 'runtime_analysis')
    enable_web_app_test = convert_to_bool(enable_web_app_test, 'enable_web_app_test')
    enable_dynamic_detection = convert_to_bool(enable_dynamic_detection, 'enable_dynamic_detection')
    enable_flask_specific_tests = convert_to_bool(enable_flask_specific_tests, 'enable_flask_specific_tests')
    enable_server_testing = convert_to_bool(enable_server_testing, 'enable_server_testing')
    
    # éªŒè¯è¾“å…¥
    if not file and not files:
        raise HTTPException(status_code=400, detail="è¯·æä¾›æ–‡ä»¶æˆ–æ–‡ä»¶åˆ—è¡¨")
    
    if file and files:
        raise HTTPException(status_code=400, detail="è¯·é€‰æ‹©å•æ–‡ä»¶ä¸Šä¼ æˆ–ç›®å½•ä¸Šä¼ ï¼Œä¸èƒ½åŒæ—¶ä½¿ç”¨")
    
    # å¤„ç†å•æ–‡ä»¶ä¸Šä¼ ï¼ˆå‹ç¼©åŒ…ï¼‰
    if file:
        if not file.filename.endswith('.zip'):
            raise HTTPException(status_code=400, detail="åªæ”¯æŒZIPæ ¼å¼çš„å‹ç¼©åŒ…")
        upload_files = [file]
        filename = file.filename
    else:
        # å¤„ç†å¤šæ–‡ä»¶ä¸Šä¼ ï¼ˆç›®å½•ï¼‰
        if not files or len(files) == 0:
            raise HTTPException(status_code=400, detail="ç›®å½•ä¸Šä¼ éœ€è¦è‡³å°‘ä¸€ä¸ªæ–‡ä»¶")
        upload_files = files
        filename = f"directory_{len(files)}_files"
    
    temp_file_path = None
    temp_dir = None
    
    try:
        print(f"å¼€å§‹å¤„ç†ä¸Šä¼ æ–‡ä»¶: {filename}")
        
        if upload_type == "file":
            # å•æ–‡ä»¶ä¸Šä¼ ï¼ˆå‹ç¼©åŒ…ï¼‰
            file = upload_files[0]
            with tempfile.NamedTemporaryFile(delete=False, suffix='.zip') as tmp_file:
                content = await file.read()
                tmp_file.write(content)
                temp_file_path = tmp_file.name
            print(f"å‹ç¼©åŒ…å·²ä¿å­˜åˆ°ä¸´æ—¶ä½ç½®: {temp_file_path}")
        else:
            # ç›®å½•ä¸Šä¼ ï¼ˆå¤šæ–‡ä»¶ï¼‰
            temp_dir = tempfile.mkdtemp(prefix="comprehensive_detection_")
            print(f"åˆ›å»ºä¸´æ—¶ç›®å½•: {temp_dir}")
            
            # ä¿å­˜æ‰€æœ‰æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
            for file in upload_files:
                if file.filename:
                    # å¤„ç†æ–‡ä»¶è·¯å¾„ç»“æ„
                    if '/' in file.filename or '\\' in file.filename:
                        file_path = os.path.join(temp_dir, file.filename)
                    else:
                        file_path = os.path.join(temp_dir, file.filename)
                    
                    os.makedirs(os.path.dirname(file_path), exist_ok=True)
                    
                    with open(file_path, "wb") as f:
                        content = await file.read()
                        f.write(content)
                    print(f"ä¿å­˜æ–‡ä»¶: {file.filename} -> {file_path}")
            
            # åˆ›å»ºZIPæ–‡ä»¶
            temp_file_path = os.path.join(temp_dir, "project.zip")
            with zipfile.ZipFile(temp_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for root, dirs, files in os.walk(temp_dir):
                    for file in files:
                        if file != "project.zip":  # é¿å…åŒ…å«è‡ªå·±
                            file_path = os.path.join(root, file)
                            arcname = os.path.relpath(file_path, temp_dir)
                            zipf.write(file_path, arcname)
            
            print(f"ç›®å½•å·²æ‰“åŒ…ä¸ºZIP: {temp_file_path}")
        
        # ä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºç‹¬ç«‹çš„æ£€æµ‹å™¨å®ä¾‹
        detector = ComprehensiveDetector(static_agent, dynamic_agent)
        detector.enable_web_app_test = enable_web_app_test
        detector.enable_dynamic_detection = enable_dynamic_detection
        detector.enable_flask_specific_tests = enable_flask_specific_tests
        detector.enable_server_testing = enable_server_testing
        
        # æ‰§è¡Œæ£€æµ‹
        print("å¼€å§‹æ‰§è¡Œç»¼åˆæ£€æµ‹...")
        try:
            results = await asyncio.wait_for(
                detector.detect_defects(
                    zip_file_path=temp_file_path,
                    static_analysis=static_analysis,
                    dynamic_monitoring=dynamic_monitoring,
                    runtime_analysis=runtime_analysis,
                    enable_dynamic_detection=enable_dynamic_detection,
                    enable_flask_specific_tests=enable_flask_specific_tests,
                    enable_server_testing=enable_server_testing,
                    enable_web_app_test=enable_web_app_test
                ),
                timeout=1800  # 30åˆ†é’Ÿè¶…æ—¶ï¼ˆ1800ç§’ï¼‰
            )
        except asyncio.TimeoutError:
            return BaseResponse(
                success=False,
                error="æ£€æµ‹è¶…æ—¶ï¼ˆ30åˆ†é’Ÿï¼‰",
                message="æ£€æµ‹è¿‡ç¨‹è¶…æ—¶ï¼Œè¯·å°è¯•ä¸Šä¼ è¾ƒå°çš„é¡¹ç›®"
            )
        
        print("æ£€æµ‹å®Œæˆï¼Œç”Ÿæˆä¸¥é‡é—®é¢˜æ±‡æ€»æ–‡æ¡£...")
        
        # ç”Ÿæˆä¸¥é‡é—®é¢˜æ±‡æ€»æ–‡æ¡£
        severe_issues_report = detector.generate_severe_issues_report(results, filename)
        
        # ä¿å­˜æ–‡æ¡£åˆ°resultæ–‡ä»¶å¤¹
        try:
            report_filename = f"severe_issues_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
            result_dir = Path("result")
            result_dir.mkdir(exist_ok=True)
            report_path = result_dir / report_filename
            
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(severe_issues_report)
            
            print(f"âœ… ä¸¥é‡é—®é¢˜æ±‡æ€»æ–‡æ¡£å·²ä¿å­˜åˆ°: {report_path}")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜æ–‡æ¡£æ–‡ä»¶å¤±è´¥: {e}")
            report_filename = None
        
        # è¿”å›ç»“æœ
        return BaseResponse(
            success=True,
            message="ä¸¥é‡é—®é¢˜æ±‡æ€»æ–‡æ¡£ç”Ÿæˆå®Œæˆ",
            data={
                "severe_issues_report": severe_issues_report,
                "report_filename": report_filename,
                "report_path": str(report_path) if report_filename else None,
                "filename": filename,
                "generation_time": datetime.now().isoformat(),
                "summary": results.get("summary", {})
            }
        )
    
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_file_path and os.path.exists(temp_file_path):
            try:
                os.unlink(temp_file_path)
                print(f"å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_file_path}")
            except Exception as e:
                print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
        
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        if temp_dir and os.path.exists(temp_dir):
            try:
                import shutil
                shutil.rmtree(temp_dir)
                print(f"å·²æ¸…ç†ä¸´æ—¶ç›®å½•: {temp_dir}")
            except Exception as e:
                print(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")
