#!/usr/bin/env python3
"""
æ¸…ç†ç©ºç™½å­—ç¬¦å·¥å…· æœ€ç»ˆç‰ˆæœ¬
æ”¯æŒå¤šç§æ¸…ç†æ¨¡å¼ã€é…ç½®æ–‡ä»¶ã€è¯¦ç»†æŠ¥å‘Š
"""

import os
import re
import argparse
import json
import time
from pathlib import Path
from typing import List, Optional, Dict, Any, Tuple

class WhitespaceCleanerFinal:
    """ç©ºç™½å­—ç¬¦æ¸…ç†å™¨ æœ€ç»ˆç‰ˆæœ¬"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or self._default_config()
        self.cleaned_files = []
        self.errors = []
        self.warnings = []
        self.stats = {
            "start_time": time.time(),
            "end_time": None,
            "files_processed": 0,
            "files_cleaned": 0,
            "files_skipped": 0,
            "lines_removed": 0,
            "bytes_saved": 0,
            "backup_files_created": 0
        }
    
    def _default_config(self) -> Dict[str, Any]:
        """é»˜è®¤é…ç½®"""
        return {
            "extensions": ['.py', '.js', '.html', '.css', '.md', '.txt', '.json', '.xml', '.yaml', '.yml'],
            "exclude_patterns": [
                r'\.git/',
                r'node_modules/',
                r'__pycache__/',
                r'\.pyc$',
                r'\.backup$'
            ],
            "cleaning_rules": {
                "remove_trailing_whitespace": True,
                "remove_trailing_tabs": True,
                "normalize_line_endings": True,
                "max_consecutive_empty_lines": 2,
                "remove_final_empty_lines": True,
                "preserve_indentation": True,
                "remove_bom": True
            },
            "backup": {
                "enabled": False,
                "suffix": ".backup",
                "directory": None
            },
            "reporting": {
                "verbose": False,
                "show_details": True,
                "save_report": False
            }
        }
    
    def _should_exclude_file(self, file_path: str) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åº”è¯¥è¢«æ’é™¤"""
        for pattern in self.config["exclude_patterns"]:
            if re.search(pattern, file_path):
                return True
        return False
    
    def clean_file(self, file_path: str) -> Dict[str, Any]:
        """æ¸…ç†å•ä¸ªæ–‡ä»¶"""
        result = {
            "file": file_path,
            "cleaned": False,
            "skipped": False,
            "lines_removed": 0,
            "bytes_saved": 0,
            "backup_created": False,
            "error": None,
            "warning": None
        }
        
        try:
            self.stats["files_processed"] += 1
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤
            if self._should_exclude_file(file_path):
                result["skipped"] = True
                self.stats["files_skipped"] += 1
                return result
            
            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            if Path(file_path).suffix not in self.config["extensions"]:
                result["skipped"] = True
                self.stats["files_skipped"] += 1
                return result
            
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            original_content = content
            original_lines = len(content.split('\n'))
            original_size = len(content.encode('utf-8'))
            
            # åº”ç”¨æ¸…ç†è§„åˆ™
            content = self._apply_cleaning_rules(content)
            
            # å¦‚æœå†…å®¹æœ‰å˜åŒ–ï¼Œå†™å›æ–‡ä»¶
            if content != original_content:
                # åˆ›å»ºå¤‡ä»½
                if self.config["backup"]["enabled"]:
                    backup_path = self._create_backup(file_path)
                    if backup_path:
                        result["backup_created"] = True
                        self.stats["backup_files_created"] += 1
                
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                
                new_lines = len(content.split('\n'))
                new_size = len(content.encode('utf-8'))
                
                result["cleaned"] = True
                result["lines_removed"] = original_lines - new_lines
                result["bytes_saved"] = original_size - new_size
                
                self.stats["files_cleaned"] += 1
                self.stats["lines_removed"] += result["lines_removed"]
                self.stats["bytes_saved"] += result["bytes_saved"]
                
                self.cleaned_files.append(file_path)
            
        except Exception as e:
            result["error"] = str(e)
            self.errors.append(f"{file_path}: {e}")
        
        return result
    
    def _apply_cleaning_rules(self, content: str) -> str:
        """åº”ç”¨æ¸…ç†è§„åˆ™"""
        rules = self.config["cleaning_rules"]
        
        # ç§»é™¤BOM
        if rules["remove_bom"]:
            content = content.lstrip('\ufeff')
        
        # æ¸…ç†è¡Œå°¾ç©ºç™½
        if rules["remove_trailing_whitespace"]:
            content = re.sub(r'[ \t]+$', '', content, flags=re.MULTILINE)
        
        # æ¸…ç†è¡Œå°¾åˆ¶è¡¨ç¬¦
        if rules["remove_trailing_tabs"]:
            content = re.sub(r'\t+$', '', content, flags=re.MULTILINE)
        
        # æ ‡å‡†åŒ–è¡Œç»“æŸç¬¦
        if rules["normalize_line_endings"]:
            content = content.replace('\r\n', '\n').replace('\r', '\n')
        
        # æ¸…ç†è¿ç»­çš„ç©ºè¡Œ
        if rules["max_consecutive_empty_lines"] > 0:
            max_empty = rules["max_consecutive_empty_lines"]
            pattern = r'\n{' + str(max_empty + 1) + ',}'
            content = re.sub(pattern, '\n' * max_empty, content)
        
        # æ¸…ç†æ–‡ä»¶æœ«å°¾çš„ç©ºè¡Œ
        if rules["remove_final_empty_lines"]:
            content = content.rstrip() + '\n'
        
        return content
    
    def _create_backup(self, file_path: str) -> Optional[str]:
        """åˆ›å»ºå¤‡ä»½æ–‡ä»¶"""
        try:
            backup_config = self.config["backup"]
            
            if backup_config["directory"]:
                backup_dir = Path(backup_config["directory"])
                backup_dir.mkdir(parents=True, exist_ok=True)
                backup_path = backup_dir / (Path(file_path).name + backup_config["suffix"])
            else:
                backup_path = file_path + backup_config["suffix"]
            
            with open(file_path, 'r', encoding='utf-8') as src:
                with open(backup_path, 'w', encoding='utf-8') as dst:
                    dst.write(src.read())
            
            return str(backup_path)
            
        except Exception as e:
            self.warnings.append(f"å¤‡ä»½å¤±è´¥ {file_path}: {e}")
            return None
    
    def clean_directory(self, directory_path: str) -> List[Dict[str, Any]]:
        """æ¸…ç†ç›®å½•ä¸­çš„æ–‡ä»¶"""
        results = []
        path = Path(directory_path)
        
        if path.is_file():
            result = self.clean_file(str(path))
            results.append(result)
        elif path.is_dir():
            for file_path in path.rglob('*'):
                if file_path.is_file():
                    result = self.clean_file(str(file_path))
                    results.append(result)
        
        self.stats["end_time"] = time.time()
        return results
    
    def get_summary(self) -> Dict[str, Any]:
        """è·å–æ¸…ç†æ€»ç»“"""
        duration = self.stats["end_time"] - self.stats["start_time"] if self.stats["end_time"] else 0
        
        return {
            "stats": {
                **self.stats,
                "duration_seconds": duration
            },
            "cleaned_files": len(self.cleaned_files),
            "errors": len(self.errors),
            "warnings": len(self.warnings),
            "files": self.cleaned_files,
            "error_details": self.errors,
            "warning_details": self.warnings,
            "config": self.config
        }
    
    def save_report(self, output_file: str):
        """ä¿å­˜æ¸…ç†æŠ¥å‘Š"""
        report = {
            "timestamp": time.time(),
            "summary": self.get_summary(),
            "details": self.cleaned_files
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ¸…ç†ç©ºç™½å­—ç¬¦å·¥å…· æœ€ç»ˆç‰ˆæœ¬')
    parser.add_argument('path', help='è¦æ¸…ç†çš„æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„')
    parser.add_argument('--extensions', nargs='+', 
                       default=['.py', '.js', '.html', '.css', '.md', '.txt', '.json'],
                       help='è¦æ¸…ç†çš„æ–‡ä»¶æ‰©å±•å')
    parser.add_argument('--config', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--report', help='ä¿å­˜æ¸…ç†æŠ¥å‘Šåˆ°æŒ‡å®šæ–‡ä»¶')
    parser.add_argument('--dry-run', action='store_true',
                       help='åªæ˜¾ç¤ºä¼šæ¸…ç†çš„æ–‡ä»¶ï¼Œä¸å®é™…ä¿®æ”¹')
    parser.add_argument('--backup', action='store_true',
                       help='æ¸…ç†å‰å¤‡ä»½æ–‡ä»¶')
    parser.add_argument('--backup-dir', help='å¤‡ä»½æ–‡ä»¶ç›®å½•')
    parser.add_argument('--max-empty-lines', type=int, default=2,
                       help='æœ€å¤§è¿ç»­ç©ºè¡Œæ•°')
    parser.add_argument('--verbose', action='store_true',
                       help='è¯¦ç»†è¾“å‡º')
    parser.add_argument('--exclude', nargs='+', 
                       help='æ’é™¤çš„æ–‡ä»¶æ¨¡å¼')
    
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    config = None
    if args.config and os.path.exists(args.config):
        with open(args.config, 'r', encoding='utf-8') as f:
            config = json.load(f)
    
    # åˆ›å»ºæ¸…ç†å™¨
    cleaner = WhitespaceCleanerFinal(config)
    
    # åº”ç”¨å‘½ä»¤è¡Œå‚æ•°
    cleaner.config["extensions"] = args.extensions
    cleaner.config["backup"]["enabled"] = args.backup
    cleaner.config["backup"]["directory"] = args.backup_dir
    cleaner.config["cleaning_rules"]["max_consecutive_empty_lines"] = args.max_empty_lines
    cleaner.config["reporting"]["verbose"] = args.verbose
    
    if args.exclude:
        cleaner.config["exclude_patterns"].extend(args.exclude)
    
    print(f"ğŸ§¹ æ¸…ç†ç©ºç™½å­—ç¬¦ æœ€ç»ˆç‰ˆæœ¬: {args.path}")
    print(f"ğŸ“ æ–‡ä»¶ç±»å‹: {', '.join(args.extensions)}")
    print(f"ğŸ“Š æœ€å¤§è¿ç»­ç©ºè¡Œ: {args.max_empty_lines}")
    
    if args.backup:
        print(f"ğŸ’¾ å¤‡ä»½å·²å¯ç”¨")
        if args.backup_dir:
            print(f"ğŸ“ å¤‡ä»½ç›®å½•: {args.backup_dir}")
    
    if args.dry_run:
        print("ğŸ” é¢„è§ˆæ¨¡å¼ - ä¸ä¼šå®é™…ä¿®æ”¹æ–‡ä»¶")
        # è¿™é‡Œå¯ä»¥æ·»åŠ é¢„è§ˆé€»è¾‘
        return
    
    results = cleaner.clean_directory(args.path)
    
    summary = cleaner.get_summary()
    
    print(f"âœ… æ¸…ç†å®Œæˆ!")
    print(f"â±ï¸ è€—æ—¶: {summary['stats']['duration_seconds']:.2f} ç§’")
    print(f"ğŸ“Š å¤„ç†äº† {summary['stats']['files_processed']} ä¸ªæ–‡ä»¶")
    print(f"ğŸ§¹ æ¸…ç†äº† {summary['stats']['files_cleaned']} ä¸ªæ–‡ä»¶")
    print(f"â­ï¸ è·³è¿‡äº† {summary['stats']['files_skipped']} ä¸ªæ–‡ä»¶")
    print(f"ğŸ“ ç§»é™¤äº† {summary['stats']['lines_removed']} è¡Œ")
    print(f"ğŸ’¾ èŠ‚çœäº† {summary['stats']['bytes_saved']} å­—èŠ‚")
    
    if summary["stats"]["backup_files_created"] > 0:
        print(f"ğŸ’¾ åˆ›å»ºäº† {summary['stats']['backup_files_created']} ä¸ªå¤‡ä»½æ–‡ä»¶")
    
    if summary["errors"]:
        print(f"âŒ é‡åˆ° {summary['errors']} ä¸ªé”™è¯¯:")
        for error in summary["error_details"]:
            print(f"  - {error}")
    
    if summary["warnings"]:
        print(f"âš ï¸ é‡åˆ° {summary['warnings']} ä¸ªè­¦å‘Š:")
        for warning in summary["warning_details"]:
            print(f"  - {warning}")
    
    if args.report:
        cleaner.save_report(args.report)
        print(f"ğŸ“„ æ¸…ç†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.report}")


if __name__ == "__main__":
    main()
