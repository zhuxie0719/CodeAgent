import asyncio
import os
import subprocess
import sys
from typing import Dict, List, Any, Optional

from ..base_agent import BaseAgent
from .llm_utils import LLMFixer


class FixExecutionAgent(BaseAgent):
    """LLMå¤šé—®é¢˜ä¿®å¤å®ç°ï¼šæŒ‰æ–‡ä»¶èšåˆé—®é¢˜ï¼Œç”Ÿæˆ _before/_after æ–‡ä»¶ã€‚"""

    def __init__(self, agent_id: str = "fix_execution_agent", config: Optional[Dict[str, Any]] = None):
        super().__init__(agent_id, config or {})
        # API keyç¡¬ç¼–ç 
        self.llm = LLMFixer(
            api_key="sk-75db9bf464d44ee78b5d45a655431710",
            model=self.config.get("LLM_MODEL", "deepseek-coder"),
            base_url=self.config.get("LLM_BASE_URL", "https://api.deepseek.com/v1/chat/completions"),
        )
    
    def _resolve_temp_extract_path(self, path: str) -> str:
        """Resolve temp_extract paths to actual location at ../../api/temp_extract"""
        if path.startswith("temp_extract"):
            agent_dir = os.path.dirname(os.path.abspath(__file__))
            api_dir = os.path.join(agent_dir, "..", "..", "api")
            api_dir = os.path.abspath(api_dir)
            # Replace temp_extract and normalize the entire path to fix mixed slashes
            resolved = path.replace("temp_extract", os.path.join(api_dir, "temp_extract"), 1)
            # Normalize to fix mixed slashes (forward/backward)
            resolved = os.path.normpath(resolved)
            return resolved
        return path

    async def initialize(self) -> bool:
        return True

    def get_capabilities(self) -> List[str]:
        return ["llm_multi_issue_fix", "write_before_after_files"]

    async def process_task(self, task_id: str, task_data: Dict[str, Any]) -> Dict[str, Any]:
        # æ”¯æŒä¸¤ç§æ•°æ®æ ¼å¼ï¼š
        # 1. æ—§æ ¼å¼: { 'file_path': <path>, 'issues': <list> }
        # 2. æ–°æ ¼å¼: { 'project_path': <path>, 'issues': <list>, 'decisions': <dict> }
        self.logger.info("**************************************************************************")
        base_file_path = task_data.get("file_path") or task_data.get("project_path", "")
        issues: List[Dict[str, Any]] = task_data.get("issues", []) or []
        print(task_data)

        
        # æ·»åŠ è°ƒè¯•æ—¥å¿—
        self.logger.info(f"ğŸ”§ ä¿®å¤Agentæ¥æ”¶ä»»åŠ¡æ•°æ®:")
        self.logger.info(f"   æ–‡ä»¶è·¯å¾„: {base_file_path}")
        self.logger.info(f"   é—®é¢˜æ•°é‡: {len(issues)}")
        self.logger.info(f"   ä»»åŠ¡æ•°æ®é”®: {list(task_data.keys())}")
        
        if not base_file_path:
            return {
                "success": False,
                "task_id": task_id,
                "fix_results": [],
                "total_issues": 0,
                "fixed_issues": 0,
                "failed_issues": 0,
                "skipped_issues": 0,
                "errors": ["æœªæä¾›æ–‡ä»¶è·¯å¾„"],
                "timestamp": asyncio.get_event_loop().time(),
                "message": "ä¿®å¤å¤±è´¥ï¼šæœªæä¾›æ–‡ä»¶è·¯å¾„"
            }

        # ç¡®å®šé¡¹ç›®æ ¹ç›®å½•å’Œè¾“å‡ºç›®å½•
        # Fix path: temp_extract is actually at ../../api/temp_extract relative to agent code
        original_path = base_file_path
        base_file_path = self._resolve_temp_extract_path(base_file_path)
        base_file_path = os.path.normpath(base_file_path)  # Normalize after resolution
        if base_file_path != original_path:
            self.logger.info(f"ğŸ”§ è·¯å¾„ä¿®æ­£: {original_path} -> {base_file_path}")
        
        # å¦‚æœbase_file_pathæ˜¯ç›®å½•ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦‚æœæ˜¯æ–‡ä»¶ï¼Œä½¿ç”¨å…¶çˆ¶ç›®å½•
        if os.path.isdir(base_file_path):
            project_root = base_file_path
        else:
            project_root = os.path.dirname(base_file_path) if base_file_path else os.getcwd()
        
        # è¾“å‡ºæ–‡ä»¶å¤¹ï¼šä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„outputå­ç›®å½•
        output_dir = os.path.join(project_root, "output")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆå¤„ç†æƒé™é—®é¢˜ï¼‰
        try:
            os.makedirs(output_dir, exist_ok=True)
            self.logger.info(f"âœ… è¾“å‡ºç›®å½•å·²åˆ›å»º: {output_dir}")
        except PermissionError as e:
            # å¦‚æœé¡¹ç›®ç›®å½•æƒé™ä¸è¶³ï¼Œå°è¯•ä½¿ç”¨ä¸´æ—¶ç›®å½•
            import tempfile
            output_dir = os.path.join(tempfile.gettempdir(), f"fix_output_{task_id[:8]}")
            os.makedirs(output_dir, exist_ok=True)
            self.logger.warning(f"âš ï¸ é¡¹ç›®ç›®å½•æƒé™ä¸è¶³ï¼Œä½¿ç”¨ä¸´æ—¶ç›®å½•: {output_dir}")
            self.logger.warning(f"   åŸå§‹é”™è¯¯: {e}")
        except Exception as e:
            self.logger.error(f"âŒ åˆ›å»ºè¾“å‡ºç›®å½•å¤±è´¥: {e}")
            return {
                "success": False,
                "task_id": task_id,
                "fix_results": [],
                "total_issues": len(issues),
                "fixed_issues": 0,
                "failed_issues": len(issues),
                "skipped_issues": 0,
                "errors": [f"åˆ›å»ºè¾“å‡ºç›®å½•å¤±è´¥: {str(e)}"],
                "timestamp": asyncio.get_event_loop().time(),
                "message": f"ä¿®å¤å¤±è´¥ï¼šæ— æ³•åˆ›å»ºè¾“å‡ºç›®å½•"
            }

        # Track skipped issues during validation
        skipped_issues: List[Dict[str, Any]] = []  # è¿½è¸ªè¢«è·³è¿‡çš„é—®é¢˜åŠå…¶åŸå› 
        
        # First pass: validate all issues and track skipped ones
        for issue in issues:
            # è·å–é—®é¢˜æ‰€åœ¨çš„æ–‡ä»¶è·¯å¾„
            issue_file_path = issue.get("file_path") or issue.get("file")
            
            if not issue_file_path:
                # å¦‚æœæ²¡æœ‰æ–‡ä»¶è·¯å¾„ä¿¡æ¯ï¼Œè·³è¿‡è¿™ä¸ªé—®é¢˜
                skip_reason = "ç¼ºå°‘æ–‡ä»¶è·¯å¾„ä¿¡æ¯"
                self.logger.warning(f"âš ï¸ é—®é¢˜ç¼ºå°‘æ–‡ä»¶è·¯å¾„ä¿¡æ¯ï¼Œè·³è¿‡: {issue.get('message', 'unknown')[:50]}")
                skipped_issues.append({
                    "issue": issue,
                    "reason": skip_reason,
                    "file_path": None
                })
                continue
            
            # è§„èŒƒåŒ–è·¯å¾„å¤„ç†
            # Fix path: if path starts with temp_extract, resolve it to ../../api/temp_extract
            issue_file_path = self._resolve_temp_extract_path(issue_file_path)
            
            if os.path.isabs(issue_file_path):
                # å·²ç»æ˜¯ç»å¯¹è·¯å¾„
                file_name = os.path.normpath(issue_file_path)
                # æ£€æŸ¥è·¯å¾„æ˜¯å¦åŒ…å«project_rootï¼ˆé¿å…é‡å¤åµŒå¥—ï¼‰
                if project_root not in file_name:
                    # è·¯å¾„ä¸åŒ…å«é¡¹ç›®è·¯å¾„ï¼Œä½†å·²ç»æ˜¯ç»å¯¹è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨
                    self.logger.info(f"ğŸ”§ ç»å¯¹è·¯å¾„ä¸åŒ…å«é¡¹ç›®æ ¹ç›®å½•ï¼Œç›´æ¥ä½¿ç”¨: {file_name}")
            else:
                # ç›¸å¯¹è·¯å¾„ï¼Œéœ€è¦æ‹¼æ¥é¡¹ç›®æ ¹ç›®å½•
                # å…ˆè§„èŒƒåŒ–ç›¸å¯¹è·¯å¾„ï¼Œç§»é™¤å¼€å¤´çš„./æˆ–../
                issue_file_path = issue_file_path.lstrip('./').lstrip('../')
                file_name = os.path.normpath(os.path.join(project_root, issue_file_path))
            
            # å†æ¬¡è§„èŒƒåŒ–è·¯å¾„
            file_name = os.path.normpath(file_name)
            
            # å¤„ç†è·¯å¾„é‡å¤åµŒå¥—é—®é¢˜ï¼ˆå¦‚ temp_extract/project_xxx/temp_extract/project_xxx/file.pyï¼‰
            # æ£€æµ‹å¹¶ç§»é™¤é‡å¤çš„è·¯å¾„æ®µåºåˆ—
            path_parts = file_name.split(os.sep)
            
            # æŸ¥æ‰¾é‡å¤çš„è·¯å¾„æ®µåºåˆ—
            if len(path_parts) > 2:
                # ä»æœ€å¤§å¯èƒ½çš„æ¨¡å¼é•¿åº¦å¼€å§‹æ£€æŸ¥ï¼ˆæœ€å¤šæ£€æŸ¥åˆ°è·¯å¾„é•¿åº¦çš„ä¸€åŠï¼‰
                max_pattern_len = min(len(path_parts) // 2, 10)  # é™åˆ¶æœ€å¤§æ¨¡å¼é•¿åº¦ä¸º10ï¼Œé¿å…æ€§èƒ½é—®é¢˜
                
                for pattern_len in range(max_pattern_len, 0, -1):  # ä»å¤§åˆ°å°æ£€æŸ¥ï¼Œä¼˜å…ˆå¤„ç†é•¿çš„é‡å¤æ¨¡å¼
                    if len(path_parts) < pattern_len * 2:
                        continue
                    
                    # æ£€æŸ¥å‰pattern_lenä¸ªæ®µæ˜¯å¦ä¸æ¥ä¸‹æ¥çš„pattern_lenä¸ªæ®µç›¸åŒ
                    pattern = path_parts[:pattern_len]
                    next_pattern = path_parts[pattern_len:pattern_len * 2]
                    
                    if pattern == next_pattern:
                        # æ‰¾åˆ°é‡å¤æ¨¡å¼ï¼Œç§»é™¤é‡å¤çš„éƒ¨åˆ†
                        self.logger.info(f"ğŸ”§ æ£€æµ‹åˆ°è·¯å¾„é‡å¤åµŒå¥—ï¼Œç§»é™¤é‡å¤æ®µ: {os.sep.join(pattern)}")
                        file_name = os.sep.join(path_parts[pattern_len:])
                        file_name = os.path.normpath(file_name)
                        break
                
                # å¦‚æœè·¯å¾„çœ‹èµ·æ¥å¼‚å¸¸é•¿ï¼Œè®°å½•æ—¥å¿—
                if len(path_parts) > 10:
                    self.logger.warning(f"âš ï¸ è·¯å¾„å¼‚å¸¸é•¿ ({len(path_parts)} æ®µ)ï¼Œå¯èƒ½å­˜åœ¨è·¯å¾„é—®é¢˜: {file_name[:200]}")
            
            # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(file_name):
                skip_reason = f"æ–‡ä»¶ä¸å­˜åœ¨: {file_name}"
                self.logger.warning(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {file_name}")
                self.logger.warning(f"   é¡¹ç›®æ ¹ç›®å½•: {project_root}")
                self.logger.warning(f"   åŸå§‹è·¯å¾„: {issue_file_path}")
                skipped_issues.append({
                    "issue": issue,
                    "reason": skip_reason,
                    "file_path": file_name,
                    "original_path": issue_file_path
                })
                continue

        fix_results: List[Dict[str, Any]] = []
        errors: List[str] = []
        failed_issues_details: List[Dict[str, Any]] = []  # è¿½è¸ªä¿®å¤å¤±è´¥çš„é—®é¢˜è¯¦æƒ…
        
        # Process issues one by one instead of grouping by file
        total_issues_to_process = len(issues) - len(skipped_issues)
        processed_issues = 0

        self.logger.info(f"{'='*60}")
        self.logger.info(f"ğŸ”§ ä¿®å¤Agentå¼€å§‹å¤„ç†ä¿®å¤ä»»åŠ¡")
        self.logger.info(f"   ä»»åŠ¡ID: {task_id}")
        self.logger.info(f"   æ€»é—®é¢˜æ•°: {len(issues)}")
        self.logger.info(f"   éœ€è¦å¤„ç†çš„é—®é¢˜æ•°: {total_issues_to_process}")
        self.logger.info(f"   è·³è¿‡çš„é—®é¢˜æ•°: {len(skipped_issues)}")
        self.logger.info(f"   è¾“å‡ºç›®å½•: {output_dir}")
        self.logger.info(f"   ä½¿ç”¨ fix-code-agent é€ä¸ªä¿®å¤é—®é¢˜")
        self.logger.info(f"{'='*60}")
        
        # Process each issue individually
        for issue_index, issue in enumerate(issues, 1):
            # Skip if this issue was already skipped during path validation
            issue_file_path = issue.get("file_path") or issue.get("file")
            if not issue_file_path:
                continue  # Already handled in skipped_issues
            
            # Normalize path for comparison
            # Fix path: if path starts with temp_extract, resolve it to ../../api/temp_extract
            issue_file_path = self._resolve_temp_extract_path(issue_file_path)
            
            if os.path.isabs(issue_file_path):
                normalized_path = os.path.normpath(issue_file_path)
            else:
                issue_file_path_clean = issue_file_path.lstrip('./').lstrip('../')
                normalized_path = os.path.normpath(os.path.join(project_root, issue_file_path_clean))
            
            # Check if this issue was skipped by comparing normalized file_path and line
            is_skipped = any(
                skipped.get("file_path") == normalized_path and 
                skipped.get("issue", {}).get("line") == issue.get("line")
                for skipped in skipped_issues
            )
            if is_skipped:
                continue
            
            processed_issues += 1
            issue_message = issue.get("message", "")
            issue_line = issue.get("line", "N/A")
            issue_file = issue.get("file") or issue.get("file_path", "unknown")
            
            self.logger.info(f"\n{'='*60}")
            self.logger.info(f"ğŸ”§ [{issue_index}/{len(issues)}] æ­£åœ¨å¤„ç†é—®é¢˜")
            self.logger.info(f"   æ–‡ä»¶: {issue_file}")
            self.logger.info(f"   è¡Œå·: {issue_line}")
            self.logger.info(f"   é—®é¢˜: {issue_message[:100]}...")
            self.logger.info(f"   è¿›åº¦: {processed_issues}/{total_issues_to_process} ({processed_issues*100//max(total_issues_to_process, 1)}%)")
            self.logger.info(f"{'='*60}")
            
            try:
                # Normalize file path
                # Fix path: if path starts with temp_extract, resolve it to ../../api/temp_extract
                issue_file_path = self._resolve_temp_extract_path(issue_file_path)
                
                if os.path.isabs(issue_file_path):
                    abs_path = os.path.normpath(issue_file_path)
                else:
                    issue_file_path = issue_file_path.lstrip('./').lstrip('../')
                    abs_path = os.path.normpath(os.path.join(project_root, issue_file_path))
                
                # Handle path duplication (same logic as before)
                path_parts = abs_path.split(os.sep)
                if len(path_parts) > 2:
                    max_pattern_len = min(len(path_parts) // 2, 10)
                    for pattern_len in range(max_pattern_len, 0, -1):
                        if len(path_parts) < pattern_len * 2:
                            continue
                        pattern = path_parts[:pattern_len]
                        next_pattern = path_parts[pattern_len:pattern_len * 2]
                        if pattern == next_pattern:
                            abs_path = os.sep.join(path_parts[pattern_len:])
                            abs_path = os.path.normpath(abs_path)
                            break
                
                # Verify file exists
                if not os.path.exists(abs_path):
                    error_msg = f"æ–‡ä»¶ä¸å­˜åœ¨: {abs_path}"
                    self.logger.error(f"âŒ {error_msg}")
                    errors.append(error_msg)
                    failed_issues_details.append({
                        "issue": issue,
                        "file": abs_path,
                        "reason": error_msg,
                        "status": "file_not_found"
                    })
                    continue
                
                # Save before state
                with open(abs_path, "r", encoding="utf-8") as f:
                    before_code = f.read()
                
                # Prepare comprehensive task description for fix-code-agent
                # Include information from original_task and task_data
                task_parts = []
                
                # Main issue message
                if issue_message:
                    task_parts.append(f"Task: {issue_message}")
                else:
                    task_parts.append(f"Fix the issue at line {issue_line} in {os.path.basename(abs_path)}")
                
                # Add context from original_task if available
                original_task = issue.get("original_task", {})
                if original_task:
                    task_parts.append("\nContext Information:")
                    
                    problem_file = original_task.get("problem_file")
                    if problem_file:
                        task_parts.append(f"Problem File: {problem_file}")
                    
                    orig_project_root = original_task.get("project_root")
                    if orig_project_root:
                        task_parts.append(f"Project Root: {orig_project_root}")
                    
                    agent_test_path = original_task.get("agent_test_path")
                    if agent_test_path:
                        task_parts.append(f"Agent Test Path: {agent_test_path}")
                    
                    backup_agent_path = original_task.get("backup_agent_path")
                    if backup_agent_path:
                        task_parts.append(f"Backup Agent Path: {backup_agent_path}")
                    
                    defect_info = original_task.get("defect_info", {})
                    if defect_info:
                        task_parts.append(f"Defect Info: {defect_info}")
                
                # Add file path information
                task_parts.append(f"\nFile to fix: {abs_path}")
                task_parts.append(f"Line number: {issue_line}")
                
                # Add issue metadata
                if issue.get("severity"):
                    task_parts.append(f"Severity: {issue.get('severity')}")
                if issue.get("type"):
                    task_parts.append(f"Issue Type: {issue.get('type')}")
                if issue.get("tool"):
                    task_parts.append(f"Detection Tool: {issue.get('tool')}")
                
                # Add decisions from task_data if available
                decisions = task_data.get("decisions", {})
                if decisions:
                    task_parts.append(f"\nDecisions: {decisions}")
                
                task_description = "\n".join(task_parts)
                
                # Save task description to a file (use absolute path)
                task_file = os.path.abspath(os.path.join(output_dir, f"task_{issue_index}.txt"))
                with open(task_file, "w", encoding="utf-8") as tf:
                    tf.write(task_description)
                
                # Call fix-code-agent using PowerShell
                self.logger.info(f"ğŸ¤– è°ƒç”¨ fix-code-agent ä¿®å¤é—®é¢˜...")
                self.logger.info(f"   ä»»åŠ¡æè¿°: {task_description[:200]}...")
                self.logger.info(f"   ä»»åŠ¡æ–‡ä»¶: {task_file}")
                
                try:
                    # Use Python module instead of direct command to avoid PATH issues
                    # Prepare environment with UTF-8 encoding for Windows
                    env = os.environ.copy()
                    env["PYTHONIOENCODING"] = "utf-8"
                    env["FIXCODE_SILENT_STARTUP"] = "1"  # Suppress emoji output
                    
                    # Read task content from file
                    with open(task_file, "r", encoding="utf-8") as tf:
                        task_content = tf.read()
                    
                    # Get the path to fixcodeagent module
                    # The module is at agents/fix_execution_agent/src/fixcodeagent
                    agent_dir = os.path.dirname(os.path.abspath(__file__))
                    fixcodeagent_src = os.path.join(agent_dir, "src")
                    
                    # Add the src directory to PYTHONPATH so we can import fixcodeagent
                    pythonpath = env.get("PYTHONPATH", "")
                    if pythonpath:
                        env["PYTHONPATH"] = f"{fixcodeagent_src}{os.pathsep}{pythonpath}"
                    else:
                        env["PYTHONPATH"] = fixcodeagent_src
                    
                    self.logger.info(f"   æ‰§è¡Œå‘½ä»¤: python -m fixcodeagent --task \"[from file]\" --yolo --exit-immediately")
                    self.logger.debug(f"   å®Œæ•´ä»»åŠ¡æè¿°å·²ä¿å­˜åˆ°: {task_file}")
                    self.logger.debug(f"   Working directory: {project_root}")
                    self.logger.debug(f"   PYTHONPATH: {fixcodeagent_src}")
                    
                    # Run using Python module - pass task content directly
                    # cwd=project_root so fix-code-agent can find the files to fix
                    process = await asyncio.create_subprocess_exec(
                        sys.executable,
                        "-m", "fixcodeagent",
                        "--task", task_content,
                        "--yolo",
                        "--exit-immediately",
                        stdout=asyncio.subprocess.PIPE,
                        stderr=asyncio.subprocess.PIPE,
                        cwd=project_root,
                        env=env
                    )
                    
                    stdout, stderr = await process.communicate()
                    return_code = process.returncode
                    
                    if return_code == 0:
                        self.logger.info(f"âœ… fix-code-agent æ‰§è¡ŒæˆåŠŸ")
                        if stdout:
                            self.logger.debug(f"   è¾“å‡º: {stdout.decode('utf-8', errors='ignore')[:500]}")
                        
                        # Read after state
                        with open(abs_path, "r", encoding="utf-8") as f:
                            after_code = f.read()
                        
                        # Save before/after files
                        base, ext = os.path.splitext(os.path.basename(abs_path))
                        issue_id = f"{base}_issue_{issue_index}"
                        before_out = os.path.join(output_dir, f"{issue_id}_before{ext}")
                        after_out = os.path.join(output_dir, f"{issue_id}_after{ext}")
                        
                        with open(before_out, "w", encoding="utf-8") as bf:
                            bf.write(before_code)
                        with open(after_out, "w", encoding="utf-8") as af:
                            af.write(after_code)
                        
                        before_out_abs = os.path.abspath(before_out)
                        after_out_abs = os.path.abspath(after_out)
                        
                        self.logger.info(f"âœ… é—®é¢˜ä¿®å¤å®Œæˆ")
                        self.logger.info(f"   ğŸ“ ä¿®å¤å‰: {before_out_abs}")
                        self.logger.info(f"   ğŸ“ ä¿®å¤å: {after_out_abs}")
                        
                        fix_results.append({
                            "issue_index": issue_index,
                            "file": abs_path,
                            "before": before_out_abs,
                            "after": after_out_abs,
                            "task_file": os.path.abspath(task_file),
                            "issue": issue,
                            "task_description": task_description,
                            "output_dir": output_dir,
                            "fixed": True
                        })
                    else:
                        error_msg = f"fix-code-agent æ‰§è¡Œå¤±è´¥ (è¿”å›ç : {return_code})"
                        if stderr:
                            error_detail = stderr.decode('utf-8', errors='ignore')
                            error_msg += f": {error_detail[:200]}"
                        self.logger.error(f"âŒ {error_msg}")
                        errors.append(error_msg)
                        failed_issues_details.append({
                            "issue": issue,
                            "file": abs_path,
                            "reason": error_msg,
                            "status": "fix_code_agent_failed",
                            "return_code": return_code
                        })
                        
                except Exception as e:
                    error_msg = f"è°ƒç”¨ fix-code-agent æ—¶å‡ºé”™: {str(e)}"
                    self.logger.error(f"âŒ {error_msg}")
                    import traceback
                    error_trace = traceback.format_exc()
                    self.logger.error(f"   é”™è¯¯è¯¦æƒ…: {error_trace}")
                    errors.append(error_msg)
                    failed_issues_details.append({
                        "issue": issue,
                        "file": abs_path,
                        "reason": error_msg,
                        "error_detail": error_trace,
                        "status": "execution_failed"
                    })
                    
            except Exception as e:
                error_msg = f"å¤„ç†é—®é¢˜å¤±è´¥: {e}"
                self.logger.error(f"âŒ {error_msg}")
                errors.append(error_msg)
                failed_issues_details.append({
                    "issue": issue,
                    "file": issue_file,
                    "reason": error_msg,
                    "status": "processing_failed"
                })

        total_issues = len(issues)
        fixed_count = len([r for r in fix_results if r.get("fixed", False)])
        skipped_count = len(skipped_issues)
        failed_count = len(failed_issues_details)
        
        # ç”Ÿæˆä¿®å¤ç»“æœæ‘˜è¦
        self.logger.info(f"\n{'='*60}")
        self.logger.info(f"ğŸ‰ ä¿®å¤ä»»åŠ¡å®Œæˆï¼")
        self.logger.info(f"   ä»»åŠ¡ID: {task_id}")
        self.logger.info(f"   æ€»é—®é¢˜æ•°: {total_issues}")
        self.logger.info(f"   æˆåŠŸä¿®å¤é—®é¢˜æ•°: {fixed_count}")
        self.logger.info(f"   è·³è¿‡é—®é¢˜æ•°: {skipped_count}")
        self.logger.info(f"   å¤±è´¥é—®é¢˜æ•°: {failed_count}")
        self.logger.info(f"   è¾“å‡ºç›®å½•: {output_dir}")
        
        if fix_results:
            self.logger.info(f"\nğŸ“ ä¿®å¤ç»“æœæ–‡ä»¶ä½ç½®:")
            for idx, result in enumerate(fix_results, 1):
                file_name = os.path.basename(result.get('file', 'unknown'))
                self.logger.info(f"   {idx}. {file_name}")
                self.logger.info(f"      ä¿®å¤å‰: {result.get('before', 'N/A')}")
                self.logger.info(f"      ä¿®å¤å: {result.get('after', 'N/A')}")
        
        if skipped_issues:
            self.logger.warning(f"\nâš ï¸ è¢«è·³è¿‡çš„é—®é¢˜ ({skipped_count} ä¸ª):")
            for idx, skipped in enumerate(skipped_issues[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
                issue = skipped.get("issue", {})
                reason = skipped.get("reason", "æœªçŸ¥åŸå› ")
                file_path = skipped.get("file_path", "N/A")
                line = issue.get("line", "N/A")
                msg = issue.get("message", "")[:50]
                self.logger.warning(f"   {idx}. [{file_path}:{line}] {msg}")
                self.logger.warning(f"      åŸå› : {reason}")
            if len(skipped_issues) > 10:
                self.logger.warning(f"   ... è¿˜æœ‰ {len(skipped_issues) - 10} ä¸ªè¢«è·³è¿‡çš„é—®é¢˜")
        
        if failed_issues_details:
            self.logger.warning(f"\nâŒ ä¿®å¤å¤±è´¥çš„é—®é¢˜ ({failed_count} ä¸ª):")
            # æŒ‰å¤±è´¥åŸå› åˆ†ç»„ç»Ÿè®¡
            failure_reasons = {}
            for failed in failed_issues_details:
                reason = failed.get("reason", "æœªçŸ¥åŸå› ")
                if reason not in failure_reasons:
                    failure_reasons[reason] = []
                failure_reasons[reason].append(failed)
            
            for reason, failed_list in failure_reasons.items():
                self.logger.warning(f"   {reason}: {len(failed_list)} ä¸ªé—®é¢˜")
                # æ˜¾ç¤ºå‰5ä¸ªå¤±è´¥é—®é¢˜çš„è¯¦æƒ…
                for idx, failed in enumerate(failed_list[:5], 1):
                    issue = failed.get("issue", {})
                    file_path = failed.get("file", "N/A")
                    line = issue.get("line", "N/A")
                    msg = issue.get("message", "")[:50]
                    self.logger.warning(f"      {idx}. [{file_path}:{line}] {msg}")
                if len(failed_list) > 5:
                    self.logger.warning(f"      ... è¿˜æœ‰ {len(failed_list) - 5} ä¸ªç±»ä¼¼é—®é¢˜")
        
        if errors:
            self.logger.warning(f"\nâš ï¸ ä¿®å¤è¿‡ç¨‹ä¸­çš„é”™è¯¯:")
            for idx, error in enumerate(errors, 1):
                self.logger.warning(f"   {idx}. {error}")
        
        self.logger.info(f"{'='*60}\n")
        
        return {
            "success": len(errors) == 0 and failed_count == 0,
            "task_id": task_id,
            "fix_results": fix_results,
            "total_issues": total_issues,
            "fixed_issues": fixed_count,
            "failed_issues": failed_count,
            "skipped_issues": skipped_count,
            "errors": errors,
            "skipped_issues_details": skipped_issues,  # æ·»åŠ è¢«è·³è¿‡çš„é—®é¢˜è¯¦æƒ…
            "failed_issues_details": failed_issues_details,  # æ·»åŠ å¤±è´¥é—®é¢˜çš„è¯¦æƒ…
            "output_dir": output_dir,
            "timestamp": asyncio.get_event_loop().time(),
            "message": f"ä¿®å¤å®Œæˆ: {fixed_count}/{total_issues} ä¸ªé—®é¢˜ (è·³è¿‡: {skipped_count}, å¤±è´¥: {failed_count})" if not errors else f"ä¿®å¤å®Œæˆä½†æœ‰é”™è¯¯: {fixed_count}/{total_issues} ä¸ªé—®é¢˜ (è·³è¿‡: {skipped_count}, å¤±è´¥: {failed_count})",
        }
