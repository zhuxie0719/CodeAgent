"""
AIå¤šè¯­è¨€é™æ€ç¼ºé™·æ£€æµ‹å™¨
æ”¯æŒJavaã€C++ã€JavaScriptã€Goã€Rustç­‰è¯­è¨€çš„AIåˆ†æ
"""

import os
import re
import asyncio
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import httpx
from api.deepseek_config import deepseek_config

class LanguageType(Enum):
    """æ”¯æŒçš„è¯­è¨€ç±»å‹"""
    PYTHON = "python"
    JAVA = "java"
    CPP = "cpp"
    C = "c"
    JAVASCRIPT = "javascript"
    TYPESCRIPT = "typescript"
    GO = "go"
    RUST = "rust"
    CSHARP = "csharp"
    PHP = "php"
    RUBY = "ruby"
    SWIFT = "swift"
    KOTLIN = "kotlin"

@dataclass
class CodeIssue:
    """ä»£ç é—®é¢˜æ•°æ®ç»“æ„"""
    file_path: str
    line_number: int
    column: int
    severity: str  # error, warning, info
    category: str   # security, performance, style, logic, best_practice
    message: str
    suggestion: str
    language: str
    confidence: float

@dataclass
class AnalysisResult:
    """åˆ†æç»“æœæ•°æ®ç»“æ„"""
    language: str
    files_analyzed: int
    issues_found: int
    issues: List[CodeIssue]
    metrics: Dict[str, Any]
    summary: str

class AIMultiLanguageAnalyzer:
    """AIå¤šè¯­è¨€é™æ€åˆ†æå™¨"""
    
    def __init__(self):
        self.config = deepseek_config
        self.supported_extensions = {
            '.java': LanguageType.JAVA,
            '.cpp': LanguageType.CPP,
            '.cc': LanguageType.CPP,
            '.cxx': LanguageType.CPP,
            '.c': LanguageType.C,
            '.h': LanguageType.C,
            '.hpp': LanguageType.CPP,
            '.js': LanguageType.JAVASCRIPT,
            '.ts': LanguageType.TYPESCRIPT,
            '.go': LanguageType.GO,
            '.rs': LanguageType.RUST,
            '.cs': LanguageType.CSHARP,
            '.php': LanguageType.PHP,
            '.rb': LanguageType.RUBY,
            '.swift': LanguageType.SWIFT,
            '.kt': LanguageType.KOTLIN,
            '.kts': LanguageType.KOTLIN
        }
        
        # è¯­è¨€ç‰¹å®šçš„æ£€æµ‹è§„åˆ™
        self.language_rules = {
            LanguageType.JAVA: self._get_java_rules(),
            LanguageType.CPP: self._get_cpp_rules(),
            LanguageType.C: self._get_c_rules(),
            LanguageType.JAVASCRIPT: self._get_javascript_rules(),
            LanguageType.GO: self._get_go_rules(),
            LanguageType.RUST: self._get_rust_rules()
        }
    
    def _get_java_rules(self) -> Dict[str, Any]:
        """Javaç‰¹å®šæ£€æµ‹è§„åˆ™"""
        return {
            "security_patterns": [
                r"System\.out\.print",  # è°ƒè¯•è¾“å‡º
                r"printStackTrace",      # å¼‚å¸¸å †æ ˆæ‰“å°
                r"Runtime\.getRuntime\(\)\.exec",  # å‘½ä»¤æ‰§è¡Œ
                r"ProcessBuilder",       # è¿›ç¨‹æ„å»º
                r"Class\.forName",        # åŠ¨æ€ç±»åŠ è½½
                r"URLClassLoader",        # URLç±»åŠ è½½å™¨
                r"Serializable",         # åºåˆ—åŒ–é£é™©
                r"ObjectInputStream",    # ååºåˆ—åŒ–
                r"SQLException",         # SQLæ³¨å…¥é£é™©
                r"PreparedStatement",    # SQLé¢„å¤„ç†
            ],
            "performance_patterns": [
                r"String\s*\+\s*String",  # å­—ç¬¦ä¸²æ‹¼æ¥
                r"new\s+String\s*\(",     # ä¸å¿…è¦çš„å­—ç¬¦ä¸²åˆ›å»º
                r"System\.gc\(\)",        # æ‰‹åŠ¨åƒåœ¾å›æ”¶
                r"Thread\.sleep",         # çº¿ç¨‹ç¡çœ 
                r"while\s*\(\s*true\s*\)", # æ— é™å¾ªç¯
            ],
            "style_patterns": [
                r"public\s+class\s+\w*[a-z]",  # ç±»åä¸ç¬¦åˆè§„èŒƒ
                r"public\s+void\s+\w*[A-Z]",    # æ–¹æ³•åä¸ç¬¦åˆè§„èŒƒ
                r"import\s+\*",                  # é€šé…ç¬¦å¯¼å…¥
                r"@SuppressWarnings",            # æŠ‘åˆ¶è­¦å‘Š
            ],
            "best_practices": [
                r"catch\s*\(\s*Exception\s*\)",  # æ•è·é€šç”¨å¼‚å¸¸
                r"null\s*==\s*",                 # ç©ºå€¼æ£€æŸ¥é¡ºåº
                r"equals\s*\(\s*\"",             # å­—ç¬¦ä¸²æ¯”è¾ƒ
            ]
        }
    
    def _get_cpp_rules(self) -> Dict[str, Any]:
        """C++ç‰¹å®šæ£€æµ‹è§„åˆ™"""
        return {
            "security_patterns": [
                r"strcpy\s*\(",          # ä¸å®‰å…¨çš„å­—ç¬¦ä¸²å¤åˆ¶
                r"strcat\s*\(",          # ä¸å®‰å…¨çš„å­—ç¬¦ä¸²è¿æ¥
                r"sprintf\s*\(",        # ä¸å®‰å…¨çš„æ ¼å¼åŒ–
                r"gets\s*\(",            # ä¸å®‰å…¨çš„è¾“å…¥
                r"scanf\s*\(",           # æ ¼å¼åŒ–å­—ç¬¦ä¸²é£é™©
                r"system\s*\(",          # ç³»ç»Ÿå‘½ä»¤æ‰§è¡Œ
                r"malloc\s*\(",          # å†…å­˜åˆ†é…
                r"free\s*\(",            # å†…å­˜é‡Šæ”¾
                r"delete\s+",            # å†…å­˜åˆ é™¤
                r"new\s+",               # åŠ¨æ€åˆ†é…
            ],
            "performance_patterns": [
                r"std::endl",            # é¢‘ç¹æ¢è¡Œ
                r"std::cout",             # æ§åˆ¶å°è¾“å‡º
                r"#include\s*<iostream>", # ä¸å¿…è¦çš„å¤´æ–‡ä»¶
                r"using\s+namespace\s+std", # ä½¿ç”¨å‘½åç©ºé—´
            ],
            "style_patterns": [
                r"goto\s+",             # gotoè¯­å¥
                r"#define\s+",           # å®å®šä¹‰
                r"#ifdef\s+",            # æ¡ä»¶ç¼–è¯‘
                r"int\s+main\s*\(",      # mainå‡½æ•°
            ],
            "best_practices": [
                r"std::auto_ptr",        # å·²åºŸå¼ƒçš„æ™ºèƒ½æŒ‡é’ˆ
                r"std::shared_ptr",      # æ™ºèƒ½æŒ‡é’ˆä½¿ç”¨
                r"const\s+",             # constä½¿ç”¨
                r"explicit\s+",           # æ˜¾å¼æ„é€ å‡½æ•°
            ]
        }
    
    def _get_c_rules(self) -> Dict[str, Any]:
        """Cç‰¹å®šæ£€æµ‹è§„åˆ™"""
        return {
            "security_patterns": [
                r"strcpy\s*\(",          # ä¸å®‰å…¨çš„å­—ç¬¦ä¸²å¤åˆ¶
                r"strcat\s*\(",          # ä¸å®‰å…¨çš„å­—ç¬¦ä¸²è¿æ¥
                r"sprintf\s*\(",        # ä¸å®‰å…¨çš„æ ¼å¼åŒ–
                r"gets\s*\(",            # ä¸å®‰å…¨çš„è¾“å…¥
                r"scanf\s*\(",           # æ ¼å¼åŒ–å­—ç¬¦ä¸²é£é™©
                r"system\s*\(",          # ç³»ç»Ÿå‘½ä»¤æ‰§è¡Œ
                r"malloc\s*\(",          # å†…å­˜åˆ†é…
                r"free\s*\(",            # å†…å­˜é‡Šæ”¾
            ],
            "performance_patterns": [
                r"printf\s*\(",          # æ ¼å¼åŒ–è¾“å‡º
                r"#include\s*<stdio\.h>", # æ ‡å‡†è¾“å…¥è¾“å‡º
                r"#include\s*<stdlib\.h>", # æ ‡å‡†åº“
            ],
            "style_patterns": [
                r"goto\s+",             # gotoè¯­å¥
                r"#define\s+",           # å®å®šä¹‰
                r"#ifdef\s+",            # æ¡ä»¶ç¼–è¯‘
                r"int\s+main\s*\(",      # mainå‡½æ•°
            ],
            "best_practices": [
                r"void\s*\*",           # ç©ºæŒ‡é’ˆä½¿ç”¨
                r"NULL\s*==\s*",         # ç©ºå€¼æ£€æŸ¥
                r"sizeof\s*\(",          # sizeofä½¿ç”¨
            ]
        }
    
    def _get_javascript_rules(self) -> Dict[str, Any]:
        """JavaScriptç‰¹å®šæ£€æµ‹è§„åˆ™"""
        return {
            "security_patterns": [
                r"eval\s*\(",            # evalå‡½æ•°
                r"innerHTML\s*=",        # innerHTMLèµ‹å€¼
                r"document\.write",       # document.write
                r"setTimeout\s*\(",      # setTimeout
                r"setInterval\s*\(",     # setInterval
                r"Function\s*\(",         # Functionæ„é€ å‡½æ•°
                r"window\.open",         # çª—å£æ‰“å¼€
                r"location\.href",       # ä½ç½®è·³è½¬
            ],
            "performance_patterns": [
                r"for\s*\(\s*var\s+",    # varå£°æ˜
                r"==\s*",                 # å®½æ¾ç›¸ç­‰
                r"!=\s*",                 # å®½æ¾ä¸ç­‰
                r"typeof\s+",             # typeofä½¿ç”¨
            ],
            "style_patterns": [
                r"var\s+",               # varå£°æ˜
                r"function\s+\w*\s*\(",   # å‡½æ•°å£°æ˜
                r"console\.log",          # æ§åˆ¶å°è¾“å‡º
                r"alert\s*\(",            # è­¦å‘Šæ¡†
            ],
            "best_practices": [
                r"===\s*",               # ä¸¥æ ¼ç›¸ç­‰
                r"!==\s*",                # ä¸¥æ ¼ä¸ç­‰
                r"let\s+",                # letå£°æ˜
                r"const\s+",              # constå£°æ˜
            ]
        }
    
    def _get_go_rules(self) -> Dict[str, Any]:
        """Goç‰¹å®šæ£€æµ‹è§„åˆ™"""
        return {
            "security_patterns": [
                r"os\.Getenv",           # ç¯å¢ƒå˜é‡è·å–
                r"exec\.Command",        # å‘½ä»¤æ‰§è¡Œ
                r"http\.Get",             # HTTPè¯·æ±‚
                r"net\.Dial",             # ç½‘ç»œè¿æ¥
                r"ioutil\.ReadFile",      # æ–‡ä»¶è¯»å–
                r"os\.Open",              # æ–‡ä»¶æ‰“å¼€
            ],
            "performance_patterns": [
                r"make\s*\(\s*map",      # mapåˆ›å»º
                r"make\s*\(\s*slice",    # sliceåˆ›å»º
                r"append\s*\(",          # sliceè¿½åŠ 
                r"range\s+",              # rangeä½¿ç”¨
            ],
            "style_patterns": [
                r"func\s+\w*\s*\(",      # å‡½æ•°å£°æ˜
                r"type\s+\w*\s+struct",  # ç»“æ„ä½“å®šä¹‰
                r"interface\s*{",          # æ¥å£å®šä¹‰
                r"package\s+\w+",         # åŒ…å£°æ˜
            ],
            "best_practices": [
                r"defer\s+",             # deferä½¿ç”¨
                r"go\s+",                # goroutine
                r"chan\s+",              # é€šé“
                r"sync\.",               # åŒæ­¥åŒ…
            ]
        }
    
    def _get_rust_rules(self) -> Dict[str, Any]:
        """Rustç‰¹å®šæ£€æµ‹è§„åˆ™"""
        return {
            "security_patterns": [
                r"unsafe\s*{",           # unsafeå—
                r"std::ptr::",            # åŸå§‹æŒ‡é’ˆ
                r"std::mem::",            # å†…å­˜æ“ä½œ
                r"std::process::",        # è¿›ç¨‹æ“ä½œ
                r"std::fs::",             # æ–‡ä»¶ç³»ç»Ÿ
            ],
            "performance_patterns": [
                r"clone\s*\(",            # cloneè°ƒç”¨
                r"to_string\s*\(",        # å­—ç¬¦ä¸²è½¬æ¢
                r"collect\s*\(",          # é›†åˆæ”¶é›†
                r"unwrap\s*\(",           # unwrapè°ƒç”¨
            ],
            "style_patterns": [
                r"fn\s+\w*\s*\(",        # å‡½æ•°å£°æ˜
                r"struct\s+\w*",          # ç»“æ„ä½“å®šä¹‰
                r"enum\s+\w*",            # æšä¸¾å®šä¹‰
                r"impl\s+\w*",            # å®ç°å—
            ],
            "best_practices": [
                r"match\s+",              # matchè¡¨è¾¾å¼
                r"if\s+let\s+",           # if let
                r"while\s+let\s+",         # while let
                r"Option::",               # Optionä½¿ç”¨
                r"Result::",               # Resultä½¿ç”¨
            ]
        }
    
    def detect_language(self, file_path: str) -> Optional[LanguageType]:
        """æ£€æµ‹æ–‡ä»¶è¯­è¨€ç±»å‹"""
        ext = os.path.splitext(file_path)[1].lower()
        return self.supported_extensions.get(ext)
    
    def is_supported_file(self, file_path: str) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ”¯æŒ"""
        return self.detect_language(file_path) is not None
    
    async def analyze_file(self, file_path: str, project_path: str) -> Optional[AnalysisResult]:
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        try:
            language = self.detect_language(file_path)
            if not language:
                return None
            
            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            if not content.strip():
                return None
            
            # æ‰§è¡ŒAIåˆ†æ
            ai_result = await self._analyze_with_ai(content, file_path, language)
            
            # æ‰§è¡Œè§„åˆ™åŒ¹é…
            rule_issues = self._analyze_with_rules(content, file_path, language)
            
            # åˆå¹¶ç»“æœ
            all_issues = ai_result.get('issues', []) + rule_issues
            
            # è®¡ç®—æŒ‡æ ‡
            metrics = self._calculate_metrics(content, all_issues, language)
            
            # ç”Ÿæˆæ‘˜è¦
            summary = await self._generate_summary(content, all_issues, language)
            
            return AnalysisResult(
                language=language.value,
                files_analyzed=1,
                issues_found=len(all_issues),
                issues=all_issues,
                metrics=metrics,
                summary=summary
            )
            
        except Exception as e:
            print(f"åˆ†ææ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return None
    
    async def _analyze_with_ai(self, content: str, file_path: str, language: LanguageType) -> Dict[str, Any]:
        """ä½¿ç”¨AIåˆ†æä»£ç """
        try:
            if not self.config.is_configured():
                return {'issues': []}
            
            # æ„å»ºåˆ†ææç¤ºè¯
            prompt = self._build_analysis_prompt(content, file_path, language)
            
            # é™åˆ¶æ–‡ä»¶å¤§å°ï¼Œé¿å…è¿‡é•¿çš„APIè¯·æ±‚
            if len(content) > 50 * 1024:  # 50KB
                return {'issues': []}
            
            # è°ƒç”¨AI API
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    f"{self.config.base_url}/chat/completions",
                    headers=self.config.get_headers(),
                    json={
                        "model": self.config.model,
                        "messages": [
                            {"role": "user", "content": prompt}
                        ],
                        "max_tokens": 1000,
                        "temperature": 0.2
                    }
                )
                
                if response.status_code == 200:
                    result = response.json()
                    ai_content = result["choices"][0]["message"]["content"]
                    
                    # è°ƒè¯•ä¿¡æ¯
                    print(f"ğŸ¤– AIå“åº”é•¿åº¦: {len(ai_content)} å­—ç¬¦")
                    print(f"ğŸ¤– AIå“åº”é¢„è§ˆ: {ai_content[:100]}...")
                    
                    # è§£æAIå“åº”
                    return self._parse_ai_response(ai_content, file_path, language)
                else:
                    print(f"AI APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                    return {'issues': []}
                    
        except Exception as e:
            print(f"AIåˆ†æå¤±è´¥: {e}")
            return {'issues': []}
    
    def _build_analysis_prompt(self, content: str, file_path: str, language: LanguageType) -> str:
        """æ„å»ºAIåˆ†ææç¤ºè¯"""
        # é™åˆ¶å†…å®¹é•¿åº¦ï¼Œæé«˜æ•ˆç‡
        content_preview = content[:1000] + "..." if len(content) > 1000 else content
        
        prompt = f"""å¿«é€Ÿåˆ†æ{language.value.upper()}ä»£ç ï¼Œåªæ£€æµ‹ä¸¥é‡é”™è¯¯ï¼š

**æ–‡ä»¶**: {file_path}
**ä»£ç **:
```{language.value}
{content_preview}
```

**ä»»åŠ¡**: æ£€æµ‹ä»£ç é—®é¢˜ï¼Œæ ¹æ®ä¸¥é‡ç¨‹åº¦åˆ¤æ–­çº§åˆ«ï¼š
1. **errorçº§åˆ«**: ä¸¥é‡å®‰å…¨æ¼æ´ã€ä¼šå¯¼è‡´å´©æºƒçš„é”™è¯¯ã€ä¸¥é‡æ€§èƒ½é—®é¢˜
2. **warningçº§åˆ«**: æ½œåœ¨é—®é¢˜ã€æ€§èƒ½è­¦å‘Šã€ä»£ç è´¨é‡é—®é¢˜
3. **infoçº§åˆ«**: ä»£ç é£æ ¼é—®é¢˜ã€å»ºè®®æ”¹è¿›

é‡ç‚¹å…³æ³¨ï¼š
- **å®‰å…¨æ¼æ´**: ç¼“å†²åŒºæº¢å‡ºã€SQLæ³¨å…¥ã€XSSæ”»å‡»ã€å†…å­˜æ³„æ¼
- **ä¸¥é‡æ€§èƒ½é—®é¢˜**: æ­»å¾ªç¯ã€å†…å­˜æº¢å‡ºã€èµ„æºæ³„éœ²
- **ä¸¥é‡é€»è¾‘é”™è¯¯**: ç©ºæŒ‡é’ˆå¼‚å¸¸ã€æ•°ç»„è¶Šç•Œã€é™¤é›¶é”™è¯¯
- **ä¸¥é‡è¯­æ³•é”™è¯¯**: ç¼–è¯‘é”™è¯¯ã€è¿è¡Œæ—¶å´©æºƒ

**è¾“å‡ºæ ¼å¼** (ä¸¥æ ¼JSONæ•°ç»„):
```json
[
    {{
        "line_number": è¡Œå·,
        "severity": "error|warning|info",
        "category": "security|performance|logic|syntax",
        "message": "é—®é¢˜æè¿°",
        "suggestion": "ä¿®å¤å»ºè®®",
        "confidence": 0.9
    }}
]
```

**ä¸¥æ ¼è¦æ±‚**:
1. æ ¹æ®é—®é¢˜ä¸¥é‡ç¨‹åº¦å‡†ç¡®åˆ¤æ–­severityçº§åˆ«
2. å¿…é¡»æä¾›å‡†ç¡®çš„è¡Œå·
3. åªè¾“å‡ºJSONæ•°ç»„ï¼Œä¸è¦åŒ…å«å…¶ä»–ä»»ä½•å†…å®¹
4. å¦‚æœæ²¡æœ‰é—®é¢˜ï¼Œè¿”å›ç©ºæ•°ç»„: []
5. ä¸è¦æ·»åŠ è§£é‡Šæ–‡å­—ã€markdownæ ¼å¼æˆ–å…¶ä»–å†…å®¹
6. ç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼Œå¯ä»¥æ­£å¸¸è§£æ"""
        
        return prompt
    
    def _parse_ai_response(self, ai_content: str, file_path: str, language: LanguageType) -> Dict[str, Any]:
        """è§£æAIå“åº”"""
        try:
            import json
            
            # å°è¯•å¤šç§JSONæå–æ–¹å¼
            json_patterns = [
                r'```json\s*(\{.*?\})\s*```',  # å¯¹è±¡æ ¼å¼
                r'```json\s*(\[.*?\])\s*```',  # æ•°ç»„æ ¼å¼
                r'(\{.*?\})',  # ç›´æ¥å¯¹è±¡
                r'(\[.*?\])',  # ç›´æ¥æ•°ç»„
            ]
            
            json_content = None
            for pattern in json_patterns:
                match = re.search(pattern, ai_content, re.DOTALL)
                if match:
                    json_content = match.group(1)
                    break
            
            if json_content:
                try:
                    result = json.loads(json_content)
                    
                    # å¤„ç†ä¸åŒçš„å“åº”æ ¼å¼
                    if isinstance(result, dict):
                        # å¯¹è±¡æ ¼å¼: {"issues": [...], "summary": "..."}
                        issues_data = result.get('issues', [])
                        summary = result.get('summary', '')
                    elif isinstance(result, list):
                        # æ•°ç»„æ ¼å¼: [{"line_number": 1, "message": "..."}, ...]
                        issues_data = result
                        summary = f"å‘ç° {len(result)} ä¸ªé—®é¢˜"
                    else:
                        print(f"âš ï¸ æœªçŸ¥çš„AIå“åº”æ ¼å¼: {type(result)}")
                        return {'issues': []}
                    
                    # è½¬æ¢é—®é¢˜æ ¼å¼ï¼Œå¤„ç†æ‰€æœ‰çº§åˆ«
                    issues = []
                    for issue in issues_data:
                        if isinstance(issue, dict):
                            severity = issue.get('severity', 'info')
                            # å¤„ç†æ‰€æœ‰çº§åˆ«çš„é—®é¢˜
                            issues.append(CodeIssue(
                                file_path=file_path,
                                line_number=issue.get('line_number', 0),
                                column=issue.get('column', 0),
                                severity=severity,  # ä½¿ç”¨åŸå§‹severity
                                category=issue.get('category', 'logic'),
                                message=issue.get('message', ''),
                                suggestion=issue.get('suggestion', ''),
                                language=language.value,
                                confidence=issue.get('confidence', 0.9)
                            ))
                    
                    return {
                        'issues': issues,
                        'summary': summary
                    }
                    
                except json.JSONDecodeError as e:
                    print(f"âš ï¸ JSONè§£æå¤±è´¥: {e}")
                    print(f"åŸå§‹å†…å®¹: {json_content[:200]}...")
                    return {'issues': []}
            else:
                # å¦‚æœæ²¡æœ‰JSONæ ¼å¼ï¼Œå°è¯•ç›´æ¥è§£ææ•´ä¸ªå“åº”
                try:
                    result = json.loads(ai_content.strip())
                    if isinstance(result, list):
                        issues_data = result
                        summary = f"å‘ç° {len(result)} ä¸ªé—®é¢˜"
                    elif isinstance(result, dict):
                        issues_data = result.get('issues', [])
                        summary = result.get('summary', '')
                    else:
                        return self._parse_text_response(ai_content, file_path, language)
                    
                    # è½¬æ¢é—®é¢˜æ ¼å¼ï¼Œå¤„ç†æ‰€æœ‰çº§åˆ«
                    issues = []
                    for issue in issues_data:
                        if isinstance(issue, dict):
                            severity = issue.get('severity', 'info')
                            # å¤„ç†æ‰€æœ‰çº§åˆ«çš„é—®é¢˜
                            issues.append(CodeIssue(
                                file_path=file_path,
                                line_number=issue.get('line_number', 0),
                                column=issue.get('column', 0),
                                severity=severity,  # ä½¿ç”¨åŸå§‹severity
                                category=issue.get('category', 'logic'),
                                message=issue.get('message', ''),
                                suggestion=issue.get('suggestion', ''),
                                language=language.value,
                                confidence=issue.get('confidence', 0.9)
                            ))
                    
                    return {
                        'issues': issues,
                        'summary': summary
                    }
                except json.JSONDecodeError:
                    # å¦‚æœç›´æ¥è§£æä¹Ÿå¤±è´¥ï¼Œå°è¯•è§£ææ–‡æœ¬
                    return self._parse_text_response(ai_content, file_path, language)
                
        except Exception as e:
            print(f"è§£æAIå“åº”å¤±è´¥: {e}")
            print(f"AIå“åº”å†…å®¹: {ai_content[:300]}...")
            return {'issues': []}
    
    def _parse_text_response(self, content: str, file_path: str, language: LanguageType) -> Dict[str, Any]:
        """è§£ææ–‡æœ¬æ ¼å¼çš„AIå“åº”"""
        issues = []
        lines = content.split('\n')
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # å°è¯•åŒ¹é…é—®é¢˜æè¿°
            if any(keyword in line.lower() for keyword in ['error', 'warning', 'issue', 'problem', 'bug']):
                issues.append(CodeIssue(
                    file_path=file_path,
                    line_number=0,
                    column=0,
                    severity='info',
                    category='style',
                    message=line,
                    suggestion='è¯·å‚è€ƒä»£ç å®¡æŸ¥å»ºè®®',
                    language=language.value,
                    confidence=0.6
                ))
        
        return {
            'issues': issues,
            'summary': content[:200] + "..." if len(content) > 200 else content
        }
    
    def _analyze_with_rules(self, content: str, file_path: str, language: LanguageType) -> List[CodeIssue]:
        """ä½¿ç”¨è§„åˆ™åˆ†æä»£ç """
        issues = []
        rules = self.language_rules.get(language, {})
        
        if not rules:
            return issues
        
        lines = content.split('\n')
        
        for line_num, line in enumerate(lines, 1):
            for category, patterns in rules.items():
                for pattern in patterns:
                    if re.search(pattern, line, re.IGNORECASE):
                        severity = self._get_severity_by_category(category)
                        message = self._get_message_by_pattern(pattern, category)
                        suggestion = self._get_suggestion_by_pattern(pattern, category)
                        
                        issues.append(CodeIssue(
                            file_path=file_path,
                            line_number=line_num,
                            column=0,
                            severity=severity,
                            category=category,
                            message=message,
                            suggestion=suggestion,
                            language=language.value,
                            confidence=0.9
                        ))
        
        return issues
    
    def _get_severity_by_category(self, category: str) -> str:
        """æ ¹æ®ç±»åˆ«è·å–ä¸¥é‡ç¨‹åº¦"""
        severity_map = {
            'security_patterns': 'error',
            'performance_patterns': 'warning',
            'style_patterns': 'info',
            'best_practices': 'warning'
        }
        return severity_map.get(category, 'info')
    
    def _get_message_by_pattern(self, pattern: str, category: str) -> str:
        """æ ¹æ®æ¨¡å¼è·å–æ¶ˆæ¯"""
        messages = {
            'security_patterns': f'å‘ç°æ½œåœ¨å®‰å…¨é—®é¢˜: {pattern}',
            'performance_patterns': f'å‘ç°æ€§èƒ½é—®é¢˜: {pattern}',
            'style_patterns': f'å‘ç°ä»£ç é£æ ¼é—®é¢˜: {pattern}',
            'best_practices': f'å‘ç°æœ€ä½³å®è·µé—®é¢˜: {pattern}'
        }
        return messages.get(category, f'å‘ç°ä»£ç é—®é¢˜: {pattern}')
    
    def _get_suggestion_by_pattern(self, pattern: str, category: str) -> str:
        """æ ¹æ®æ¨¡å¼è·å–å»ºè®®"""
        suggestions = {
            'security_patterns': 'å»ºè®®ä½¿ç”¨æ›´å®‰å…¨çš„æ›¿ä»£æ–¹æ¡ˆ',
            'performance_patterns': 'å»ºè®®ä¼˜åŒ–æ€§èƒ½å®ç°',
            'style_patterns': 'å»ºè®®éµå¾ªä»£ç é£æ ¼è§„èŒƒ',
            'best_practices': 'å»ºè®®é‡‡ç”¨æœ€ä½³å®è·µ'
        }
        return suggestions.get(category, 'å»ºè®®æ”¹è¿›ä»£ç å®ç°')
    
    def _calculate_metrics(self, content: str, issues: List[CodeIssue], language: LanguageType) -> Dict[str, Any]:
        """è®¡ç®—ä»£ç æŒ‡æ ‡"""
        lines = content.split('\n')
        total_lines = len(lines)
        code_lines = len([line for line in lines if line.strip() and not line.strip().startswith('#')])
        
        # ç»Ÿè®¡é—®é¢˜
        issues_by_severity = {}
        issues_by_category = {}
        
        for issue in issues:
            severity = issue.severity
            category = issue.category
            
            issues_by_severity[severity] = issues_by_severity.get(severity, 0) + 1
            issues_by_category[category] = issues_by_category.get(category, 0) + 1
        
        # è®¡ç®—å¤æ‚åº¦ï¼ˆç®€å•ä¼°ç®—ï¼‰
        complexity = self._calculate_complexity(content, language)
        
        # è®¡ç®—å¯ç»´æŠ¤æ€§è¯„åˆ†
        maintainability_score = self._calculate_maintainability_score(issues, total_lines)
        
        return {
            'total_lines': total_lines,
            'code_lines': code_lines,
            'complexity': complexity,
            'maintainability_score': maintainability_score,
            'issues_by_severity': issues_by_severity,
            'issues_by_category': issues_by_category,
            'language': language.value
        }
    
    def _calculate_complexity(self, content: str, language: LanguageType) -> int:
        """è®¡ç®—ä»£ç å¤æ‚åº¦"""
        complexity_keywords = {
            LanguageType.JAVA: ['if', 'else', 'while', 'for', 'switch', 'case', 'catch', 'try'],
            LanguageType.CPP: ['if', 'else', 'while', 'for', 'switch', 'case', 'catch', 'try'],
            LanguageType.C: ['if', 'else', 'while', 'for', 'switch', 'case'],
            LanguageType.JAVASCRIPT: ['if', 'else', 'while', 'for', 'switch', 'case', 'catch', 'try'],
            LanguageType.GO: ['if', 'else', 'for', 'switch', 'case', 'select'],
            LanguageType.RUST: ['if', 'else', 'while', 'for', 'match', 'loop']
        }
        
        keywords = complexity_keywords.get(language, ['if', 'else', 'while', 'for'])
        complexity = 1  # åŸºç¡€å¤æ‚åº¦
        
        for keyword in keywords:
            complexity += len(re.findall(rf'\b{keyword}\b', content, re.IGNORECASE))
        
        return complexity
    
    def _calculate_maintainability_score(self, issues: List[CodeIssue], total_lines: int) -> float:
        """è®¡ç®—å¯ç»´æŠ¤æ€§è¯„åˆ†"""
        base_score = 100.0
        
        # æ ¹æ®é—®é¢˜æ•°é‡æ‰£åˆ†
        for issue in issues:
            if issue.severity == 'error':
                base_score -= 5.0
            elif issue.severity == 'warning':
                base_score -= 2.0
            else:
                base_score -= 0.5
        
        # æ ¹æ®ä»£ç è¡Œæ•°è°ƒæ•´
        if total_lines > 1000:
            base_score -= (total_lines - 1000) * 0.01
        
        return max(0.0, min(100.0, base_score))
    
    async def _generate_summary(self, content: str, issues: List[CodeIssue], language: LanguageType) -> str:
        """ç”Ÿæˆåˆ†ææ‘˜è¦"""
        total_issues = len(issues)
        error_count = len([i for i in issues if i.severity == 'error'])
        warning_count = len([i for i in issues if i.severity == 'warning'])
        info_count = len([i for i in issues if i.severity == 'info'])
        
        summary = f"{language.value.upper()}ä»£ç åˆ†æå®Œæˆã€‚"
        summary += f"å…±å‘ç°{total_issues}ä¸ªé—®é¢˜ï¼š"
        summary += f"ä¸¥é‡é—®é¢˜{error_count}ä¸ªï¼Œ"
        summary += f"è­¦å‘Šé—®é¢˜{warning_count}ä¸ªï¼Œ"
        summary += f"ä¿¡æ¯é—®é¢˜{info_count}ä¸ªã€‚"
        
        if error_count > 0:
            summary += "å»ºè®®ä¼˜å…ˆä¿®å¤ä¸¥é‡é—®é¢˜ã€‚"
        elif warning_count > 0:
            summary += "å»ºè®®åŠæ—¶å¤„ç†è­¦å‘Šé—®é¢˜ã€‚"
        else:
            summary += "ä»£ç è´¨é‡è‰¯å¥½ã€‚"
        
        return summary
    
    async def analyze_project(self, project_path: str) -> Dict[str, Any]:
        """åˆ†ææ•´ä¸ªé¡¹ç›®"""
        results = {}
        total_files = 0
        total_issues = 0
        all_issues = []
        
        # éå†é¡¹ç›®æ–‡ä»¶
        for root, dirs, files in os.walk(project_path):
            # è·³è¿‡ä¸éœ€è¦çš„ç›®å½•
            dirs[:] = [d for d in dirs if d not in {'.git', '__pycache__', 'node_modules', '.venv', 'venv'}]
            
            for file in files:
                file_path = os.path.join(root, file)
                
                if self.is_supported_file(file_path):
                    total_files += 1
                    result = await self.analyze_file(file_path, project_path)
                    
                    if result:
                        language = result.language
                        if language not in results:
                            results[language] = {
                                'files_analyzed': 0,
                                'issues_found': 0,
                                'issues': [],
                                'metrics': {},
                                'summary': ''
                            }
                        
                        results[language]['files_analyzed'] += result.files_analyzed
                        results[language]['issues_found'] += result.issues_found
                        results[language]['issues'].extend(result.issues)
                        results[language]['metrics'].update(result.metrics)
                        
                        total_issues += result.issues_found
                        all_issues.extend(result.issues)
        
        # ç”Ÿæˆæ€»ä½“æ‘˜è¦
        overall_summary = f"å¤šè¯­è¨€é¡¹ç›®åˆ†æå®Œæˆã€‚å…±åˆ†æ{total_files}ä¸ªæ–‡ä»¶ï¼Œå‘ç°{total_issues}ä¸ªé—®é¢˜ã€‚"
        
        return {
            'total_files': total_files,
            'total_issues': total_issues,
            'results_by_language': results,
            'all_issues': all_issues,
            'overall_summary': overall_summary
        }
